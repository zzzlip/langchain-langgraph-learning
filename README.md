# å¸¦ä½ æ·±å…¥äº†è§£LangChain+Langgraphçš„å­¦ä¹ æ–‡æ¡£ç¬”è®°  (v0.3)

## ç›®å½•

- [1. å¼•è¨€](#1-å¼•è¨€)
- [2. ä»€ä¹ˆæ˜¯Langchainå’ŒLanggraph](#2-ä»€ä¹ˆæ˜¯langchainå’Œlanggraph)
- [3. ç»„ä»¶ä¸€ï¼šåŸºç¡€ä¸‰å¤§ä»¶ (Base)](#3-ç»„ä»¶ä¸€åŸºç¡€ä¸‰å¤§ä»¶-base)
  - [3.1. æ¨¡å‹è°ƒç”¨ (Language Models)](#31-æ¨¡å‹è°ƒç”¨-language-models)
  - [3.2. æç¤ºæ¨¡æ¿ (Prompt Templates)](#32-æç¤ºæ¨¡æ¿-prompt-templates)
    - [åŸºç¡€æç¤ºè¯æ¨¡ç‰ˆ](#åŸºç¡€æç¤ºè¯æ¨¡ç‰ˆ)
      - [PromptTemplate](#prompttemplate)
      - [SystemMessagePromptTemplate // HumanMessagePromptTemplate // AIMessagePromptTemplate](#systemmessageprompttemplate--humanmessageprompttemplate--aimessageprompttemplate)
      - [ChatPromptTemplate](#chatprompttemplate)
    - [few-shot æ¨¡ç‰ˆ](#few-shot-æ¨¡ç‰ˆ)
  - [3.3. è¾“å‡ºè§£æå™¨ (Output Parsers)](#33-è¾“å‡ºè§£æå™¨-output-parsers)
    - [è‡ªå®šä¹‰è¾“å‡ºè§£æå™¨](#è‡ªå®šä¹‰è¾“å‡ºè§£æå™¨)
    - [è¾“å‡ºä¿®å¤](#è¾“å‡ºä¿®å¤)
- [4. ç»„ä»¶ä¸‰ï¼šé“¾ (Chains)](#4-ç»„ä»¶ä¸‰é“¾-chains)
  - [4.1 åŸºç¡€æ¦‚å¿µ](#41-åŸºç¡€æ¦‚å¿µ)
    - [Runnable](#runnable)
    - [RunnableLambda](#runnablelambda)
    - [RunnableParallel (æˆ– RunnableMap)](#runnableparallel-æˆ–-runnablemap)
    - [LangChain è¡¨è¾¾å¼è¯­è¨€ (LCEL) - æ–°ä¸€ä»£é“¾æ„å»ºæ–¹æ³•](#langchain-è¡¨è¾¾å¼è¯­è¨€-lcel---æ–°ä¸€ä»£é“¾æ„å»ºæ–¹æ³•)
  - [4.2 é¡ºåºé“¾ (Sequential Chains)](#42-é¡ºåºé“¾-sequential-chains)
    - [å‰è€…è¾“å‡ºä¸ºç›´æ¥ä½œä¸ºåè€…è¾“å…¥çš„](#å‰è€…è¾“å‡ºä¸ºç›´æ¥ä½œä¸ºåè€…è¾“å…¥çš„)
    - [å‰è€…è¾“å‡ºä½œä¸ºåè€…çš„éƒ¨åˆ†è¾“å…¥](#å‰è€…è¾“å‡ºä½œä¸ºåè€…çš„éƒ¨åˆ†è¾“å…¥)
    - [åè€…çš„è¾“å…¥è¦æ±‚ä¸åªå‰è€…çš„è¾“å‡ºï¼Œè¿˜è¦æ±‚å…¶ä»–è¾“å…¥ï¼ˆä¾‹å¦‚åˆå§‹ä¿¡æ¯ï¼Œæˆ–è€…ä¹‹å‰é“¾çš„æŸäº›è¾“å‡ºï¼‰](#åè€…çš„è¾“å…¥è¦æ±‚ä¸åªå‰è€…çš„è¾“å‡ºè¿˜è¦æ±‚å…¶ä»–è¾“å…¥ä¾‹å¦‚åˆå§‹ä¿¡æ¯æˆ–è€…ä¹‹å‰é“¾çš„æŸäº›è¾“å‡º)
  - [4.3 å¹¶è¡Œé“¾ (Parallel Chains)](#43-å¹¶è¡Œé“¾-parallel-chains)
    - [Langchain](#langchain)
    - [Langgraph](#langgraph)
  - [4.4 å¾ªç¯é“¾-Langgraphç‰¹æœ‰](#44-å¾ªç¯é“¾-langgraphç‰¹æœ‰)
    - [è‡ªæˆ‘ä¿®æ­£ä¸åæ€](#è‡ªæˆ‘ä¿®æ­£ä¸åæ€)
- [5. ç»„ä»¶å››ï¼šè®°å¿† (Memory)](#5-ç»„ä»¶å››è®°å¿†-memory)
  - [5.1. çŸ­æœŸè®°å¿†](#51-çŸ­æœŸè®°å¿†)
    - [æ·»åŠ çŸ­æœŸè®°å¿†-èŠ‚ç‚¹](#æ·»åŠ çŸ­æœŸè®°å¿†-èŠ‚ç‚¹)
    - [æ·»åŠ çŸ­æœŸè®°å¿†-å·¥å…·](#æ·»åŠ çŸ­æœŸè®°å¿†-å·¥å…·)
    - [è¯»å–è®°å¿†](#è¯»å–è®°å¿†)
    - [ä¿®å‰ªè®°å¿†](#ä¿®å‰ªè®°å¿†)
    - [åˆ é™¤è®°å¿†](#åˆ é™¤è®°å¿†)
    - [æ‘˜è¦è®°å¿†](#æ‘˜è¦è®°å¿†)
      - [summarize_messages](#summarize_messages)
      - [SummarizationNode](#summarizationnode)
  - [5.2 é•¿æœŸè®°å¿†](#52-é•¿æœŸè®°å¿†)
  - [5.3 æ£€æŸ¥ç‚¹](#53-æ£€æŸ¥ç‚¹)
    - [è·å–å½“å‰å¯¹è¯çŠ¶æ€](#è·å–å½“å‰å¯¹è¯çŠ¶æ€)
    - [è·å–æ•´ä¸ªè¿‡ç¨‹å¯¹è¯å†å²çŠ¶æ€è®°å½•](#è·å–æ•´ä¸ªè¿‡ç¨‹å¯¹è¯å†å²çŠ¶æ€è®°å½•)
    - [åˆ é™¤çº¿ç¨‹çš„æ‰€æœ‰æ£€æŸ¥ç‚¹](#åˆ é™¤çº¿ç¨‹çš„æ‰€æœ‰æ£€æŸ¥ç‚¹)
- [6. ç»„ä»¶äº”ï¼šä»£ç† (Agents)](#6-ç»„ä»¶äº”ä»£ç†-agents)
  - [6.1. å·¥å…·](#61-å·¥å…·)
    - [å·¥å…·åŸºæœ¬å‚æ•°](#å·¥å…·åŸºæœ¬å‚æ•°)
    - [åˆ›å»ºæ–¹æ³•](#åˆ›å»ºæ–¹æ³•)
      - [@tool åˆ›å»º](#tool-åˆ›å»º)
      - [StructuredTool](#structuredtool)
      - [é’ˆå¯¹äºå·¥å…·çš„é”™è¯¯å¤„ç†](#é’ˆå¯¹äºå·¥å…·çš„é”™è¯¯å¤„ç†)
      - [è¿›é˜¶ç”¨æ³•](#è¿›é˜¶ç”¨æ³•)
    - [å·¥å…·è°ƒç”¨](#å·¥å…·è°ƒç”¨)
      - [è°ƒç”¨æ–¹æ³•](#è°ƒç”¨æ–¹æ³•)
      - [é’ˆå¯¹äºéšè—å‚æ•°çš„å¤„ç†](#é’ˆå¯¹äºéšè—å‚æ•°çš„å¤„ç†)
  - [6.2 React_agent](#62-react_agent)
    - [æ¶æ„ä»‹ç»](#æ¶æ„ä»‹ç»)
    - [å‚æ•°ä»‹ç»](#å‚æ•°ä»‹ç»)
  - [6.3 å›¾](#63-å›¾)
    - [æ ¸å¿ƒæ¦‚å¿µ](#æ ¸å¿ƒæ¦‚å¿µ)
    - [stateï¼ˆçŠ¶æ€ï¼‰](#stateçŠ¶æ€)
      - [å¸¸è§type](#å¸¸è§type)
      - [Reducers (å½’çº³å‡½æ•°)](#reducers-å½’çº³å‡½æ•°)
      - [Messages (æ¶ˆæ¯)](#messages-æ¶ˆæ¯)
      - [çŠ¶æ€å®ä¾‹è®²è§£](#çŠ¶æ€å®ä¾‹è®²è§£)
    - [Nodes (èŠ‚ç‚¹)](#nodes-èŠ‚ç‚¹)
    - [Edges (è¾¹)](#edges-è¾¹)
    - [`Send` å’Œ `Command`](#send-å’Œ-command)
    - [Runtime Contextï¼ˆè¿è¡Œæ—¶ä¸Šä¸‹æ–‡ ï¼‰](#runtime-contextè¿è¡Œæ—¶ä¸Šä¸‹æ–‡-)
  - [6.4 å¤šæ™ºèƒ½ä½“](#64-å¤šæ™ºèƒ½ä½“)
    - [è½¬äº¤æœºåˆ¶](#è½¬äº¤æœºåˆ¶)
      - [æ„å›¾è¯†åˆ«](#æ„å›¾è¯†åˆ«)
      - [èŠ‚ç‚¹ç§»äº¤](#èŠ‚ç‚¹ç§»äº¤)
    - [å¤šæ™ºèƒ½ä½“æ¶æ„](#å¤šæ™ºèƒ½ä½“æ¶æ„)
      - [Network-ç½‘ç»œæ¶æ„ï¼ˆSwarm-é¸Ÿç¾¤æ¶æ„ï¼‰](#network-ç½‘ç»œæ¶æ„swarm-é¸Ÿç¾¤æ¶æ„)
      - [Supervisoræ¶æ„](#supervisoræ¶æ„)


---

## 1. å¼•è¨€

åœ¨aiæŒç»­é£é€Ÿå‘å±•çš„ä»Šå¤©ï¼Œæ™ºèƒ½ä½“å¼€å‘ç°å¦‚ä»Šéå¸¸ç«çˆ†ï¼Œè€Œä½œä¸ºä¸»æµçš„æ™ºèƒ½ä½“å¼€å‘å¹³å° Langchain+Langgraph ä¹Ÿæœ‰ç€å¾ˆé«˜çš„æµé‡

ä½†æ˜¯ç›®å‰å¸‚é¢ä¸Šçš„é’ˆå¯¹äºè¯¥å·¥å…·çš„è§†é¢‘æ•™å­¦è¿‡äºç®€å•ï¼Œæ‰€ä»¥æˆ‘ä¹¦å†™äº†ä¸‹é¢è¿™ä¸ªæ–‡æ¡£ã€‚

è¯¥æ–‡æ¡£è¯¦ç»†è®°å½•å¦‚ä½•é›†æˆlangchainå’Œlanggraphçš„ä¼˜åŠ¿è¿›è¡Œæ™ºèƒ½ä½“å¼€å‘ï¼Œåœ¨æœ¬æ–‡æ¡£ä¸­è¯¦ç»†è®°å½•äº†æˆ‘ä½¿ç”¨langchainå’Œlanggraphå¼€å‘æ™ºèƒ½ä½“çš„ç»éªŒä»¥åŠç»“åˆå®˜æ–¹æ–‡æ¡£è¿›è¡Œçš„æ ¸å¿ƒç»„ä»¶æ•™å­¦ï¼Œåœ¨è¯¥æ–‡æ¡£ä¸­ä¸ä»…æ¶µç›–äº†çŸ¥è¯†å†…å®¹è¿˜æ¶µç›–äº†æˆ‘å¯¹å…¶çš„ç†è§£ä»¥åŠå®Œæ•´çš„ä»£ç å®ä¾‹ã€‚

æ–‡æ¡£è¿˜å°†ä¼šæŒç»­æ›´æ–°ï¼ˆç›®å‰æ›´æ–°åˆ°å¤šæ™ºèƒ½ä½“æ¶æ„ï¼Œæ¥ä¸‹æ¥å°†ä¼šæ›´æ–° å›è°ƒæœºåˆ¶ï¼Œäººæœºäº¤äº’ï¼Œæ—¶é—´æ—…è¡Œï¼Œæ™ºèƒ½ä½“è¯„ä¼°ç­‰ï¼‰

åŒæ—¶æˆ‘åœ¨ä¸ä¹…æˆ‘å°†ä¼šå‘å¸ƒåŸºäºllamaindexè¿›è¡ŒRAGæ•™å­¦ï¼ˆåŒ…æ‹¬ä½†ä¸é™äº å¦‚ä½•è¿›è¡Œemmbedingå¾®è°ƒï¼ŒçŸ¥è¯†åº“æ­å»ºï¼Œé«˜çº§ragæ£€ç´¢ï¼Œä»¥åŠragåº”ç”¨è¯„ä¼°ï¼‰

## 2. ä»€ä¹ˆæ˜¯Langchainå’ŒLanggraph

LangChain æ˜¯ä¸€ä¸ªå¼€æºæ¡†æ¶ï¼Œç”¨äºæ„å»ºå’Œæ‰©å±•åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ (LLM) çš„åº”ç”¨ç¨‹åºã€‚å®ƒå…è®¸å¼€å‘è€…é€šè¿‡â€œé“¾å¼â€ (chaining) æ“ä½œæ¥ç»„åˆ LLM ä¸å…¶ä»–ç»„ä»¶ï¼Œå¦‚æç¤ºæ¨¡æ¿ã€å†…å­˜ã€æ£€ç´¢ç³»ç»Ÿå’Œå·¥å…·ï¼Œä»è€Œåˆ›å»ºå¯¹è¯ä»£ç†ã€è‡ªåŠ¨åŒ–ä»»åŠ¡æˆ–è‡ªå®šä¹‰ AI åº”ç”¨ã€‚LangChain å¼ºè°ƒç®€å•æ€§å’Œæ¨¡å—åŒ–ï¼Œé€‚åˆå¤„ç†çº¿æ€§ã€å¯é¢„æµ‹çš„å·¥ä½œæµï¼Œä¾‹å¦‚é—®ç­”ç³»ç»Ÿæˆ–æ•°æ®å¤„ç†ç®¡é“ã€‚

LangGraph æ˜¯ LangChain çš„ä¸€ä¸ªæ‰©å±•æ¨¡å—ï¼Œä¸“æ³¨äºæ„å»ºçŠ¶æ€åŒ–çš„ã€å¤šä»£ç†å·¥ä½œæµã€‚å®ƒå°†ä»£ç†é€»è¾‘å»ºæ¨¡ä¸ºå›¾ (graph)ï¼ŒåŒ…æ‹¬èŠ‚ç‚¹ (nodes) è¡¨ç¤ºåŠ¨ä½œã€è¾¹ç¼˜ (edges) è¡¨ç¤ºå†³ç­–è·¯å¾„ï¼Œæ”¯æŒå¾ªç¯ã€æ¡ä»¶åˆ†æ”¯å’Œå¤æ‚è¿­ä»£ã€‚ç›¸æ¯” LangChain çš„é«˜å±‚æ¬¡æŠ½è±¡ï¼ŒLangGraph æä¾›æ›´ä½çº§çš„æ§åˆ¶ï¼Œé€‚åˆå¤„ç†ä¸ç¡®å®šæ€§é«˜æˆ–éœ€è¦å¤šæ­¥æ¨ç†çš„åœºæ™¯ï¼Œå¦‚é«˜çº§ AI ä»£ç†æˆ–åŠ¨æ€å†³ç­–ç³»ç»Ÿã€‚

æ€»ä½“ä¸Šï¼ŒLangChain æ›´é€‚åˆåˆå­¦è€…å’Œç®€å•åº”ç”¨ï¼Œè€Œ LangGraph åˆ™å¢å¼ºäº† LangChain çš„èƒ½åŠ›ï¼Œç”¨äºæ›´å¤æ‚çš„ AI ç³»ç»Ÿæ„å»ºã€‚å¦‚æœä½ åˆšå…¥é—¨ï¼Œå»ºè®®ä» LangChain å¼€å§‹å­¦ä¹ ï¼Œç„¶åæ‰©å±•åˆ° LangGraphã€‚

## 3. ç»„ä»¶ä¸€ï¼šåŸºç¡€ä¸‰å¤§ä»¶ (Base)

è¿™æ˜¯ä¸ LLM ç›´æ¥äº¤äº’çš„å±‚ã€‚

### 3.1. æ¨¡å‹è°ƒç”¨ (Language Models)

åœ¨langchainä¸­æœ€å¸¸ç”¨çš„è°ƒç”¨æ–¹å¼å°±æ˜¯ä½¿ç”¨ ``ChatOpenai``ã€‚ä»–æ˜¯å¯¹ `openai` åº“çš„ç›´æ¥å°è£…ï¼Œä¼ å…¥çš„å‚æ•°ï¼Œä¹Ÿæ˜¯ä¼šç›´æ¥ä¼ å…¥ç»™åº•å±‚çš„ `chat.completions.create` æ–¹æ³•ã€‚


**ä»¥googleè°ƒå–æ€è€ƒçŠ¶æ€ä¸ºä¾‹å­:**

```
from openai import OpenAI
# è¿™æ˜¯å®˜æ–¹ç»™å‡ºçš„è°ƒç”¨æ–¹å¼
client = OpenAI(
    api_key="GEMINI_API_KEY",
    base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
)

response = client.chat.completions.create(
    model="gemini-2.5-flash",
    messages=[{"role": "user", "content": "Explain to me how AI works"}],
    extra_body={
      'extra_body': {
        "google": {
          "thinking_config": {
            "thinking_budget": 800,
            "include_thoughts": True
          }
        }
      }
    }
)

print(response.choices[0].message)

#### ä¸‹é¢æ˜¯å¦‚æœåœ¨langchainä¸­è®¾ç½®ç›¸å…³å‚æ•°çš„æ–¹å¼ï¼š
from langchain_openai import ChatOpenAI
import api_key

llm_google_think = ChatOpenAI(
    base_url="https://generativelanguage.googleapis.com/v1beta/openai/",
    api_key=api_key.google_api,
    model="gemini-2.5-flash",
    temperature=0.7,
    streaming=True,
    extra_body={
        'extra_body': {
            "google": {
                "thinking_config": {
                    "thinking_budget": 800,
                    "include_thoughts": True
                }
            }
        }
    }
)
# å¯ä»¥çœ‹åˆ°åº•å±‚çš„ `chat.completions.create` æ–¹æ³•å¯¹åº”çš„å‚æ•°å¯ä»¥ç›´æ¥åœ¨ ChatOpenAI ç»™å‡ºã€‚
```

### 3.2. æç¤ºæ¨¡æ¿ (Prompt Templates)

#### åŸºç¡€æç¤ºè¯æ¨¡ç‰ˆ
##### PromptTemplate

è¯¥æç¤ºè¯æ¨¡ç‰ˆæ˜¯æœ€åŸºæœ¬çš„æç¤ºè¯æ¨¡ç‰ˆï¼Œæ‰€æœ‰å…¶ä»–æ¨¡ç‰ˆéƒ½æ˜¯åœ¨è¯¥åŸºç¡€çš„å°è£… ä¸€èˆ¬ä½¿ç”¨æ–¹æ³•ä¸ºï¼š

```
prompt = PromptTemplate(
    template="""è¯·æ ¹æ®ä¸‹é¢çš„æ–‡æœ¬ï¼Œæå–å‡ºäººç‰©çš„å…³é”®ä¿¡æ¯ã€‚
{format_instructions}
æ–‡æœ¬: {query}
""",
    input_variables=["query"],
    partial_variables={"format_instructions": format_instructions}
)
```
**SystemMessagePromptTemplate // HumanMessagePromptTemplate // AIMessagePromptTemplate**

è¿™ä¸‰ä¸ªæç¤ºè¯æ¨¡ç‰ˆæ˜¯å¯¹ `Message` çš„å°è£…ï¼Œåˆ†åˆ«å¯¹åº”ç³»ç»Ÿæ¶ˆæ¯ã€äººç±»æ¶ˆæ¯å’ŒAIæ¶ˆæ¯ã€‚å®ƒä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨å­—ç¬¦ä¸²æˆ–è€…PromptTemplateæ¥åˆ›å»ºã€‚

```
1.
system_prompt=SystemMessagePromptTemplate.from_template(system_template,partial_variables={'out_put_parser': json_parser.get_format_instructions()})
2.
#æˆ–è€…ä¸‹é¢è¿™ç§åˆ›å»ºæ–¹å¼
prompt_one=PromptTemplate.from_template(system_template,partial_variables={'out_put_parser': json_parser.get_format_instructions()})
system_prompt=SystemMessagePromptTemplate(prompt_one)#å¦‚æœä½ å·²ç»æœ‰äº†prompttemplateå°±å¯ä»¥ç”¨æ¥ç›´æ¥è½¬åŒ–
3.
##åŒæ—¶ä¹Ÿç­‰ä»·äº
('system',system_template) ## è¿™ç§å…ƒç»„çš„å½¢å¼ ä½†æ˜¯è¿™æ ·æ— æ³•éƒ¨åˆ†è¾“å…¥ï¼Œé€‚ç”¨äºè¯¥æç¤ºè¯æ‰€æœ‰å‚æ•°å…¨éƒ¨è¾“å…¥çš„åœºæ™¯ã€‚
```
**ChatPromptTemplate**

* `from_template` é€‚ç”¨äºç®€å•çš„å­—ç¬¦ä¸²æ¨¡æ¿,å¹¶ä¸”ä»–åˆ›å»ºçš„æ˜¯human message ä¸€èˆ¬åªé€‚ç”¨äºæ ¼å¼åŒ–ç”¨æˆ·çš„è¾“å…¥ä¿¡æ¯ã€‚

* `from_messages` é€‚ç”¨äºæ›´å¤æ‚çš„æ¶ˆæ¯æ ¼å¼ï¼Œæ”¯æŒè§’è‰²ï¼ˆå¦‚ user, assistantï¼‰å’Œå¤šè½®å¯¹è¯ã€‚

**ä¸€èˆ¬ä¸€ä¸ªå®Œæ•´çš„æç¤ºè¯æ¨¡ç‰ˆéƒ½æ˜¯ä½¿ç”¨ `from_messages` æ¥åˆ›å»ºçš„ã€‚**

```
sysytem_message = """ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚"""
prompt = ChatPromptTemplate.from_messages(
    [
        ("system", sysytem_message),  # ç³»ç»Ÿæ¶ˆæ¯ä¹Ÿç”¨å…ƒç»„å®šä¹‰
        ("human", "ç”¨æˆ·è¾“å…¥ï¼š{input}")         # äººç±»æ¶ˆæ¯æ¨¡æ¿ å¦‚æœè¿™é‡Œè¾“å…¥è¿‡å¤š ä¹Ÿå¯ä»¥é¢„å…ˆæ­å»ºä¸€ä¸ªprompt
    ]
)
# ä¾‹å¦‚ä¸‹é¢æ‰€ç¤º
human_prompt=ChatPromptTemplate.from_template("ç”¨æˆ·è¾“å…¥ï¼š{input}")
prompt= ChatPromptTemplate.from_messages(
    [
        ("system", sysytem_message),  # ç³»ç»Ÿæ¶ˆæ¯ä¹Ÿç”¨å…ƒç»„å®šä¹‰
        human_prompt
    ]
)
```
**å¦‚æœå½“å‰æ¨¡å—æ¶‰åŠåˆ°å¤šè½®å¯¹è¯ä¸”ä¸ºaiå®šä¹‰äº†éå¸¸è§„è§’è‰²ï¼Œè¯·åŠ¡å¿…ä¸è¦ä½¿ç”¨ä¸€ä¸ª `from_template` çš„æ¨¡ç‰ˆæ¥åˆ›å»ºæç¤ºè¯ã€‚å› ä¸º `from_template` åªä¼šåˆ›å»º human message è§’è‰²ä¿¡æ¯å¦‚æœå¤„äº `human message` ä¼šéšç€å¤šè½®å¯¹è¯å®¹æ˜“è¢«é—å¿˜ä¸”å¾ˆå®¹æ˜“è¢«ç”¨æˆ·çš„è¾“å…¥é‡æ–°å®šä¹‰**

* ç¡¬ç¼–ç æ¨¡ç‰ˆ
```
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
import api_key

llm_google = ChatOpenAI(
  base_url="https://generativelanguage.googleapis.com/v1beta/openai/",
  api_key=api_key.google_api,
  model="gemini-2.5-flash-lite",
  temperature=0.7,
  streaming=True,
)
topic = "äººå·¥æ™ºèƒ½çš„æœªæ¥å‘å±•"
prompt_template=f"""
è¯·ä½ å¸®æˆ‘å†™ä¸€ä¸ªå…³äº{topic}çš„æ–‡ç« ï¼š
"""
prompt=ChatPromptTemplate.from_template(prompt_template)
chain= prompt | llm_google
response = chain.invoke({})
```
* åŠ¨æ€æç¤ºè¯æ¨¡ç‰ˆ
```
topic = "äººå·¥æ™ºèƒ½çš„æœªæ¥å‘å±•"
prompt_template="""
è¯·ä½ å¸®æˆ‘å†™ä¸€ä¸ªå…³äº{topic}çš„æ–‡ç« ï¼š
"""
prompt=ChatPromptTemplate.from_template(prompt_template)
chain= prompt | llm_google
response = chain.invoke({'topic': topic})
```

#### few-shot æ¨¡ç‰ˆ

**LangChain æä¾›äº† `FewShotPromptTemplate` æ¥ç®€åŒ–è¿™ä¸ªè¿‡ç¨‹ã€‚** 

ä¸‹é¢æ˜¯æœ€ç®€å•çš„æ— éœ€å¯¹exampleè¿›è¡Œå¤„ç†çš„æ–¹æ³•
```
examples = [
    {"input": "2 ğŸ¦œ 2", "output": "4"},
    {"input": "2 ğŸ¦œ 3", "output": "5"},
    {"input": "2 ğŸ¦œ 4", "output": "6"},
    {"input": "What did the cow say to the moon?", "output": "nothing at all"},
    {
        "input": "Write me a poem about the moon",
        "output": "One for the moon, and one for me, who are we to talk about the moon?",
    },
]

few_shot_prompt = FewShotChatMessagePromptTemplate(
    examples=examples,
    example_prompt=ChatPromptTemplate.from_messages(
        [('human', "{input}"), ("ai", "{output}")]
    ),
    input_variables=["input"],
)
```
**ä½†æ˜¯å¯¹äºç”Ÿäº§ä¸­ç”±äºexampleå¯èƒ½è¿‡å¤šè¿‡æ‚ï¼Œå¿…é¡»è¦å¯¹exampleè¿›è¡Œå¤„ç†æ‰€ä»¥æˆ‘ä»¬é€šå¸¸éœ€è¦å¼•å…¥selectorã€‚**

**ä¸‹é¢æˆ‘å°±ç›´æ¥ä»‹ç»æœ€ä¸ºçµæ´»çš„è‡ªå®šä¹‰é€‰æ‹©å™¨çš„æ–¹æ³•ï¼Œå®˜æ–¹ä¹Ÿå°è£…äº†ä¸€äº›ï¼Œå¯ä»¥è‡ªè¡ŒæŸ¥é˜…æ–‡æ¡£**
```
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate
from langchain_core.example_selectors.base import BaseExampleSelector
from langchain_core.messages import HumanMessage, AIMessage

# ä½ çš„ç¤ºä¾‹æ•°æ®
examples = [
    {"input": "2 ğŸ¦œ 2", "output": "4"},
    {"input": "2 ğŸ¦œ 3", "output": "5"},
    {"input": "2 ğŸ¦œ 4", "output": "6"},
    {"input": "What did the cow say to the moon?", "output": "nothing at all"},
    {
        "input": "Write me a poem about the moon",
        "output": "One for the moon, and one for me, who are we to talk about the moon?",
    },
]


# ä½ çš„è‡ªå®šä¹‰é€‰æ‹©å™¨ï¼Œç¡®ä¿ select_examples æœ‰è¿”å›å€¼
class CustomExampleSelector(BaseExampleSelector):
    def __init__(self, examples):
        self.examples = examples

    def add_example(self, example):
        self.examples.append(example)

    def select_examples(self, input_variables):
        """æ ¹æ®è¾“å…¥å˜é‡é€‰æ‹©ç¤ºä¾‹ã€‚"""
        print(f"ä¼ é€’ç»™é€‰æ‹©å™¨çš„è¾“å…¥å˜é‡: {input_variables}")

        # è¿™æ˜¯ä¸€ä¸ªç®€å•çš„é€‰æ‹©é€»è¾‘ï¼šå¦‚æœè¾“å…¥åŒ…å«é¹¦é¹‰è¡¨æƒ…ï¼Œå°±åªè¿”å›æ•°å­¦ç›¸å…³çš„ä¾‹å­
        user_input = input_variables['input']
        if "ğŸ¦œ" in user_input:
            return [ex for ex in self.examples if "ğŸ¦œ" in ex['input']]
        else:
            # å¦åˆ™ï¼Œè¿”å›éæ•°å­¦ç›¸å…³çš„ä¾‹å­
            return [ex for ex in self.examples if "ğŸ¦œ" not in ex['input']]


# åˆå§‹åŒ–é€‰æ‹©å™¨
example_selector = CustomExampleSelector(examples)
few_shot_prompt = FewShotChatMessagePromptTemplate(
    example_selector=example_selector,
    example_prompt=ChatPromptTemplate.from_messages(
        [('human', "{input}"), ("ai", "{output}")]
    ),
    input_variables=["input"],
)
system_prompt='ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚'
prompt= ChatPromptTemplate.from_messages(
    [
        ("system", system_prompt),
        few_shot_prompt,
        ("human", "{input}"),
    ]
)
# --- æµ‹è¯• ---
# 1. æµ‹è¯•æ•°å­¦é—®é¢˜
print("--- æµ‹è¯•æ•°å­¦é—®é¢˜ ---")
final_prompt_math = prompt.invoke({"input": "What's 3 ğŸ¦œ 3?"})
print(final_prompt_math.to_messages())
```
* **æ³¨æ„äº‹é¡¹**
  * å¦‚æœä½ éœ€è¦selectorï¼Œé‚£ä¹ˆä½ å°±æ— éœ€ä¼ å…¥examples
  * è‡ªå®šä¹‰é€‰æ‹© å…¶ä»–çš„éƒ½å¯ä»¥ç»§æ‰¿ï¼Œä½†æ˜¯éœ€è¦ä½ å¤å†™ add_example å’Œ select_examples æ–¹æ³•  select_examples æ–¹æ³•çš„è¾“å…¥å°±æ˜¯ç”¨æˆ·çš„è¾“å…¥ï¼Œè¿”å›ä¸€ä¸ªç»è¿‡å¤„ç†çš„exampleåˆ—è¡¨
  * input_variables å‚æ•°å¹¶ä¸æ˜¯ä¸€ä¸ªè¿‡æ»¤å™¨ï¼Œä»–å¹¶ä¸ä¼šè¿‡æ»¤æ‰ä¸éœ€è¦çš„keyï¼Œä»–åªæ˜¯èµ·åˆ°ä¸€ä¸ªç›‘æ§ä½œç”¨ï¼Œå³è¾“å…¥å¿…é¡»åŒ…å«ä½ è¦æ±‚çš„keyï¼Œå¦åˆ™ä¼šæŠ¥é”™ã€‚


### 3.3. è¾“å‡ºè§£æå™¨ (Output Parsers)

LLM çš„è¾“å‡ºæ˜¯æ–‡æœ¬ï¼Œä½†æˆ‘ä»¬å¸¸å¸¸éœ€è¦ç»“æ„åŒ–çš„æ•°æ®ï¼ˆå¦‚ JSON, Listï¼‰ã€‚è¾“å‡ºè§£æå™¨è´Ÿè´£å°†æ¨¡å‹çš„åŸå§‹æ–‡æœ¬è¾“å‡ºè½¬æ¢ä¸ºæˆ‘ä»¬éœ€è¦çš„æ ¼å¼ï¼Œå¹¶å¯ä»¥é™„å¸¦æ ¼å¼åŒ–æŒ‡ä»¤ã€‚

* StrOutputParser
* JsonOutputParser
* CommaSeparatedListOutputParser
* PydanticOutputParser
ä¸Šé¢å››ç§å°±æ˜¯æœ€æ™®é€šçš„ï¼Œåˆ†åˆ«ç”¨æ¥ï¼Œå°†messageè½¬æ¢æˆå­—ç¬¦ä¸²ï¼Œjsonï¼Œåˆ—è¡¨ï¼Œpydanticï¼Œä½†æ˜¯åœ¨å®é™…åº”ç”¨ä¸­å¯¹äºjsonæˆ–è€…pydanticçš„è¾“å‡ºæ ¼å¼å¯¹äºä¸åŒçš„åœºæ™¯ï¼Œå¾€å¾€éœ€è¦è‡ªå®šä¹‰æ ¼å¼ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨è‡ªå®šä¹‰è¾“å‡ºè§£æå™¨ã€‚
#### è‡ªå®šä¹‰è¾“å‡ºè§£æå™¨

```python
from base import model,llm
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import PydanticOutputParser,StrOutputParser,JsonOutputParser,CommaSeparatedListOutputParser
from pydantic import BaseModel, Field

class CharacterInfo(BaseModel): #ä½¿ç”¨pydanticå®šä¹‰æ•°æ®ç»“æ„
    name: str = Field(description="è§’è‰²çš„å§“å")
    age: int = Field(description="è§’è‰²çš„å¹´é¾„")
    skills: list[str] = Field(description="è§’è‰²çš„æŠ€èƒ½åˆ—è¡¨")

# 2. åˆ›å»ºè§£æå™¨
parser = PydanticOutputParser(pydantic_object=CharacterInfo)
parser = JsonOutputParser(pydantic_object=CharacterInfo) ##è¿™æ˜¯jsonè‡ªå®šä¹‰

# 3. è·å–æ ¼å¼åŒ–æŒ‡ä»¤
format_instructions = parser.get_format_instructions()


# 5. åœ¨ä½ çš„ä¸­æ–‡æç¤ºä¸­ä½¿ç”¨å®ƒ
prompt = PromptTemplate(
    template="""è¯·æ ¹æ®ä¸‹é¢çš„æ–‡æœ¬ï¼Œæå–å‡ºäººç‰©çš„å…³é”®ä¿¡æ¯ã€‚

{format_instructions}

æ–‡æœ¬: {query}
""",
    input_variables=["query"],
    partial_variables={"format_instructions": format_instructions} #éƒ¨åˆ†è¿½åŠ ï¼Œé¢„å…ˆåŠ å…¥ä¸€äº›æ— éœ€åŠ¨æ€å¡«å…¥çš„å‚æ•°ï¼Œè¿™æ ·å‡å°‘äº†ä¹‹åinvokeæ—¶çš„å‚æ•°
)

# 6. è¿è¡Œé“¾
chain = prompt | llm | parser
answer = chain.invoke({
    "query": "è§’è‰²åæ˜¯äºšç‘Ÿï¼Œå¹´é¾„30å²ï¼ŒæŠ€èƒ½åŒ…æ‹¬å‰‘æœ¯ã€éª‘æœ¯å’Œæˆ˜ç•¥ã€‚"
})
### è¾“å‡º name='äºšç‘Ÿ' age=30 skills=['å‰‘æœ¯', 'éª‘æœ¯', 'æˆ˜ç•¥']
### {'name': 'äºšç‘Ÿ', 'age': 30, 'skills': ['å‰‘æœ¯', 'éª‘æœ¯', 'æˆ˜ç•¥']}

```
**æ³¨æ„äº‹é¡¹ï¼š**
* é’ˆå¯¹äºjsonå’Œpydanticæµå¼è¾“å‡ºé—®é¢˜ï¼š
  * ä»–ä»¬çš„æµå¼è¾“å‡ºæ¯æ¬¡æµå¼è¿”å›çš„éƒ½æ˜¯å¯¹åº”ç±»å‹ï¼ˆä»¥jsonä¸ºä¾‹å­ï¼‰
```
{'name': 'æé›·', 'age': 120}
{'name': 'æé›·', 'age': 120, 'skills': ['']}
{'name': 'æé›·', 'age': 120, 'skills': ['ç«ç„°']}
{'name': 'æé›·', 'age': 120, 'skills': ['ç«ç„°é­”æ³•']}
{'name': 'æé›·', 'age': 120, 'skills': ['ç«ç„°é­”æ³•', '']}
{'name': 'æé›·', 'age': 120, 'skills': ['ç«ç„°é­”æ³•', 'ç©ºé—´']}
{'name': 'æé›·', 'age': 120, 'skills': ['ç«ç„°é­”æ³•', 'ç©ºé—´ä¼ é€']}
```
  ä½†æ˜¯æˆ‘ä»¬å¦‚æœä¸å‰ç«¯æµå¼äº¤äº’çš„è¯å°±éœ€è¦æˆ‘ä»¬è¿›è¡Œå¤„ç†,ä¸‹é¢çš„æ“ä½œå°±å¯ä»¥ä¿è¯æŸä¸€ä¸ªkeyçš„valueåœ¨è¾“å‡ºçš„æ—¶å€™æ˜¯çœŸæ­£çš„æµå¼è¾“å‡ºäº†ã€‚
```
for chunk in chain.stream({"query": query_text}):
    if hasattr(chunk, "name"):
        print(chunk.name.replace(last_name, ""))
        last_name=chunk.name
```
#### è¾“å‡ºä¿®å¤
llmæœ‰æ—¶å€™ä¼šå› ä¸ºå„ç§åŸå› å¯¼è‡´è¾“å‡ºé”™è¯¯ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦è¿›è¡Œæ£€æŸ¥ï¼Œè¿™é‡Œæˆ‘ç»™å‡ºæœ€å¸¸ç”¨çš„æ–¹æ³•
```python
from langchain.output_parsers import RetryOutputParser
from base import model,llm
from langchain.prompts import PromptTemplate,ChatPromptTemplate
from langchain_core.output_parsers import PydanticOutputParser,StrOutputParser,JsonOutputParser,CommaSeparatedListOutputParser
from pydantic import BaseModel, Field
class CharacterInfo(BaseModel):
    name: str = Field(description="è§’è‰²çš„å§“å")
    age: int = Field(description="è§’è‰²çš„å¹´é¾„")
    skills: list[str] = Field(description="è§’è‰²çš„æŠ€èƒ½åˆ—è¡¨")

parser = PydanticOutputParser(pydantic_object=CharacterInfo)

format_instructions = parser.get_format_instructions()

prompt = PromptTemplate(
    template="""è¯·æ ¹æ®ä¸‹é¢çš„æ–‡æœ¬ï¼Œæå–å‡ºäººç‰©çš„å…³é”®ä¿¡æ¯ã€‚
{format_instructions}
æ–‡æœ¬: {query}
""",
    input_variables=["query"],
    partial_variables={"format_instructions": format_instructions}
)
prompt_value = prompt.format_prompt(query="è§’è‰²çš„å§“åæ˜¯å¼ ä¸‰ï¼Œå¹´é¾„æ˜¯äºŒåäº”å²ï¼ŒæŠ€èƒ½åŒ…æ‹¬ç¼–ç¨‹ã€ç»˜ç”»å’Œå†™ä½œã€‚") ##è½¬ä¸ºpromptvalueå¯¹è±¡

retry_parser = RetryOutputParser.from_llm(parser=parser, llm=llm) ## åˆ›å»ºå®ä¾‹ï¼Œéœ€è¦ä¼ å…¥ åŸå§‹è§£é‡Šå™¨å’Œ LLM
bad_response = "è§’è‰²çš„å§“åæ˜¯å¼ ä¸‰ï¼Œå¹´é¾„æ˜¯äºŒåäº”å²ï¼ŒæŠ€èƒ½åŒ…æ‹¬ç¼–ç¨‹ã€ç»˜ç”»å’Œå†™ä½œã€‚" ### å‡è®¾è¿™æ˜¯æ¨¡å‹ç¬¬ä¸€æ¬¡é”™è¯¯çš„è¾“å‡º
result=retry_parser.parse_with_prompt(bad_response, prompt_value) ## ä½¿ç”¨parse_with_promptæ–¹æ³•æ¥è§£æå“åº”ï¼Œéœ€è¦ä¼ å…¥è¾“å‡ºå’Œä¸€ä¸ªpromptvalue å¯¹è±¡

## name='å¼ ä¸‰' age=25 skills=['ç¼–ç¨‹', 'ç»˜ç”»', 'å†™ä½œ']
```
**ç‰¹åˆ«æ³¨æ„è°ƒç”¨æ–¹æ³•çš„æ—¶å€™éœ€è¦ä¼ å…¥çš„æ˜¯PromptValue å¯¹è±¡ï¼Œè€Œä¸æ˜¯ç›´æ¥ä¼ å…¥å­—ç¬¦ä¸²æˆ–è€…templateã€‚**  

## 4. ç»„ä»¶ä¸‰ï¼šé“¾ (Chains)

é“¾æ˜¯å°†å¤šä¸ªç»„ä»¶ï¼ˆå¦‚æ¨¡å‹ã€æç¤ºã€æ£€ç´¢å™¨ï¼‰æŒ‰é¡ºåºç»„åˆèµ·æ¥çš„æ ¸å¿ƒ
### 4.1 åŸºç¡€æ¦‚å¿µ
#### Runnable
Runnable æ˜¯ LangChain è¡¨è¾¾å¼è¯­è¨€ (LCEL) çš„åŸºçŸ³ã€‚å®ƒæ˜¯ä¸€ä¸ªæ ‡å‡†åŒ–çš„æ¥å£ï¼Œä»»ä½•å®ç°äº†è¯¥æ¥å£çš„å¯¹è±¡éƒ½å¯ä»¥è¢«æ— ç¼åœ°é›†æˆåˆ° LCEL é“¾å¼è°ƒç”¨ä¸­ã€‚å¯ä»¥æŠŠå®ƒç†è§£ä¸º LCEL ä¸–ç•Œé‡Œçš„â€œé€šç”¨é›¶ä»¶â€æˆ–â€œæ ‡å‡†æ’å¤´â€ã€‚
ä¸€ä¸ªå¯¹è±¡ä¸€æ—¦æˆä¸º Runnableï¼Œå°±è‡ªåŠ¨è·å¾—äº† LCEL æä¾›çš„æ‰€æœ‰èƒ½åŠ›

#### RunnableLambda
RunnableLambda æ˜¯ä¸€ä¸ªâ€œé€‚é…å™¨â€æˆ–â€œåŒ…è£…å™¨â€ï¼Œå®ƒå¯ä»¥å°†ä»»ä½•æ™®é€šçš„ Python å‡½æ•°æˆ– lambda è¡¨è¾¾å¼è½¬æ¢æˆä¸€ä¸ªæ ‡å‡†çš„ Runnable å¯¹è±¡ã€‚è¿™ä¸ºä½ æ‰“å¼€äº†ä¸€æ‰‡å¤§é—¨ï¼Œè®©ä½ å¯ä»¥åœ¨ LCEL é“¾ä¸­æ‰§è¡Œä»»æ„çš„è‡ªå®šä¹‰é€»è¾‘ã€‚

#### RunnableParallel (æˆ– RunnableMap)

RunnableParallelï¼ˆé€šå¸¸é€šè¿‡å­—å…¸å­—é¢é‡éšå¼åˆ›å»ºï¼Œæ‰€ä»¥ä¹Ÿå¸¸è¢«ç§°ä¸º RunnableMapï¼‰æ˜¯ä¸€ä¸ªç‰¹æ®Šçš„ Runnableï¼Œå®ƒå…è®¸ä½ å¹¶è¡Œæ‰§è¡Œå¤šä¸ª Runnableï¼Œå¹¶å°†å®ƒä»¬çš„ç»“æœèšåˆåˆ°ä¸€ä¸ªå­—å…¸ä¸­ã€‚
å®ƒçš„ä¸»è¦ä½œç”¨æ˜¯ **â€œæ‰‡å‡º/æ‰‡å…¥â€ï¼ˆFan-out/Fan-inï¼‰**ï¼šå°†ä¸€ä¸ªè¾“å…¥åŒæ—¶åˆ†å‘ç»™å¤šä¸ªå¤„ç†åˆ†æ”¯ï¼ˆæ‰‡å‡ºï¼‰ï¼Œç„¶åå°†æ¯ä¸ªåˆ†æ”¯çš„ç»“æœæ”¶é›†åˆ°ä¸€ä¸ªæ–°çš„å­—å…¸é‡Œï¼ˆæ‰‡å…¥ï¼‰ã€‚
```
parallel_chain = {
    "original_topic": lambda x: x["topic"], # æå–åŸå§‹ topic
    "generated_fact": chain_a,             # æ‰§è¡Œ chain_a
    "passthrough_input": RunnablePassthrough() # ä¼ é€’æ•´ä¸ªåŸå§‹è¾“å…¥
}
```

ä»–å¯ä»¥ä¼ å…¥runnableå¯¹è±¡æˆ–è€…æ™®é€šå‡½æ•°ï¼Œæ™®é€šå‡½æ•°ä¼šåœ¨å†…éƒ¨è¢«è‡ªåŠ¨è½¬æ¢ä¸º RunnableLambda å¯¹è±¡ã€‚


#### LangChain è¡¨è¾¾å¼è¯­è¨€ (LCEL) - æ–°ä¸€ä»£é“¾æ„å»ºæ–¹æ³•

LCEL æ˜¯ç›®å‰æ„å»ºé“¾çš„**é¦–é€‰æ–¹å¼**ã€‚å®ƒä½¿ç”¨ç®¡é“ç¬¦ `|` æ¥è¿æ¥ç»„ä»¶ï¼Œè¯­æ³•æ›´ç®€æ´ï¼Œå¹¶ä¸”åŸç”Ÿæ”¯æŒæµå¼å¤„ç†ã€æ‰¹å¤„ç†å’Œå¼‚æ­¥è°ƒç”¨ã€‚

**ä»£ç å®ä¾‹ (LCEL):**

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# 1. å®šä¹‰æç¤ºã€æ¨¡å‹å’Œè¾“å‡ºè§£æå™¨
prompt = ChatPromptTemplate.from_template("å†™ä¸€ä¸ªå…³äº {topic} çš„çŸ­ç¬‘è¯ã€‚")
model = ChatOpenAI()
output_parser = StrOutputParser()

# 2. ä½¿ç”¨ LCEL ç®¡é“ç¬¦ | ç»„åˆæˆé“¾
chain = prompt | model | output_parser

# 3. è°ƒç”¨é“¾
response = chain.invoke({"topic": "ç¨‹åºå‘˜"})
print(response)
# è¾“å‡º: ä¸ºä»€ä¹ˆç¨‹åºå‘˜æ€»æ˜¯æŠŠä¸‡åœ£èŠ‚å’Œåœ£è¯èŠ‚ææ··ï¼Ÿå› ä¸º OCT 31 == DEC 25ï¼
```

### 4.2 é¡ºåºé“¾ (Sequential Chains)

å°†å¤šä¸ªé“¾æŒ‰é¡ºåºè¿æ¥èµ·æ¥ï¼Œå‰ä¸€ä¸ªé“¾çš„è¾“å‡ºä½œä¸ºåä¸€ä¸ªé“¾çš„è¾“å…¥ã€‚

#### å‰è€…è¾“å‡ºä¸ºç›´æ¥ä½œä¸ºåè€…è¾“å…¥çš„

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# é“¾1: æ ¹æ®ä¸»é¢˜ç”Ÿæˆä¸€ä¸ªå‰§æœ¬æ ‡é¢˜
prompt1 = ChatPromptTemplate.from_template("ç»™æˆ‘ä¸€ä¸ªå…³äº {topic} çš„å¥‡å¹»å‰§æœ¬æ ‡é¢˜ã€‚")
model = ChatOpenAI()
chain1 = prompt1 | model | StrOutputParser()

# é“¾2: æ ¹æ®å‰§æœ¬æ ‡é¢˜å†™ä¸€ä¸ªç®€ä»‹
prompt2 = ChatPromptTemplate.from_template("ä¸ºå‰§æœ¬ã€Š{title}ã€‹å†™ä¸€ä¸ª20å­—çš„ç®€ä»‹ã€‚")
chain2 = prompt2 | model | StrOutputParser()

# ç»„åˆæˆé¡ºåºé“¾ ç›´æ¥è¿æ¥å³å¯
sequential_chain = chain1 | chain2

response = sequential_chain.invoke({"topic": "æ—¶é—´æ—…è¡Œçš„çŒ«"})
print(response)
# è¾“å‡º: ä¸€åªå¤åŸƒåŠçš„çŒ«æ„å¤–ç©¿è¶Šåˆ°æœªæ¥ï¼Œå¿…é¡»åœ¨ç§‘æŠ€éƒ½å¸‚ä¸­æ‰¾åˆ°å›å®¶çš„è·¯ã€‚
```
#### å‰è€…è¾“å‡ºä½œä¸ºåè€…çš„éƒ¨åˆ†è¾“å…¥
æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°æ¥è°ƒæ§è¿™ä¸€è¡Œä¸ºã€‚
```python
import os
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser
from langchain_core.runnables import RunnableLambda,RunnableSequence, RunnableParallel,RunnablePassthrough
from base import  llm

# --- é“¾ A: ä¿¡æ¯ç”Ÿæˆå™¨ ---
# æç¤ºè¯ï¼Œè¦æ±‚ LLM è¾“å‡º JSON
prompt_a = ChatPromptTemplate.from_template(
    "è¯·ä¸ºä¸»é¢˜ '{topic}' æä¾›ä¸€ä¸ªæœ‰è¶£çš„äº‹å®å’Œä¸€ä¸ªç›¸å…³çš„æ´»åŠ¨ã€‚ä»¥ JSON æ ¼å¼è¿”å›ï¼ŒåŒ…å« 'fact' å’Œ 'activity' é”®ã€‚"
)
# é“¾ A = æç¤ºè¯ | LLM | JSONè§£æå™¨
chain_a = prompt_a | llm | JsonOutputParser()

# --- é“¾ B: ç¿»è¯‘å™¨ ---
# æç¤ºè¯ï¼Œæ¥æ”¶ 'text_to_translate' å˜é‡
prompt_b = ChatPromptTemplate.from_template(
    "è¯·å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ï¼š\n{text_to_translate}"
)

chain_b = prompt_b | llm | StrOutputParser()


full_chain = chain_a | RunnableLambda(lambda x: chain_b.invoke(x['fact'])) 
# --- è¿è¡Œå®Œæ•´çš„é“¾ ---
topic_to_analyze = "å’–å•¡"
print(f"å¼€å§‹å¤„ç†ä¸»é¢˜: {topic_to_analyze}\n")
final_result = full_chain.invoke({"topic": topic_to_analyze})
print("\n=====================")
print("æœ€ç»ˆçš„ç¿»è¯‘ç»“æœ:")
print(final_result)

#
```

è¾“å‡º
```

å¼€å§‹å¤„ç†ä¸»é¢˜: å’–å•¡

=====================
æœ€ç»ˆçš„ç¿»è¯‘ç»“æœ:
Coffee is the second most traded commodity in the world, after oil.
```

åŒæ—¶æˆ‘ä»¬è¿˜å¯ä»¥é‡‡ç”¨RunnableMapæ¥å¤„ç†è¿™ä¸€è¡Œä¸º
```python
import os
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser
from langchain_core.runnables import RunnableLambda
from base import  llm

# --- é“¾ A: ä¿¡æ¯ç”Ÿæˆå™¨ ---
# æç¤ºè¯ï¼Œè¦æ±‚ LLM è¾“å‡º JSON
prompt_a = ChatPromptTemplate.from_template(
    "è¯·ä¸ºä¸»é¢˜ '{topic}' æä¾›ä¸€ä¸ªæœ‰è¶£çš„äº‹å®å’Œä¸€ä¸ªç›¸å…³çš„æ´»åŠ¨ã€‚ä»¥ JSON æ ¼å¼è¿”å›ï¼ŒåŒ…å« 'fact' å’Œ 'activity' é”®ã€‚"
)
# é“¾ A = æç¤ºè¯ | LLM | JSONè§£æå™¨
chain_a = prompt_a | llm | JsonOutputParser()

# --- é“¾ B: ç¿»è¯‘å™¨ ---
# æç¤ºè¯ï¼Œæ¥æ”¶ 'text_to_translate' å˜é‡
prompt_b = ChatPromptTemplate.from_template(
    "è¯·å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ï¼š\n{text_to_translate}"
)
chain_b = prompt_b | llm | StrOutputParser()
chain_c={'out_put': lambda x :chain_b.invoke(x['fact'])}
full_chain = chain_a | chain_c
# --- è¿è¡Œå®Œæ•´çš„é“¾ ---
topic_to_analyze = "å’–å•¡"
print(f"å¼€å§‹å¤„ç†ä¸»é¢˜: {topic_to_analyze}\n")
final_result = full_chain.invoke({"topic": topic_to_analyze})

```
è¾“å‡º
```
å¼€å§‹å¤„ç†ä¸»é¢˜: å’–å•¡
=====================
æœ€ç»ˆçš„ç¿»è¯‘ç»“æœ:
{'out_put': 'Coffee is the second most traded commodity in the world, after petroleum.  \n\n(Note: The translation uses "petroleum" as it is the more precise term for crude oil in commodity trading contexts, though "oil" could also be used colloquially. The structure mirrors the original\'s emphasis on ranking while maintaining clarity.)'}

```

å¯ä»¥çœ‹åˆ°å‰è€…æ˜¯ç›´æ¥è¿”å›çš„è¾“å‡ºå†…å®¹ï¼Œè€Œåè€…è¿”å›ä¸€ä¸ªå­—å…¸



#### åè€…çš„è¾“å…¥è¦æ±‚ä¸åªå‰è€…çš„è¾“å‡ºï¼Œè¿˜è¦æ±‚å…¶ä»–è¾“å…¥ï¼ˆä¾‹å¦‚åˆå§‹ä¿¡æ¯ï¼Œæˆ–è€…ä¹‹å‰é“¾çš„æŸäº›è¾“å‡ºï¼‰

**å®ä¾‹ä»£ç -Langchain**

```python
import os
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser
from langchain_core.runnables import RunnableLambda, RunnablePassthrough
from base import llm

# --- é“¾ A: ç›®çš„åœ°åˆ†æå™¨ ---
prompt_a = ChatPromptTemplate.from_template(
    "å»åŸå¸‚ '{city}' æ—…æ¸¸çš„æœ€ä½³å­£èŠ‚æ˜¯ä»€ä¹ˆï¼Ÿä»¥ JSON æ ¼å¼è¿”å›ï¼ŒåªåŒ…å« 'best_season' é”®ã€‚"
)
chain_a = prompt_a | llm | JsonOutputParser()

# --- é“¾ B: æ´»åŠ¨ç”Ÿæˆå™¨ ---
prompt_b = ChatPromptTemplate.from_template(
    "åœ¨ '{season}' çš„ '{city}'ï¼Œæ¨èä¸€é¡¹ç‰¹è‰²æ´»åŠ¨ã€‚ä»¥ JSON æ ¼å¼è¿”å›ï¼ŒåªåŒ…å« 'activity' é”®ã€‚"
)
chain_b = prompt_b | llm | JsonOutputParser()

# --- é“¾ C: è¡Œç¨‹æ€»ç»“å™¨ ---
prompt_c = ChatPromptTemplate.from_template(
    "ä¸ºæˆ‘åˆ¶å®šä¸€ä»½å» '{original_city}' çš„ç®€çŸ­æ—…è¡Œå»ºè®®ã€‚\n"
    "æœ€ä½³å­£èŠ‚æ˜¯: {travel_season}\n"
    "æ¨èæ´»åŠ¨æ˜¯: {recommended_activity}"
)
chain_c = prompt_c | llm | StrOutputParser()


# --- ç»„è£…å®Œæ•´çš„é¡ºåºé“¾ (æœ€å…³é”®çš„éƒ¨åˆ†) ---

# ç¬¬ä¸€æ­¥ï¼šæ‰§è¡Œé“¾ Aï¼Œå¹¶ä¿ç•™åŸå§‹è¾“å…¥
chain_step1 = {
    "original_input": RunnablePassthrough(), # æºå¸¦ {"city": "..."}
    "chain_a_output": chain_a,             # æ‰§è¡Œé“¾ A
}

# ç¬¬äºŒæ­¥ï¼šå‡†å¤‡é“¾ B çš„è¾“å…¥ï¼Œå¹¶æ‰§è¡Œé“¾ Bï¼ŒåŒæ—¶ä¿ç•™ç¬¬ä¸€æ­¥çš„æ‰€æœ‰ä¿¡æ¯
chain_step2 = {
    # å†æ¬¡ä½¿ç”¨ RunnablePassthroughï¼Œè¿™æ¬¡å®ƒæºå¸¦çš„æ˜¯ chain_step1 çš„å®Œæ•´è¾“å‡º
    "previous_info": RunnablePassthrough(),
    # ä»ä¸Šä¸€æ­¥çš„ç»“æœä¸­æå–æ•°æ®æ¥è°ƒç”¨ chain_b
    "chain_b_output": lambda x: chain_b.invoke({
        "city": x["original_input"]["city"],
        "season": x["chain_a_output"]["best_season"]
    })
}

# ç¬¬ä¸‰æ­¥ï¼šæœ€ç»ˆçš„æ•°æ®æ•´ç†å’Œè°ƒç”¨é“¾ C
full_chain = (
    chain_step1
    | chain_step2
    | RunnableLambda(
        # è¿™ä¸ª lambda çš„è¾“å…¥æ˜¯ chain_step2 çš„è¾“å‡ºï¼Œä¸€ä¸ªåŒ…å«äº†æ‰€æœ‰å†å²ä¿¡æ¯çš„åµŒå¥—å­—å…¸
        # x çš„ç»“æ„: {'previous_info': {'original_input': ..., 'chain_a_output': ...}, 'chain_b_output': ...}
        lambda x: {
            "original_city": x["previous_info"]["original_input"]["city"],
            "travel_season": x["previous_info"]["chain_a_output"]["best_season"],
            "recommended_activity": x["chain_b_output"]["activity"],
        }
    )
    | chain_c
)


# --- è¿è¡Œå®Œæ•´çš„é“¾ ---
city_to_plan = "äº¬éƒ½"
print(f"å¼€å§‹ä¸ºåŸå¸‚ '{city_to_plan}' åˆ¶å®šæ—…è¡Œè®¡åˆ’...\n")

final_result = full_chain.invoke({"city": city_to_plan})

print("\n=====================")
print("æœ€ç»ˆçš„æ—…è¡Œå»ºè®®:")
print(final_result)
```
åœ¨è¿™éƒ¨åˆ†ä»£ç ä¸­æ•°æ®çš„ä¼ é€’é‡‡ç”¨çš„æ˜¯`RunnablePassthrough` è¿™ä¸ªå‡½æ•°çš„ä½œç”¨å°±æ˜¯å°†å½“å‰çš„è¾“å…¥ä½œä¸ºè¾“å‡ºä¼ é€’ç»™ä¸‹ä¸€ä¸ªé“¾ã€‚è¿™æ ·å¯ä»¥ç¡®ä¿åœ¨æ¯ä¸ªæ­¥éª¤ä¸­éƒ½èƒ½è®¿é—®åˆ°ä¹‹å‰çš„æ‰€æœ‰ä¿¡æ¯ã€‚

ä»£ç å®ä¾‹-Langgraph

```python
import os
from typing import TypedDict

# ä» langgraph åº“å¯¼å…¥æ ¸å¿ƒç»„ä»¶
from langgraph.graph import StateGraph, END

# ä» langchain åº“å¯¼å…¥æ‰€éœ€ç»„ä»¶
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser
from base import llm



# --- 2. å®šä¹‰å›¾çš„çŠ¶æ€ (State) ---
# è¿™æ˜¯ LangGraph çš„æ ¸å¿ƒã€‚æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªä¸­å¿ƒåŒ–çš„â€œçŠ¶æ€â€å¯¹è±¡ï¼Œ
# å®ƒå°†åƒä¸€ä¸ªå…±äº«çš„ç™½æ¿ä¸€æ ·ï¼Œåœ¨å›¾çš„å„ä¸ªèŠ‚ç‚¹ä¹‹é—´ä¼ é€’å’Œæ›´æ–°ã€‚

class TravelPlanState(TypedDict):
    """
    å®šä¹‰å›¾çš„çŠ¶æ€ï¼Œå®ƒå°†åŒ…å«æ‰€æœ‰éœ€è¦çš„ä¿¡æ¯ã€‚

    Attributes:
        city: åˆå§‹è¾“å…¥çš„åŸå¸‚åç§°ã€‚
        best_season: ç”±èŠ‚ç‚¹Aç”Ÿæˆçš„æœ€ä½³å­£èŠ‚ã€‚
        activity: ç”±èŠ‚ç‚¹Bç”Ÿæˆçš„æ¨èæ´»åŠ¨ã€‚
        final_plan: ç”±èŠ‚ç‚¹Cç”Ÿæˆçš„æœ€ç»ˆæ—…è¡Œå»ºè®®ã€‚
    """
    city: str
    best_season: str
    activity: str
    final_plan: str


# --- 3. å°†åŸæœ‰çš„é“¾åŒ…è£…æˆå›¾çš„èŠ‚ç‚¹ (Nodes) ---
# æ¯ä¸ªç‹¬ç«‹çš„é€»è¾‘å•å…ƒéƒ½å°†è¢«å°è£…æˆä¸€ä¸ªå›¾çš„èŠ‚ç‚¹ã€‚
# æ¯ä¸ªèŠ‚ç‚¹éƒ½æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œå®ƒæ¥æ”¶å½“å‰çš„çŠ¶æ€ï¼Œæ‰§è¡Œå…¶ä»»åŠ¡ï¼Œ
# ç„¶åè¿”å›ä¸€ä¸ªåŒ…å«è¦æ›´æ–°çš„çŠ¶æ€å­—æ®µçš„å­—å…¸ã€‚

def analyze_destination(state: TravelPlanState):
    """èŠ‚ç‚¹ A: ç›®çš„åœ°åˆ†æå™¨ï¼Œè´Ÿè´£å¡«å…… 'best_season' å­—æ®µã€‚"""
    print("--- æ­£åœ¨æ‰§è¡ŒèŠ‚ç‚¹: ç›®çš„åœ°åˆ†æå™¨ ---")
    prompt_a = ChatPromptTemplate.from_template(
        "å»åŸå¸‚ '{city}' æ—…æ¸¸çš„æœ€ä½³å­£èŠ‚æ˜¯ä»€ä¹ˆï¼Ÿä»¥ JSON æ ¼å¼è¿”å›ï¼ŒåªåŒ…å« 'best_season' é”®ã€‚"
    )
    chain_a = prompt_a | llm | JsonOutputParser()

    city = state["city"]
    result = chain_a.invoke({"city": city})

    # è¿”å›ä¸€ä¸ªå­—å…¸ï¼ŒæŒ‡æ˜è¦æ›´æ–°çŠ¶æ€ä¸­çš„å“ªä¸ªå­—æ®µ
    return {"best_season": result["best_season"]}


def generate_activity(state: TravelPlanState):
    """èŠ‚ç‚¹ B: æ´»åŠ¨ç”Ÿæˆå™¨ï¼Œè´Ÿè´£å¡«å…… 'activity' å­—æ®µã€‚"""
    print("--- æ­£åœ¨æ‰§è¡ŒèŠ‚ç‚¹: æ´»åŠ¨ç”Ÿæˆå™¨ ---")
    prompt_b = ChatPromptTemplate.from_template(
        "åœ¨ '{season}' çš„ '{city}'ï¼Œæ¨èä¸€é¡¹ç‰¹è‰²æ´»åŠ¨ã€‚ä»¥ JSON æ ¼å¼è¿”å›ï¼ŒåªåŒ…å« 'activity' é”®ã€‚"
    )
    chain_b = prompt_b | llm | JsonOutputParser()

    city = state["city"]
    season = state["best_season"]  # ç›´æ¥ä»çŠ¶æ€ä¸­è¯»å–ä¸Šä¸€æ­¥çš„ç»“æœ
    result = chain_b.invoke({"city": city, "season": season})

    return {"activity": result["activity"]}


def summarize_plan(state: TravelPlanState):
    """èŠ‚ç‚¹ C: è¡Œç¨‹æ€»ç»“å™¨ï¼Œè´Ÿè´£å¡«å…… 'final_plan' å­—æ®µã€‚"""
    print("--- æ­£åœ¨æ‰§è¡ŒèŠ‚ç‚¹: è¡Œç¨‹æ€»ç»“å™¨ ---")
    prompt_c = ChatPromptTemplate.from_template(
        "ä¸ºæˆ‘åˆ¶å®šä¸€ä»½å» '{original_city}' çš„ç®€çŸ­æ—…è¡Œå»ºè®®ã€‚\n"
        "æœ€ä½³å­£èŠ‚æ˜¯: {travel_season}\n"
        "æ¨èæ´»åŠ¨æ˜¯: {recommended_activity}"
    )
    chain_c = prompt_c | llm | StrOutputParser()

    # ç›´æ¥ä»çŠ¶æ€ä¸­è¯»å–æ‰€æœ‰éœ€è¦çš„ä¿¡æ¯ï¼Œæ— éœ€å¤æ‚çš„ä¼ é€’
    result = chain_c.invoke({
        "original_city": state["city"],
        "travel_season": state["best_season"],
        "recommended_activity": state["activity"]
    })

    return {"final_plan": result}


# --- 4. æ„å»ºå›¾ (Graph) ---
# ç°åœ¨ï¼Œæˆ‘ä»¬å°†å®šä¹‰å¥½çš„çŠ¶æ€å’ŒèŠ‚ç‚¹ç»„è£…æˆä¸€ä¸ªå·¥ä½œæµå›¾ã€‚

# 4.1 åˆå§‹åŒ–ä¸€ä¸ªçŠ¶æ€å›¾ï¼Œå¹¶å‘Šè¯‰å®ƒæˆ‘ä»¬çš„çŠ¶æ€ç»“æ„
workflow = StateGraph(TravelPlanState)

# 4.2 å°†æˆ‘ä»¬å®šä¹‰çš„å‡½æ•°æ·»åŠ ä¸ºå›¾ä¸­çš„èŠ‚ç‚¹
workflow.add_node("analyzer", analyze_destination)
workflow.add_node("activity_generator", generate_activity)
workflow.add_node("summarizer", summarize_plan)

# 4.3 å®šä¹‰èŠ‚ç‚¹ä¹‹é—´çš„è¿æ¥å…³ç³»ï¼ˆè¾¹ï¼‰ï¼Œè¿™å†³å®šäº†æ‰§è¡Œçš„é¡ºåº
workflow.set_entry_point("analyzer")  # è®¾ç½®å…¥å£èŠ‚ç‚¹
workflow.add_edge("analyzer", "activity_generator")
workflow.add_edge("activity_generator", "summarizer")
workflow.add_edge("summarizer", END)  # 'summarizer' æ˜¯æœ€åä¸€ä¸ªèŠ‚ç‚¹ï¼Œæ‰§è¡Œå®Œåç»“æŸ

# 4.4 ç¼–è¯‘å›¾ï¼Œç”Ÿæˆä¸€ä¸ªå¯æ‰§è¡Œçš„åº”ç”¨
app = workflow.compile()

# --- 5. è¿è¡Œ LangGraph åº”ç”¨ ---

if __name__ == "__main__":
    city_to_plan = "äº¬éƒ½"
    print(f"å¼€å§‹ä¸ºåŸå¸‚ '{city_to_plan}' åˆ¶å®šæ—…è¡Œè®¡åˆ’...\n")

    # åˆå§‹è¾“å…¥åªéœ€è¦æä¾›çŠ¶æ€ä¸­ç¬¬ä¸€ä¸ªèŠ‚ç‚¹éœ€è¦çš„å­—æ®µ
    initial_state = {"city": city_to_plan}

    # è°ƒç”¨å›¾ï¼Œå®ƒä¼šä»å…¥å£èŠ‚ç‚¹å¼€å§‹ï¼ŒæŒ‰ç…§æˆ‘ä»¬å®šä¹‰çš„è¾¹é¡ºåºæ‰§è¡Œ
    # .invoke() ä¼šè¿”å›æœ€ç»ˆçš„çŠ¶æ€å¯¹è±¡
    final_state = app.invoke(initial_state)

    print("\n=====================")
    print("æœ€ç»ˆçš„æ—…è¡Œå»ºè®®:")
    # æœ€ç»ˆçš„ç»“æœå­˜å‚¨åœ¨è¿”å›çš„çŠ¶æ€å¯¹è±¡çš„ 'final_plan' å­—æ®µä¸­
    print(final_state.get("final_plan", "æœªèƒ½ç”Ÿæˆè®¡åˆ’ã€‚"))

    # ä½ ä¹Ÿå¯ä»¥æ‰“å°æ•´ä¸ªæœ€ç»ˆçŠ¶æ€ï¼Œçœ‹çœ‹æ‰€æœ‰å­—æ®µæ˜¯å¦‚ä½•è¢«å¡«å……çš„
    print("\n--- æœ€ç»ˆçŠ¶æ€å¯¹è±¡ ---")
    print(final_state)
```
**å…¶å®å¯ä»¥çœ‹åˆ°æ¶‰åŠåˆ°åç»­chainéœ€è¦ä½¿ç”¨å‰é¢æ•°æ®çš„è¿™ç§é¡ºåºé“¾è¿æ¥å®Œå…¨ä½¿ç”¨langchainè¿æ¥æ˜¯å¤æ‚çš„ï¼Œå°¤å…¶æ¶‰åŠåˆ°æ¯æ¬¡çš„è¾“å…¥ä¿¡æ¯éƒ½å¯èƒ½åœ¨åé¢è¢«ç”¨åˆ°çš„æƒ…å†µ**

**æ‰€ä»¥è¿™æ—¶å€™æˆ‘ä»¬å°±å¯ä»¥é‡‡ç”¨Langgraphè¿›è¡Œæ„å»ºï¼ŒLangchainå¯ä»¥å°è£…ä¸€äº›ç®€å•çš„é¡ºåºé“¾å†ç»“åˆLanggraphä¼šååˆ†é¡ºç•…**



### 4.3 å¹¶è¡Œé“¾ (Parallel Chains)
#### Langchain
åœ¨langchainä¸­å®è¡Œå¹¶è¡Œä¹‹å‰å·²ç»è®²è¿‡å°±æ˜¯ `RunnableParallel` ä»–ä¼šå¹¶è¡Œæ‰§è¡Œå¤šä¸ª Runnableï¼Œå¹¶å°†ç»“æœèšåˆåˆ°ä¸€ä¸ªå­—å…¸ä¸­ã€‚æˆ‘å°±ä¸åœ¨é‡ç‚¹ä»‹ç»äº†ã€‚

#### Langgraph

åœ¨langgraphä¸­æ‰€æœ‰çš„é“¾å…¶å®éƒ½æ˜¯é€šè¿‡èŠ‚ç‚¹è¿æ¥èµ·æ¥çš„

```python
import os
from typing import TypedDict, List, Optional
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langgraph.graph import StateGraph, END
from base import llm


# --- 1. å®šä¹‰çŠ¶æ€ (State) ---
# çŠ¶æ€æ˜¯å›¾åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­ä¼ é€’çš„æ•°æ®ç»“æ„ã€‚
# æ¯ä¸ªèŠ‚ç‚¹éƒ½ä¼šæ¥æ”¶å½“å‰çŠ¶æ€ï¼Œå¹¶å¯ä»¥è¿”å›ä¸€ä¸ªæ›´æ–°åçš„çŠ¶æ€ã€‚
class GraphState(TypedDict):
    original_question: str  # ç”¨æˆ·çš„åŸå§‹é—®é¢˜
    summary: Optional[str]  # æ€»ç»“èŠ‚ç‚¹çš„ç»“æœ
    keywords: Optional[str] # å…³é”®è¯èŠ‚ç‚¹çš„ç»“æœ
    translation: Optional[str] # ç¿»è¯‘èŠ‚ç‚¹çš„ç»“æœ
    final_result: Optional[str] # èšåˆèŠ‚ç‚¹çš„æœ€ç»ˆç»“æœ


# æ€»ç»“é“¾
summarizer_prompt = ChatPromptTemplate.from_template("è¯·ç”¨ä¸€å¥è¯æ€»ç»“ä»¥ä¸‹æ–‡æœ¬ï¼š\n\n{text}")
summarizer_chain = summarizer_prompt | llm | StrOutputParser()

# å…³é”®è¯é“¾
keywords_prompt = ChatPromptTemplate.from_template("è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–3ä¸ªæ ¸å¿ƒå…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”ï¼š\n\n{text}")
keywords_chain = keywords_prompt | llm | StrOutputParser()

# ç¿»è¯‘é“¾
translator_prompt = ChatPromptTemplate.from_template("è¯·å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ï¼š\n\n{text}")
translator_chain = translator_prompt | llm | StrOutputParser()


# --- 3. å®šä¹‰å›¾çš„èŠ‚ç‚¹ (Nodes) ---
# æ¯ä¸ªèŠ‚ç‚¹éƒ½æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œæ¥æ”¶ state ä½œä¸ºè¾“å…¥ï¼Œè¿”å›ä¸€ä¸ªåŒ…å«çŠ¶æ€æ›´æ–°çš„å­—å…¸ã€‚

def start_node(state: GraphState):
    """
    èµ·å§‹èŠ‚ç‚¹ï¼Œæ‰“å°ä¸€æ¡æ¶ˆæ¯è¡¨ç¤ºå·¥ä½œæµå¼€å§‹ã€‚
    å®ƒä¸ä¿®æ”¹çŠ¶æ€ï¼Œåªæ˜¯ä½œä¸ºæµç¨‹çš„å…¥å£ã€‚
    """
    print("--- å·¥ä½œæµå¼€å§‹ ---")
    # åŸå§‹é—®é¢˜å·²ç»é€šè¿‡ .invoke() çš„è¾“å…¥ä¼ å…¥äº† state
    return {}

def summarize_node(state: GraphState):
    """
    æ€»ç»“èŠ‚ç‚¹ï¼šè°ƒç”¨æ€»ç»“é“¾å¹¶æ›´æ–°çŠ¶æ€ã€‚
    """
    print("...æ­£åœ¨æ‰§è¡Œæ€»ç»“ä»»åŠ¡...")
    question = state["original_question"]
    summary_result = summarizer_chain.invoke({"text": question})
    return {"summary": summary_result}

def keywords_node(state: GraphState):
    """
    å…³é”®è¯èŠ‚ç‚¹ï¼šè°ƒç”¨å…³é”®è¯é“¾å¹¶æ›´æ–°çŠ¶æ€ã€‚
    """
    print("...æ­£åœ¨æ‰§è¡Œæå–å…³é”®è¯ä»»åŠ¡...")
    question = state["original_question"]
    keywords_result = keywords_chain.invoke({"text": question})
    return {"keywords": keywords_result}

def translate_node(state: GraphState):
    """
    ç¿»è¯‘èŠ‚ç‚¹ï¼šè°ƒç”¨ç¿»è¯‘é“¾å¹¶æ›´æ–°çŠ¶æ€ã€‚
    """
    print("...æ­£åœ¨æ‰§è¡Œç¿»è¯‘ä»»åŠ¡...")
    question = state["original_question"]
    translation_result = translator_chain.invoke({"text": question})
    return {"translation": translation_result}

def aggregator_node(state: GraphState):
    """
    èšåˆèŠ‚ç‚¹ï¼šç­‰å¾…æ‰€æœ‰å¹¶è¡Œåˆ†æ”¯å®Œæˆåï¼Œæ±‡æ€»ç»“æœã€‚
    """
    print("--- æ­£åœ¨èšåˆæ‰€æœ‰ç»“æœ ---")
    summary = state.get("summary", "æ— æ€»ç»“")
    keywords = state.get("keywords", "æ— å…³é”®è¯")
    translation = state.get("translation", "æ— ç¿»è¯‘")

    final_report = f"""
## å¹¶è¡Œä»»åŠ¡å¤„ç†æŠ¥å‘Š

**åŸå§‹æ–‡æœ¬**: {state['original_question']}

---

### 1. æ–‡æœ¬æ‘˜è¦
{summary}

---

### 2. æ ¸å¿ƒå…³é”®è¯
{keywords}

---

### 3. è‹±æ–‡ç¿»è¯‘
{translation}
"""
    return {"final_result": final_report}


# --- 4. æ„å»ºå›¾ (Graph) ---
workflow = StateGraph(GraphState)

# æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹
workflow.add_node("start", start_node)
workflow.add_node("summarize", summarize_node)
workflow.add_node("keywords", keywords_node)
workflow.add_node("translate", translate_node)
workflow.add_node("aggregator", aggregator_node)

# è®¾ç½®å…¥å£ç‚¹
workflow.set_entry_point("start")

# æ·»åŠ è¾¹
# **å…³é”®ç‚¹**: ä» 'start' èŠ‚ç‚¹åˆ°ä¸‰ä¸ªå¹¶è¡ŒèŠ‚ç‚¹çš„è¾¹ã€‚
# å°†è¾¹çš„ç›®æ ‡è®¾ç½®ä¸ºä¸€ä¸ªåˆ—è¡¨ï¼ŒLangGraph ä¼šè‡ªåŠ¨å¹¶è¡Œæ‰§è¡Œåˆ—è¡¨ä¸­çš„æ‰€æœ‰èŠ‚ç‚¹ã€‚
for node in ["summarize", "keywords", "translate"]:
    workflow.add_edge("start", node)
    workflow.add_edge(node, "aggregator")


# å°†èšåˆèŠ‚ç‚¹è¿æ¥åˆ°ç»ˆç‚¹
workflow.add_edge("aggregator", END)

# ç¼–è¯‘å›¾
app = workflow.compile()

```
è¿™æ˜¯æ•´ä¸ªå›¾ç»“æ„
![](parallel_graph.png)

è™½ç„¶ä¸Šè¿°ä¸¤ç§æ–¹æ³•éƒ½å®ç°äº†é“¾çš„å¹¶è¡Œï¼Œä½†æ˜¯å„è‡ªä¼˜ç¼ºç‚¹æ˜æ˜¾
* langchainç»“æ„ç®€å•ï¼Œæ–¹ä¾¿æ„å»ºï¼Œåªéœ€è¦æ„å»ºä¸€ä¸ªå­—å…¸ä¼ å…¥ä¸€ä¸ªrunnableå¯¹è±¡æˆ–è€…å¯è°ƒç”¨å‡½æ•°å³å¯ã€‚
* langgraphè™½ç„¶æ„å»ºéº»çƒ¦ï¼Œä½†æ˜¯ç”±äºå„ä¸ªå¹¶è¡Œå‡½æ•°æ˜¯ä»¥èŠ‚ç‚¹çš„å½¢å¼å­˜åœ¨çš„ï¼Œä»–å¯ä»¥æ›´æ–°çŠ¶æ€ï¼Œå¹¶ä¸”é€šè¿‡streamæµå¯ä»¥è·å–å„ä¸ªå¹¶è¡Œå‡½æ•°çš„ç»“æœã€‚

* **æ€»ç»“ï¼š** å¦‚æœä½ çš„å¹¶è¡Œä»»åŠ¡ç®€å•ä¸”ä¸éœ€è¦ä¸å¤–éƒ¨è¿›è¡Œäº¤äº’ï¼ˆä¾‹å¦‚å‰åç«¯äº¤äº’ï¼‰é‚£ä¹ˆlangchainæ— ç–‘æ›´å¥½ï¼Œä½†æ˜¯å¦‚æœæ¶‰åŠåˆ°éœ€è¦å°†å¹¶è¡ŒèŠ‚ç‚¹çš„è¾“å‡ºå†…å®¹è¿›è¡Œå‘ä¸‹ä¼ è¾“é‚£ä¹ˆlanggraphæ›´å¥½
* å½“ç„¶åœ¨å®é™…åº”ç”¨ä¸­æˆ‘ä»¬éœ€è¦ç»„åˆä½¿ç”¨è¿™ä¸¤ç§æ–¹æ³•æ¥è¿›è¡Œæ„å»ºã€‚
### 4.4 å¾ªç¯é“¾-Langgraphç‰¹æœ‰ 
å¾ªç¯é“¾é“¾ä¸»è¦çš„ä½œç”¨åœ¨äº
* è‡ªæˆ‘ä¿®æ­£ä¸åæ€ï¼ˆä¾‹å¦‚å·¥å…·è°ƒç”¨ï¼Œæˆ–è€…å†³ç­–ï¼‰
* äººæœºäº¤äº’çš„å¤šè½®å¯¹è¯
#### è‡ªæˆ‘ä¿®æ­£ä¸åæ€
æˆ‘ä»¥å¯¹å·¥å…·è°ƒç”¨è¿›è¡Œæƒé™ç”³è¯·çš„é€»è¾‘ä¸ºä¾‹ï¼Œæ¥è¯´æ˜å¾ªç¯é“¾çš„ä½¿ç”¨ã€‚
```python
import os
from operator import add
from typing import TypedDict, List, Annotated
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage,SystemMessage
from langgraph.graph import StateGraph, END

from langchain_core.tools import tool
from base import llm

# --- 1. å®šä¹‰å·¥å…· (Tools) ---
# æˆ‘ä»¬å®šä¹‰ä¸¤ä¸ªå·¥å…·ï¼šä¸€ä¸ªç”¨äºç½‘ç»œæœç´¢ï¼Œä¸€ä¸ªç”¨äºè®¡ç®—ã€‚

# å·¥å…·1ï¼šç½‘ç»œæœç´¢
@tool
def search_tool(query: str) -> str:
    """ä½¿ç”¨ æœç´¢å·¥å…·è¿›è¡Œç½‘ç»œæœç´¢ã€‚"""
    print(f"--- æ­£åœ¨æ‰§è¡Œæœç´¢å·¥å…·: {query} ---")
    return 'å¤©æ°”æ™´æœ—'
#ä¸ºäº†æ–¹ä¾¿æˆ‘æ¨¡æ‹Ÿäº†ä¸€ä¸ªç½‘ç»œæœç´¢

# å·¥å…·2ï¼šä¸€ä¸ªç®€å•çš„ä¹˜æ³•è®¡ç®—å™¨
@tool
def multiply(a: int, b: int) -> int:
    """è®¡ç®—ä¸¤ä¸ªæ•´æ•°çš„ä¹˜ç§¯ã€‚"""
    print(f"--- æ­£åœ¨æ‰§è¡Œä¹˜æ³•å·¥å…·: {a} * {b} ---")
    return a * b


# å°†æ‰€æœ‰å·¥å…·æ”¾å…¥ä¸€ä¸ªåˆ—è¡¨
tools = [search_tool, multiply]
tools_name={k.name:k for k in tools}
print(tools_name)
# --- 2. å®šä¹‰çŠ¶æ€ (State) ---
# çŠ¶æ€éœ€è¦åŒ…å«å¯¹è¯å†å²å’Œä»»ä½•ä¸­é—´ç»“æœã€‚
class AgentState(TypedDict):
    messages: Annotated[List[BaseMessage],add]
    # æˆ‘ä»¬å¢åŠ ä¸€ä¸ªå­—æ®µæ¥è·Ÿè¸ªè¢«æ‹’ç»çš„å·¥å…·è°ƒç”¨ï¼Œä»¥ä¾¿Agentå¯ä»¥çŸ¥é“
    rejected_tool_calls: List[dict]


# --- 3. å®šä¹‰å›¾çš„èŠ‚ç‚¹ (Nodes) ---

# èŠ‚ç‚¹1: Agent èŠ‚ç‚¹ (è°ƒç”¨LLMè¿›è¡Œæ€è€ƒ)
# æˆ‘ä»¬å°†LLMå’Œå·¥å…·ç»‘å®šï¼Œä½¿å…¶èƒ½å¤Ÿç”Ÿæˆ tool_calls

llm_with_tools = llm.bind_tools(tools)

def agent_node(state: AgentState):
    """
    AgentèŠ‚ç‚¹ï¼šæ ¹æ®å½“å‰å¯¹è¯å†å²è¿›è¡Œæ€è€ƒï¼Œå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚
    """
    print("--- Agent æ­£åœ¨æ€è€ƒ... ---")
    response = llm_with_tools.invoke(state["messages"])
    # Agentçš„å“åº”æ˜¯ä¸€ä¸ªAIMessageï¼Œå®ƒä¼šè¢«è‡ªåŠ¨æ·»åŠ åˆ°çŠ¶æ€çš„messagesåˆ—è¡¨ä¸­
    return {"messages": [response]} #å› ä¸ºæˆ‘åœ¨stateä¸­è®¾ç½®çš„messageæ˜¯ä»¥addå½¢å¼çš„æ‰€ä»¥æ›´æ–°ç­–ç•¥æ˜¯è¿½åŠ è€Œéè¦†ç›–ï¼Œæ‰€ä»¥æˆ‘å¯ä»¥ç›´æ¥è¿”å›å½“å‰ä¿¡æ¯ï¼Œä¸ç”¨copyä¸€éè¿½åŠ å†è¿”å›
def human_approval_node(state: AgentState) -> dict:
    """
    æ£€æŸ¥æœ€æ–°çš„AIæ¶ˆæ¯æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨è¯·æ±‚ã€‚
    å¦‚æœæ˜¯ï¼Œåˆ™è¯·æ±‚äººå·¥æ‰¹å‡†ï¼Œå¹¶æ ¹æ®æ‰¹å‡†ç»“æœæ‰§è¡Œæˆ–ç”Ÿæˆæ‹’ç»æ¶ˆæ¯ã€‚
    è¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰ç»“æœçš„ ToolMessage åˆ—è¡¨ã€‚
    """
    print("--- ç­‰å¾…äººå·¥å®¡æ‰¹ ---")
    last_message = state["messages"][-1]
    # ç¡®ä¿æœ€åä¸€æ¡æ¶ˆæ¯æ˜¯å¸¦æœ‰å·¥å…·è°ƒç”¨çš„AIæ¶ˆæ¯
    if not isinstance(last_message, AIMessage) or not last_message.tool_calls:
        return {}

    tool_messages = []
    tool_dict = {tool.name: tool for tool in tools}

    for tool_call in last_message.tool_calls:##å¦‚æœå­˜åœ¨å·¥å…·è¯·æ±‚é‚£ä¹ˆè¿”å›çš„è¿™ä¸€ç»„ä¿¡æ¯å°±ä¼šå­˜åœ¨tool.calls(å¯èƒ½å­˜åœ¨å¤šä¸ªå·¥å…·è°ƒç”¨ï¼Œæ‰€ä»¥è¦ç”¨å¾ªç¯)
        tool_name = tool_call['name']#è·å–å½“å‰è°ƒç”¨å·¥å…·çš„åå­—
        tool_args = tool_call['args']#è·å–å½“å‰è°ƒç”¨å·¥å…·çš„å‚æ•°
        tool_to_run = tool_dict.get(tool_name)#è·å–å·¥å…·å¯¹è±¡

        prompt = f"Agent æƒ³è¦æ‰§è¡Œå·¥å…· '{tool_name}' (å‚æ•°: {tool_args})ã€‚\nä½ æ˜¯å¦æ‰¹å‡†ï¼Ÿ (yes/no): "
        user_input = input(prompt).lower() ##æˆ‘ç°åœ¨åœ¨æ¨¡æ‹Ÿæƒé™ç”³è¯·ï¼ŒçœŸæ­£çš„å‰åç«¯äº¤äº’æ—¶æ˜¯éœ€è¦ç”¨interruptçš„ï¼ˆåé¢ä¼šè®²åˆ°ï¼‰

        if user_input == 'yes' and tool_to_run:
            print(f"âœ… å·²æ‰¹å‡†å¹¶æ‰§è¡Œ: {tool_name}")
            try:
                # ç›´æ¥åœ¨è¿™é‡Œæ‰§è¡Œå·¥å…·
                result = tool_to_run.invoke(tool_args)
                tool_messages.append(
                    ToolMessage(
                        content=str(result), # ç¡®ä¿å†…å®¹æ˜¯å­—ç¬¦ä¸²
                        name=tool_name,
                        tool_call_id=tool_call["id"]
                    )
                )
            except Exception as e:
                print(f"å·¥å…· '{tool_name}' æ‰§è¡Œå‡ºé”™: {e}")
                tool_messages.append(
                    ToolMessage(
                        content=f"Error executing tool: {e}",
                        name=tool_name,
                        tool_call_id=tool_call["id"]
                    )
                )
        else:
            print(f"âŒ å·²æ‹’ç»æ‰§è¡Œ: {tool_name}")
            # ä¸ºè¢«æ‹’ç»çš„å·¥å…·åˆ›å»ºä¸€ä¸ªæ˜ç¡®çš„ ToolMessage
            rejected_content = f"User denied permission to run tool '{tool_name}'."
            tool_messages.append(
                ToolMessage(
                    content=rejected_content,
                    name=tool_name,
                    tool_call_id=tool_call["id"]
                )
            )
    # è¿”å›çš„ToolMessageåˆ—è¡¨ä¼šè¢«è‡ªåŠ¨æ·»åŠ åˆ°çŠ¶æ€çš„messagesåˆ—è¡¨ä¸­
    return {"messages": tool_messages}

# --- 4. å®šä¹‰æ¡ä»¶è¾¹/è·¯ç”±å™¨ (Router) ---
def router(state: AgentState):
    """
    å†³ç­–èŠ‚ç‚¹ï¼šåœ¨Agentæ€è€ƒåï¼Œå†³å®šæµç¨‹èµ°å‘ã€‚
    """
    print("--- æ­£åœ¨å†³ç­–... ---")
    last_message = state["messages"][-1]
    if isinstance(last_message, AIMessage) and last_message.tool_calls:
        # å¦‚æœæœ‰å·¥å…·è°ƒç”¨è¯·æ±‚ï¼Œåˆ™è¿›å…¥äººå·¥å®¡æ‰¹ç¯èŠ‚
        print("å†³ç­–ç»“æœ: éœ€è¦äººå·¥å®¡æ‰¹ã€‚")
        return "request_approval"
    else:
        # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼ˆæ„å‘³ç€Agentå‡†å¤‡ç›´æ¥å›ç­”ï¼‰ï¼Œåˆ™ç»“æŸæµç¨‹
        print("å†³ç­–ç»“æœ: æ— éœ€å·¥å…·ï¼Œæµç¨‹ç»“æŸã€‚")
        return END
    ##åœ¨è¿™æˆ‘è§£é‡Šä¸€ä¸‹ä¸ºä»€ä¹ˆæ²¡æœ‰å·¥å…·è°ƒç”¨å°±ä»£è¡¨ç€è¾“å‡ºå®Œæˆï¼Œå› ä¸ºåªæœ‰å½“æœ‰å·¥å…·è°ƒç”¨çš„æ—¶å€™ä¼šæ‰“æ–­æ¨¡å‹è¾“å‡ºï¼Œæ‰€ä»¥å½“æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œä½†ä»ç„¶èŠ‚ç‚¹è·³è½¬äº†å°±åªèƒ½æ˜¯è¾“å‡ºçœŸæ­£ç»“æŸäº†

# --- 5. æ„å»ºå›¾ (Graph) ---
workflow = StateGraph(AgentState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("agent", agent_node)
workflow.add_node("human_approval_and_execution", human_approval_node)

# è®¾ç½®å…¥å£ç‚¹
workflow.set_entry_point("agent")

# æ·»åŠ æ¡ä»¶è¾¹
workflow.add_conditional_edges(
    "agent",
    router,
    {
        "request_approval": "human_approval_and_execution",
        END: END
    }
)

# æ·»åŠ å¸¸è§„è¾¹ï¼Œå½¢æˆå¾ªç¯
# å®¡æ‰¹å’Œæ‰§è¡Œå -> è¿”å›Agentï¼Œè®©å®ƒçœ‹åˆ°æ‰€æœ‰å·¥å…·çš„ç»“æœï¼ˆåŒ…æ‹¬è¢«æ‹’ç»çš„ï¼‰
workflow.add_edge("human_approval_and_execution", "agent")

# ç¼–è¯‘å›¾
app = workflow.compile()

# --- 6. è¿è¡Œå’Œäº¤äº’ ---
config = {"recursion_limit": 100}
initial_messages = [HumanMessage(content="ä»Šå¤©åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿç„¶åè®¡ç®—ä¸€ä¸‹ 25 ä¹˜ä»¥ 8 çš„ç»“æœã€‚")]
thread = {"messages": initial_messages}

print("="*50)
print(f"ç”¨æˆ·é—®é¢˜: {initial_messages[0].content}")
print("="*50)

for event in app.stream(thread, config=config):
    for key, value in event.items():
        print(f"--- èŠ‚ç‚¹ '{key}' çš„è¾“å‡º ---")
        if "messages" in value:
            latest_messages = value["messages"]
            for msg in latest_messages:
                if isinstance(msg, AIMessage) and msg.content:
                     print(f"AI å›ç­”: {msg.content}")
                # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å¯¹å…¶ä»–æ¶ˆæ¯ç±»å‹çš„æ‰“å°ï¼Œç”¨äºè°ƒè¯•
                # print(f"  - {msg.pretty_repr()}")
        print("-" * 20)

```
```
{'search_tool': StructuredTool(name='search_tool', description='ä½¿ç”¨ æœç´¢å·¥å…·è¿›è¡Œç½‘ç»œæœç´¢ã€‚', args_schema=<class 'langchain_core.utils.pydantic.search_tool'>, func=<function search_tool at 0x111c60430>), 'multiply': StructuredTool(name='multiply', description='è®¡ç®—ä¸¤ä¸ªæ•´æ•°çš„ä¹˜ç§¯ã€‚', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x158b039a0>)}
==================================================
ç”¨æˆ·é—®é¢˜: ä»Šå¤©åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿç„¶åè®¡ç®—ä¸€ä¸‹ 25 ä¹˜ä»¥ 8 çš„ç»“æœã€‚
==================================================
--- Agent æ­£åœ¨æ€è€ƒ... ---
--- æ­£åœ¨å†³ç­–... ---
å†³ç­–ç»“æœ: éœ€è¦äººå·¥å®¡æ‰¹ã€‚
--- èŠ‚ç‚¹ 'agent' çš„è¾“å‡º ---
--------------------
--- ç­‰å¾…äººå·¥å®¡æ‰¹ ---
Agent æƒ³è¦æ‰§è¡Œå·¥å…· 'search_tool' (å‚æ•°: {'query': 'ä»Šå¤©åŒ—äº¬çš„å¤©æ°”'})ã€‚
ä½ æ˜¯å¦æ‰¹å‡†ï¼Ÿ (yes/no): no
âŒ å·²æ‹’ç»æ‰§è¡Œ: search_tool
Agent æƒ³è¦æ‰§è¡Œå·¥å…· 'multiply' (å‚æ•°: {'a': 25, 'b': 8})ã€‚
ä½ æ˜¯å¦æ‰¹å‡†ï¼Ÿ (yes/no): yes
âœ… å·²æ‰¹å‡†å¹¶æ‰§è¡Œ: multiply
--- æ­£åœ¨æ‰§è¡Œä¹˜æ³•å·¥å…·: 25 * 8 ---
--- èŠ‚ç‚¹ 'human_approval_and_execution' çš„è¾“å‡º ---
--------------------
--- Agent æ­£åœ¨æ€è€ƒ... ---
--- æ­£åœ¨å†³ç­–... ---
å†³ç­–ç»“æœ: æ— éœ€å·¥å…·ï¼Œæµç¨‹ç»“æŸã€‚
--- èŠ‚ç‚¹ 'agent' çš„è¾“å‡º ---
AI å›ç­”: ä»Šå¤©åŒ—äº¬çš„å¤©æ°”ä¿¡æ¯æ— æ³•è·å–ï¼Œå› ä¸ºæœç´¢æƒé™è¢«æ‹’ç»äº†ã€‚  

25 ä¹˜ä»¥ 8 çš„ç»“æœæ˜¯ 200ã€‚
--------------------
```
è¿™æ˜¯è¯¥å¾ªç¯é“¾çš„å·¥ä½œæµå›¾
![](cycle_workflow.png)
å½“agentèŠ‚ç‚¹ç»“æŸåä¼šè¿›å…¥æ¡ä»¶è¾¹åˆ¤æ–­æµè½¬ï¼Œå¦‚æœæ˜¯å·¥å…·è°ƒç”¨è¿›å…¥human_approval_nodeèŠ‚ç‚¹ï¼Œç„¶åæ‰§è¡Œå®Œæˆä¹‹åå°±ä¼šè¿”å›åˆ°agentèŠ‚ç‚¹ï¼ŒagentèŠ‚ç‚¹å°±ä¼šåˆ©ç”¨æœ€æ–°æ›´æ–°çš„messageå†æ¬¡è·‘ä¸€éllmç›´åˆ°è¾“å‡ºç»“æŸ

åœ¨human_approval_nodeä¸­ä½ å¯ä»¥å®ç°å„ç§ä½ æƒ³è¦çš„åŠŸèƒ½ä¾‹å¦‚æ‰“å°è°ƒè¯•ä¿¡æ¯æˆ–è€…å¯¹å·¥å…·è¾“å‡ºç»“æœçš„è¯„ä¼°ç­‰ç­‰ï¼Œè¿™ç§å¾ªç¯é“¾çš„è®¾è®¡ä½¿å¾— Agent èƒ½å¤Ÿåœ¨æ¯æ¬¡å·¥å…·è°ƒç”¨åè¿›è¡Œåæ€å’Œå†³ç­–ï¼Œç¡®ä¿æœ€ç»ˆè¾“å‡ºçš„è´¨é‡ã€‚

å…¶å®langgraphä¸­çš„react_agentä¹Ÿæ˜¯é€šè¿‡å¾ªç¯é“¾å®ç°çš„ï¼Œä»–çš„æ ¸å¿ƒå°±æ˜¯è®©agentä¸æ–­çš„æ€è€ƒå’Œå†³ç­–ï¼Œç›´åˆ°è¾“å‡ºæœ€ç»ˆç»“æœ,å…¶ä¸­å°±æ˜¯é€šè¿‡messageæ¥å›æº¯ä¹‹å‰å¤„ç†çš„å†…å®¹çš„ï¼ˆåé¢ä¼šæ›´åŠ æ·±å…¥çš„è®²è§£ï¼‰



## 5. ç»„ä»¶å››ï¼šè®°å¿† (Memory)

ä¸ºäº†è®©å¯¹è¯èƒ½å¤ŸæŒç»­ï¼Œé“¾å’Œ Agent éœ€è¦è®°ä½ä¹‹å‰çš„äº¤äº’ã€‚åœ¨`langchain` v0.3ç‰ˆæœ¬ä¹‹åï¼Œå®˜æ–¹æ›´åŠ æ¨èä½¿ç”¨`langgraph`è¿›è¡Œè®°å¿†ç®¡ç†ï¼Œæ‰€ä»¥ä¸‹é¢æˆ‘å°†ä½¿ç”¨`langgraph`è¿›è¡Œè®²è§£

### 5.1. çŸ­æœŸè®°å¿†

åœ¨langgraphä¸­çŸ­æœŸè®°å¿†å·²ç»ä½œä¸ºçŠ¶æ€ä¸­çš„ä¸€éƒ¨åˆ†ï¼Œä¸‹é¢æˆ‘å°†ä»‹ç»é’ˆå¯¹äºçŸ­æœŸè®°å¿†çš„ä¸€äº›å¤„ç†æ–¹å¼

#### æ·»åŠ çŸ­æœŸè®°å¿†-èŠ‚ç‚¹

**ä»£ç å®ä¾‹:**

```python
from typing import Annotated, Sequence
from typing_extensions import TypedDict
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from base import model
# å®šä¹‰çŠ¶æ€ï¼ŒåŒ…å«æ¶ˆæ¯å†å²ï¼ˆçŸ­æœŸè®°å¿†ï¼‰
class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]

# å®šä¹‰ä»£ç†èŠ‚ç‚¹ï¼Œå¤„ç†è¾“å…¥å¹¶ä½¿ç”¨çŸ­æœŸè®°å¿†
def agent_node(state: AgentState) -> AgentState:
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹ã€‚è¯·æ ¹æ®å¯¹è¯å†å²è‡ªç„¶å›åº”ã€‚"),
        MessagesPlaceholder(variable_name="messages"),  # æ³¨å…¥çŸ­æœŸè®°å¿†
    ])
    chain = prompt | model  # ä½¿ç”¨é¢„å®šä¹‰çš„æ¨¡å‹
    response = chain.invoke(state["messages"])
    return {"messages": [response]}

# åˆå§‹åŒ–æ£€æŸ¥ç‚¹å­˜å‚¨ï¼ˆçŸ­æœŸè®°å¿†æŒä¹…åŒ–ï¼‰
checkpointer = InMemorySaver()

# æ„å»ºçŠ¶æ€å›¾
builder = StateGraph(state_schema=AgentState)
builder.add_node("agent", agent_node)
builder.add_edge(START, "agent")
builder.add_edge("agent", END)

# ç¼–è¯‘å›¾å½¢ï¼Œå¯ç”¨æ£€æŸ¥ç‚¹
graph = builder.compile(checkpointer=checkpointer)

# æµ‹è¯•å¤šè½®äº¤äº’ï¼Œå±•ç¤ºçŸ­æœŸè®°å¿†
def run_conversation():
    # ç¬¬ä¸€è½®ï¼šç”¨æˆ·è‡ªæˆ‘ä»‹ç»
    inputs = {"messages": [HumanMessage(content="ä½ å¥½ï¼æˆ‘æ˜¯Bob")]}
    config = {"configurable": {"thread_id": "1"}}  # thread_idç¡®ä¿è®°å¿†éš”ç¦»
    result = graph.invoke(inputs, config)
    print('é—®é¢˜',inputs['messages'][0].content)
    print("åŠ©æ‰‹ï¼š", result["messages"][-1].content)

    # ç¬¬äºŒè½®ï¼šéªŒè¯æ˜¯å¦è®°ä½Bob
    inputs = {"messages": [HumanMessage(content="æˆ‘çš„åå­—æ˜¯ä»€ä¹ˆï¼Ÿ")]}
    result = graph.invoke(inputs, config)
    print('é—®é¢˜', inputs['messages'][0].content)
    print("åŠ©æ‰‹ï¼š", result["messages"][-1].content)


# æ‰§è¡Œæµ‹è¯•
if __name__ == "__main__":
    run_conversation()
```

```
è¿è¡Œç»“æœï¼š

é—®é¢˜ ä½ å¥½ï¼æˆ‘æ˜¯Bob
åŠ©æ‰‹ï¼š ä½ å¥½ï¼ŒBobï¼å¾ˆé«˜å…´è§åˆ°ä½ ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ

é—®é¢˜ æˆ‘çš„åå­—æ˜¯ä»€ä¹ˆï¼Ÿ
åŠ©æ‰‹ï¼š ä½ çš„åå­—æ˜¯Bobã€‚å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ŒBobï¼
```

å¯ä»¥çœ‹åˆ°è®°å¿†è¢«æˆåŠŸæ·»åŠ åˆ°äº†llmä¸­ï¼Œä½†æ˜¯æ³¨æ„åœ¨langgraphä¸­è®°å¿†æ˜¯å­˜åœ¨éš”ç¦»çš„ï¼Œåªæœ‰configä¸­çš„çº¿ç¨‹ä¸€è‡´æ‰ä¼šè°ƒç”¨ç›¸å…³è®°å¿†

#### æ·»åŠ çŸ­æœŸè®°å¿†-å·¥å…·

åœ¨èŠ‚ç‚¹ä¸­æ·»åŠ çŸ­æœŸè®°å¿†å¯ä»¥ç›´æ¥é€šè¿‡returnçš„æ–¹å¼ï¼Œé‚£ä¹ˆæ¶ˆæ¯å°±ä¼šè¢«æ·»åŠ è¿›å…¥çŠ¶æ€ï¼Œä½†æ˜¯å·¥å…·è¾“å‡ºçš„è¿”å›å€¼ä¸ä¼šç”¨äºæ›´æ–°çŠ¶æ€ï¼Œå¦‚æœä½ æƒ³è¦å·¥å…·çš„è¾“å‡ºåœ¨çŠ¶æ€ä¸­æ›´æ–°å¯ä»¥ä½¿ç”¨ä¸‹é¢è¿™ä¸ªæ–¹æ³•

```python

@tool(description='æŸ¥è¯¢ç”¨æˆ·å§“åçš„å·¥å…·')
def update_user_info(
        tool_call_id: Annotated[str, InjectedToolCallId],
        config: RunnableConfig
) -> Command:
    """æŸ¥æ‰¾å¹¶æ›´æ–°ç”¨æˆ·ä¿¡æ¯ã€‚
    Args:
        tool_call_id: å·¥å…·è°ƒç”¨ID
        config: è¿è¡Œé…ç½®ï¼ŒåŒ…å«ç”¨æˆ·ID
    Returns:
        Commandå¯¹è±¡ï¼ŒåŒ…å«æ›´æ–°åçš„ç”¨æˆ·åå’Œæ¶ˆæ¯å†å²
    """
    user_id = config["configurable"].get("user_id")
    print(user_id)
    name = "å¼ ä¼Ÿ" if user_id == "user_123" else "æœªçŸ¥ç”¨æˆ·"
    return Command(update={
        "user_name": name,
        # æ›´æ–°æ¶ˆæ¯å†å²
        "messages": [
            ToolMessage(
                "æˆåŠŸæŸ¥æ‰¾ç”¨æˆ·ä¿¡æ¯",
                tool_call_id=tool_call_id
            )
        ]
    })

```

ä½ å¯ä»¥ä½¿ç”¨commandçš„æ–¹å¼è¿›è¡Œè·¯ç”±æ¥è¿›è¡ŒçŠ¶æ€æ›´æ–°ï¼Œæ­¤æ—¶å·¥å…·çš„è¿”å›å€¼ç”¨äºçŠ¶æ€æ›´æ–°

#### è¯»å–è®°å¿†

è¯»å–è®°å¿†å°±éå¸¸ç®€å•ï¼Œç›´æ¥ä¼ å…¥ç›¸å…³çŠ¶æ€ç„¶åè¿›è¡Œè¯»å–å³å¯

#### ä¿®å‰ªè®°å¿†

```python
from base import llm as model
from typing import Annotated, Sequence
from langchain_core.tools import tool
from langchain_core.messages import HumanMessage, ToolMessage, AIMessage
from langchain_core.messages.utils import trim_messages, count_tokens_approximately
from langchain_core.runnables import RunnableConfig
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.prebuilt.chat_agent_executor import AgentState
import json

# æ¨¡æ‹Ÿæ—¥ç¨‹æ•°æ®åº“
schedule_db = {
    "2025-10-13": ["ä¸Šåˆ9ç‚¹ï¼šå›¢é˜Ÿä¼šè®®"]
}

# å®šä¹‰å·¥å…·
@tool
def get_schedule(date: str) -> str:
    """æŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„æ—¥ç¨‹å®‰æ’ã€‚
    Args:
        date: æ—¥æœŸï¼Œæ ¼å¼ä¸ºYYYY-MM-DD
    Returns:
        æ—¥ç¨‹åˆ—è¡¨çš„JSONå­—ç¬¦ä¸²
    """
    return json.dumps(schedule_db.get(date, []), ensure_ascii=False)

# é¢„å¤„ç†é’©å­ï¼šä¿®å‰ªæ¶ˆæ¯
def pre_model_hook(state: AgentState) -> dict:
    trimmed_messages = trim_messages(
        state["messages"],
        strategy="last",
        token_counter=count_tokens_approximately,
        max_tokens=30,
        start_on="human",
        end_on=("human", "tool"),
    )
    return {"llm_input_messages": trimmed_messages}
  
#æˆ‘æ¥é‡ç‚¹

# åˆå§‹åŒ–æ£€æŸ¥ç‚¹å­˜å‚¨
checkpointer = InMemorySaver()

# åˆ›å»ºä»£ç†
agent = create_react_agent(
    model=model,  # å‡è®¾modelå·²å®šä¹‰ï¼Œæ”¯æŒå·¥å…·è°ƒç”¨
    tools=[get_schedule],
    pre_model_hook=pre_model_hook,
    checkpointer=checkpointer,
)

# æµ‹è¯•å¤šè½®äº¤äº’
def run_conversation():
    config = {"configurable": {"thread_id": "1"}}

    # ç¬¬ä¸€è½®ï¼šæŸ¥è¯¢æ—¥ç¨‹
    result = agent.invoke(
        {"messages": [HumanMessage(content="2025å¹´10æœˆ13æ—¥æœ‰ä»€ä¹ˆæ—¥ç¨‹ï¼Ÿ")]},
        config=config
    )
    print("åŠ©æ‰‹ï¼š", result["messages"][-1].content)

    result = agent.invoke(
        {"messages": [HumanMessage(content="æˆ‘æ˜¯å¦æŸ¥è¯¢è¿‡æ—¥ç¨‹")]},
        config=config
    )
    print("åŠ©æ‰‹ï¼š", result["messages"][-1].content)

if __name__ == "__main__":
    run_conversation()
```

**ç›¸å…³å‡½æ•°ä»‹ç»**

- trim_messages è¯¥å‡½æ•°æ˜¯å®˜æ–¹å¯¹åŸºäºtokenæ•°é‡è¿›è¡Œä¿®å‰ªè®°å¿†çš„ä¸€ä¸ªå‡½æ•°å°è£…ï¼Œæˆ‘é‡ç‚¹ä»‹ç»å‡ ä¸ªé‡è¦å‚æ•° 
  -  strategy è¯¥ä»£è¡¨ç€è£å‰ªç­–ç•¥ åŒ…æ‹¬ä¸‰ç§ 1. first è¡¨ç¤ºä»å¤´å¼€å§‹é€‰å– 2. last è¡¨ç¤ºä»æœ«å°¾è¿›è¡Œé€‰å– 3. random éšæœºé€‰å–ç›´è‡³è¾¾åˆ°tokenæ•°ï¼Œæœ€ä¸ºå¸¸ç”¨çš„å°±æ˜¯lastï¼Œåªé€‰å–æœ€è¿‘çš„å‡ æ¡æ¶ˆæ¯
  - token_counter å¹´éœ€è¦ä¼ å…¥ä¸€ä¸ªå®˜æ–¹å°è£…çš„tokenè®¡ç®—å™¨
  - start_onå’Œend_on è§„å®šäº†æˆªå–çš„ç¬¬ä¸€æ¡æ¶ˆæ¯å’Œæœ€åä¸€æ¡æ¶ˆæ¯å¿…é¡»ä¸ºä»€ä¹ˆç±»å‹ã€‚
- pre_model_hook è¿™æ˜¯ä¸€ä¸ªé’©å­å‡½æ•°ï¼Œè¡¨ç¤ºåœ¨å¤§æ¨¡å‹è°ƒç”¨ä¹‹å‰éœ€è¦è¿è¡Œè¯¥å‡½æ•°ã€‚

**æ³¨æ„äº‹é¡¹**

éœ€è¦æ³¨æ„çš„æ˜¯ä¿®å‰ªåªæ˜¯ä»å…¨éƒ¨è®°å¿†åº“ä¸­é€‰å–éƒ¨åˆ†å¹¶æ²¡æœ‰è¿›è¡Œåˆ é™¤ã€‚

å½“ç„¶ä½ å¯ä»¥è‡ªå°è£…ä¿®å‰ªå‡½æ•°åˆ°é’©å­å‡½æ•°ä¸­ï¼ˆæ¯”å¦‚å¸¸è§æŒ‰ç…§æ¶ˆæ¯æ¡æ•°è¿›è¡Œä¿®å‰ªï¼ŒåŸºäºragè¿›è¡Œè®°å¿†æ¶ˆæ¯æŒ‘é€‰ç­‰ç­‰ï¼Œåœ¨è¿™é‡Œå°±ä¸å†å…·ä½“æè¿°ï¼‰

```
è¾“å‡ºï¼š
åŠ©æ‰‹ï¼š æ ¹æ®æŸ¥è¯¢ç»“æœï¼Œæ‚¨åœ¨2025å¹´10æœˆ13æ—¥æœ‰ä¸€ä¸ªæ—¥ç¨‹å®‰æ’ï¼š

**ä¸Šåˆ9ç‚¹ï¼šå›¢é˜Ÿä¼šè®®**

å¦‚æœæ‚¨éœ€è¦äº†è§£å…¶ä»–æ—¥æœŸçš„æ—¥ç¨‹å®‰æ’ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚


åŠ©æ‰‹ï¼š ç›®å‰æˆ‘æ— æ³•ç›´æ¥æŸ¥çœ‹æ‚¨çš„æŸ¥è¯¢å†å²è®°å½•ã€‚ä¸è¿‡ï¼Œæˆ‘å¯ä»¥å¸®æ‚¨æŸ¥è¯¢ç‰¹å®šæ—¥æœŸçš„æ—¥ç¨‹å®‰æ’ã€‚

å¦‚æœæ‚¨æƒ³æŸ¥çœ‹æŸä¸€å¤©çš„æ—¥ç¨‹ï¼Œè¯·å‘Šè¯‰æˆ‘å…·ä½“çš„æ—¥æœŸï¼ˆæ ¼å¼ä¸ºYYYY-MM-DDï¼‰ï¼Œæˆ‘å°±å¯ä»¥ä¸ºæ‚¨æŸ¥è¯¢é‚£å¤©çš„æ—¥ç¨‹å®‰æ’äº†ã€‚

æ¯”å¦‚æ‚¨å¯ä»¥é—®ï¼š"è¯·å¸®æˆ‘æŸ¥è¯¢2024å¹´1æœˆ15æ—¥çš„æ—¥ç¨‹" æˆ–è€… "æŸ¥çœ‹ä»Šå¤©çš„æ—¥ç¨‹å®‰æ’" ç­‰ç­‰ã€‚


```

#### åˆ é™¤è®°å¿†

```python
from langchain_core.messages import RemoveMessage

def delete_messages(state):
    messages = state["messages"]
    if len(messages) > 2:
        # remove the earliest two messages
        return {"messages": [RemoveMessage(id=m.id) for m in messages[:2]]}
```

å¯ä»¥çœ‹åˆ°åˆ é™¤è®°å¿†åªéœ€è¦ä¼ å…¥è¿™æ¡æ¶ˆæ¯çš„idå³å¯
**è‹¥è¦ä»å›¾å½¢çŠ¶æ€ä¸­åˆ é™¤æ¶ˆæ¯ï¼Œå¯ä»¥ä½¿ç”¨ `RemoveMessage`ã€‚è¦ä½¿ `RemoveMessage` æ­£å¸¸å·¥ä½œï¼Œæ‚¨éœ€è¦å°†çŠ¶æ€é”®ä¸ [reducer](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) ä¸€èµ·ä½¿ç”¨ [`add_messages`](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.message.add_messages) ä¾‹å¦‚ [`MessagesState`](https://langchain-ai.github.io/langgraph/concepts/low_level/#messagesstate)ã€‚**

#### æ‘˜è¦è®°å¿†

åœ¨langgraphä¸­æä¾›äº†ä¸€ç§å‡½æ•°æ¥å£å’Œä¸€ç§èŠ‚ç‚¹æ¥å£

##### summarize_messages

| å‚æ•°åç§°                    | ç±»å‹                    | é»˜è®¤å€¼                            | æè¿°                                                         |
| --------------------------- | ----------------------- | --------------------------------- | ------------------------------------------------------------ |
| `messages`                  | `list[AnyMessage]`      | -                                 | è¦å¤„ç†çš„è¾“å…¥æ¶ˆæ¯åˆ—è¡¨ã€‚è¿™æ˜¯å¿…éœ€å‚æ•°ï¼ŒæŒ‰æ—¶é—´é¡ºåºä»æ—§åˆ°æ–°æ’åˆ—ã€‚ |
| `running_summary`           | `RunningSummary | None` | `None`                            | å¯é€‰çš„è¿è¡Œä¸­æ‘˜è¦å¯¹è±¡ï¼Œç”¨äºè·Ÿè¸ªä¹‹å‰çš„æ±‡æ€»ä¿¡æ¯ã€‚å¦‚æœæä¾›ï¼Œåˆ™åªå¤„ç†æœªè¢«ä¹‹å‰æ±‡æ€»è¿‡çš„æ¶ˆæ¯ï¼›å¦‚æœç”Ÿæˆæ–°æ‘˜è¦ï¼Œä¼šåŸºäºç°æœ‰æ‘˜è¦æ›´æ–°ï¼›å¦‚æœæ— éœ€æ–°æ±‡æ€»ï¼Œåˆ™å°†ç°æœ‰æ‘˜è¦æ·»åŠ åˆ°è¿”å›æ¶ˆæ¯ä¸­ã€‚ |
| `model`                     | `LanguageModelLike`     | -                                 | ç”¨äºç”Ÿæˆæ‘˜è¦çš„è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ ChatOpenAIï¼‰ã€‚å¿…éœ€å‚æ•°ã€‚å»ºè®®ç»‘å®š `max_tokens` ä»¥é™åˆ¶è¾“å‡ºé•¿åº¦ï¼Œä¾‹å¦‚ `model.bind(max_tokens=128)`ã€‚ |
| `max_tokens`                | `int`                   | -                                 | æœ€ç»ˆè¾“å‡ºä¸­å…è®¸çš„æœ€å¤§ä»¤ç‰Œæ•°ã€‚æ±‡æ€»åä¼šå¼ºåˆ¶æ‰§è¡Œæ­¤é™åˆ¶ã€‚åŒæ—¶ï¼Œè¿™ä¹Ÿæ˜¯å–‚ç»™æ±‡æ€» LLM çš„æœ€å¤§ä»¤ç‰Œæ•°ï¼ˆå‡è®¾ LLM ä¸Šä¸‹æ–‡çª—å£ä¸Šé™ä¸º `max_tokens`ï¼‰ã€‚å¿…éœ€å‚æ•°ã€‚ |
| `max_tokens_before_summary` | `int | None`            | `None` (é»˜è®¤ä¸º `max_tokens`)      | åœ¨è§¦å‘æ±‡æ€»å‰å…è®¸ç´¯ç§¯çš„æœ€å¤§ä»¤ç‰Œæ•°ã€‚å¦‚æœä¸º `None`ï¼Œåˆ™ä½¿ç”¨ `max_tokens`ã€‚è¿™å…è®¸ä¸ºæ±‡æ€» LLM é¢„ç•™æ›´å¤šä»¤ç‰Œç©ºé—´ã€‚ **æ³¨æ„ï¼š** å¦‚æœé˜ˆå€¼å†…çš„æœ€åä¸€æ¡æ¶ˆæ¯æ˜¯å¸¦å·¥å…·è°ƒç”¨çš„ AI æ¶ˆæ¯ï¼Œåˆ™åç»­å¯¹åº”çš„å·¥å…·æ¶ˆæ¯ä¹Ÿä¼šè¢«çº³å…¥æ±‡æ€»ã€‚ **æ³¨æ„ï¼š** å¦‚æœè¦æ±‡æ€»çš„ä»¤ç‰Œæ•° > `max_tokens`ï¼Œåˆ™åªæ±‡æ€»æœ€è¿‘çš„ `max_tokens` ä¸ªï¼Œä»¥é¿å…è¶…è¿‡ LLM ä¸Šä¸‹æ–‡çª—å£ã€‚ |
| `max_summary_tokens`        | `int`                   | `256`                             | ä¸ºæ‘˜è¦é¢„ç•™çš„æœ€å¤§ä»¤ç‰Œé¢„ç®—ã€‚ **æ³¨æ„ï¼š** æ­¤å‚æ•°ä»…ç”¨äºå†…éƒ¨ä»¤ç‰Œä¼°ç®—ï¼Œä¸ä¼šç›´æ¥ä¼ é€’ç»™ LLM ä»¥é™åˆ¶è¾“å‡ºé•¿åº¦ã€‚å¦‚æœéœ€è¦å¼ºåˆ¶æ‰§è¡Œï¼Œå¯åœ¨ `model` ä¸­ç»‘å®š `max_tokens=max_summary_tokens`ã€‚ |
| `token_counter`             | `TokenCounter`          | `count_tokens_approximately`      | è®¡ç®—æ¶ˆæ¯ä»¤ç‰Œæ•°çš„å‡½æ•°ã€‚é»˜è®¤ä½¿ç”¨è¿‘ä¼¼è®¡æ•°ï¼›ä¸ºæ›´ç²¾ç¡®ï¼Œå¯ç”¨ `model.get_num_tokens_from_messages`ã€‚ |
| `initial_summary_prompt`    | `ChatPromptTemplate`    | `DEFAULT_INITIAL_SUMMARY_PROMPT`  | ç”Ÿæˆé¦–æ¬¡æ‘˜è¦çš„æç¤ºæ¨¡æ¿ã€‚é»˜è®¤æç¤ºç”¨äºåˆå§‹æ±‡æ€»åœºæ™¯ã€‚           |
| `existing_summary_prompt`   | `ChatPromptTemplate`    | `DEFAULT_EXISTING_SUMMARY_PROMPT` | æ›´æ–°ç°æœ‰ï¼ˆè¿è¡Œä¸­ï¼‰æ‘˜è¦çš„æç¤ºæ¨¡æ¿ã€‚é»˜è®¤æç¤ºç”¨äºå¢é‡æ±‡æ€»ã€‚     |
| `final_prompt`              | `ChatPromptTemplate`    | `DEFAULT_FINAL_SUMMARY_PROMPT`    | åœ¨è¿”å›å‰ç»“åˆæ‘˜è¦ä¸å‰©ä½™æ¶ˆæ¯çš„æœ€ç»ˆæç¤ºæ¨¡æ¿ã€‚é»˜è®¤æç¤ºç”¨äºç»„è£…æœ€ç»ˆæ¶ˆæ¯åˆ—è¡¨ã€‚ |

###### å‡½æ•°è¿”å›å€¼

SummarizationResult å¯¹è±¡

- messages: list[AnyMessage]ï¼šæ›´æ–°åçš„æ¶ˆæ¯åˆ—è¡¨ï¼Œå‡†å¤‡è¾“å…¥åˆ° LLMï¼ŒåŒ…æ‹¬æ‘˜è¦æ¶ˆæ¯ï¼ˆå¦‚æœæœ‰ï¼‰ã€‚
- running_summary: RunningSummary | Noneï¼šæ›´æ–°åçš„è¿è¡Œæ‘˜è¦ä¿¡æ¯ã€‚å¦‚æœæ— éœ€æ±‡æ€»ï¼Œåˆ™ä¸º Noneã€‚

###### é‡ç‚¹å‚æ•°ä»‹ç»

- max_token è¡¨ç¤ºè¾“å…¥åˆ°æ±‡æ€»medelä¸­æœ€å¤§çš„tokenæ•° å¦‚æœè¶…è¿‡è¯¥tokenå°±ä¼šæˆªæ–­
- running_summary è¿™æ˜¯æ±‡æ€»æ¶ˆæ¯è¾“å…¥å¤„ å¦‚æœè¯¥è¾“å…¥ä¸ä¸ºç©ºå°±ä¼šmodelå°±ä¼šä½¿ç”¨existing_summary_prompt æç¤ºè¯è¿›è¡Œè¾“å‡ºåä¹‹ä½¿ç”¨initial_summary_promptæç¤ºè¯

###### é»˜è®¤æç¤ºè¯ç»“æ„

- DEFAULT_INITIAL_SUMMARY_PROMPT ç»“æ„:

ç±»å‹: <class 'langchain_core.prompts.chat.ChatPromptTemplate'>
è¾“å…¥å˜é‡: []
å¯é€‰å˜é‡: ['messages']
æ¶ˆæ¯ç»“æ„: [MessagesPlaceholder(variable_name='messages', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Create a summary of the conversation above:'), additional_kwargs={})]

---



- DEFAULT_EXISTING_SUMMARY_PROMPT ç»“æ„:

ç±»å‹: <class 'langchain_core.prompts.chat.ChatPromptTemplate'>
è¾“å…¥å˜é‡: ['existing_summary']
å¯é€‰å˜é‡: ['messages']
æ¶ˆæ¯ç»“æ„: [MessagesPlaceholder(variable_name='messages', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['existing_summary'], input_types={}, partial_variables={}, template='This is summary of the conversation so far: {existing_summary}\n\nExtend this summary by taking into account the new messages above:'), additional_kwargs={})]

---

- DEFAULT_FINAL_SUMMARY_PROMPT ç»“æ„:

ç±»å‹: <class 'langchain_core.prompts.chat.ChatPromptTemplate'>
è¾“å…¥å˜é‡: ['summary']
å¯é€‰å˜é‡: ['messages', 'system_message']
æ¶ˆæ¯ç»“æ„: [MessagesPlaceholder(variable_name='system_message', optional=True), SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['summary'], input_types={}, partial_variables={}, template='Summary of the conversation so far: {summary}'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages', optional=True)]

**åº•å±‚å‡½æ•°é»˜è®¤å¡«å…¥çš„å°±æ˜¯é»˜è®¤æç¤ºè¯æ¨¡ç‰ˆçš„å‚æ•°è€Œä¸ä¼šå¡«å…¥å…¶ä»–å‚æ•°æ‰€ä»¥å½“ä½ ä½¿ç”¨ä½ è‡ªå®šä¹‰çš„æç¤ºè¯æ¨¡ç‰ˆæ—¶éœ€è¦æŠŠå…¶ä»–å‚æ•°è®¾ç½®æˆpartial_variablesæå‰è¿›è¡Œå¡«å……**

###### ä»£ç å®ä¾‹

ä¸‹é¢æ˜¯ä¸€ä¸ªèŠå¤©å¯¹è¯æœºå™¨äººé’ˆå¯¹äºè®°å¿†å¤„ç†çš„ä¸€ä¸ªç®€æ˜“å®ä¾‹ï¼Œå®ƒä¼šå¯¹è®°å¿†è¿›è¡Œåˆ†ç±»æ‘˜è¦ã€‚

~~~python
import typing
import typing_extensions
from langchain_core.prompts import ChatPromptTemplate
from langmem.short_term.summarization import DEFAULT_INITIAL_SUMMARY_PROMPT

if not hasattr(typing, 'NotRequired'):
    typing.NotRequired = typing_extensions.NotRequired

from base import llm as model
from langgraph.graph import StateGraph, START, MessagesState
from langgraph.checkpoint.memory import InMemorySaver
from langmem.short_term import summarize_messages, RunningSummary
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
prompt=DEFAULT_INITIAL_SUMMARY_PROMPT
print(prompt)

summarization_model = model.bind(max_tokens=128)

class SummaryState(MessagesState):
    summary: RunningSummary | None

def call_model(state):
    # è‡ªå®šä¹‰æ ‡ç­¾ç”Ÿæˆæç¤ºè¯
    system_message = """
# è§’è‰²ä¸ç›®æ ‡
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è®°å¿†å—æ ‡ç­¾ç”Ÿæˆä¸“å®¶ã€‚ä½ çš„æ ¸å¿ƒä»»åŠ¡æ˜¯æ·±å…¥åˆ†æç”¨æˆ·æä¾›çš„"èŠå¤©è®°å¿†"ç‰‡æ®µï¼Œå¹¶ä¸ºå…¶ç”Ÿæˆæˆ–åŒ¹é…æœ€ç²¾å‡†çš„"è®°å¿†å—æ ‡ç­¾"ã€‚ä½ çš„ç›®æ ‡æ˜¯ç¡®ä¿æ¯ä¸ªæ ‡ç­¾éƒ½èƒ½é«˜åº¦æ¦‚æ‹¬è®°å¿†ä¸­çš„ä¸€ä¸ªæ ¸å¿ƒäº‹ä»¶ï¼Œå¹¶ä¸”éµå¾ªç‰¹å®šçš„åŒ¹é…ä¸åˆ›å»ºè§„åˆ™ã€‚

# å·¥ä½œæµç¨‹

1.  **æ·±åº¦åˆ†æ**ï¼šé¦–å…ˆï¼Œä»”ç»†é˜…è¯»å¹¶å®Œå…¨ç†è§£`[èŠå¤©è®°å¿†]`ä¸­çš„æ‰€æœ‰å†…å®¹ã€‚è¯†åˆ«å‡ºå…¶ä¸­å‘ç”Ÿçš„ä¸€ä¸ªæˆ–å¤šä¸ªæ ¸å¿ƒäº‹ä»¶ã€å…³é”®å†³ç­–æˆ–é‡è¦ä¿¡æ¯ç‚¹ã€‚
2.  **åŒ¹é…ä¼˜å…ˆ**ï¼šå°†ä½ åˆ†æå‡ºçš„æ ¸å¿ƒäº‹ä»¶ä¸`[å·²æœ‰æ ‡ç­¾åˆ—è¡¨]`è¿›è¡Œé€ä¸€æ¯”å¯¹ã€‚å¦‚æœæŸä¸ªå·²æœ‰æ ‡ç­¾èƒ½å¤Ÿå‡†ç¡®ã€å®Œæ•´åœ°æ¦‚æ‹¬è®°å¿†ä¸­çš„ä¸€ä¸ªäº‹ä»¶ï¼Œä½ å¿…é¡»ç›´æ¥æ²¿ç”¨è¯¥æ ‡ç­¾ã€‚
3.  **æŒ‰éœ€åˆ›å»º**ï¼šå¦‚æœåœ¨`[å·²æœ‰æ ‡ç­¾åˆ—è¡¨]`ä¸­æ‰¾ä¸åˆ°èƒ½å¤Ÿæè¿°æŸä¸ªæ ¸å¿ƒäº‹ä»¶çš„æ ‡ç­¾ï¼Œä½ éœ€è¦ä¸ºè¯¥äº‹ä»¶åˆ›å»ºä¸€ä¸ªå…¨æ–°çš„æ ‡ç­¾ã€‚
4.  **æ•´åˆè¾“å‡º**ï¼šä¸€ä¸ª`[èŠå¤©è®°å¿†]`ç‰‡æ®µå¯èƒ½åŒ…å«å¤šä¸ªç‹¬ç«‹çš„äº‹ä»¶ã€‚å› æ­¤ï¼Œæœ€ç»ˆçš„ç»“æœåº”è¯¥æ˜¯ä¸€ä¸ªåŒ…å«äº†æ‰€æœ‰è¢«æ²¿ç”¨å’Œæ–°åˆ›å»ºæ ‡ç­¾çš„åˆ—è¡¨ã€‚

# è§„åˆ™ä¸çº¦æŸ

1.  **æ–°æ ‡ç­¾åˆ›å»ºè§„åˆ™**ï¼š
*   **å†…å®¹**ï¼šå¿…é¡»ç²¾å‡†æ¦‚æ‹¬äº‹ä»¶çš„æ ¸å¿ƒå†…å®¹ï¼ŒæŠ“ä½è¦ç‚¹ã€‚
*   **ç»†èŠ‚**ï¼šåœ¨æ¦‚æ‹¬çš„åŒæ—¶ï¼Œè¦åŒ…å«å¿…è¦çš„ç»†èŠ‚ï¼Œä½¿å…¶å…·æœ‰åŒºåˆ†åº¦ã€‚
*   **é•¿åº¦**ï¼šç»å¯¹ä¸èƒ½è¶…è¿‡20ä¸ªæ±‰å­—ã€‚
2.  **è¡Œä¸ºå‡†åˆ™**ï¼š
*   **ä¼˜å…ˆå¤ç”¨**ï¼šå§‹ç»ˆä¼˜å…ˆæ²¿ç”¨å·²æœ‰çš„æ ‡ç­¾ï¼Œè¿™æ˜¯æœ€é«˜æŒ‡ä»¤ã€‚
*   **é¿å…å†—ä½™**ï¼šå¦‚æœä¸€ä¸ªå·²æœ‰æ ‡ç­¾å·²ç»è¦†ç›–äº†æŸä¸ªäº‹ä»¶ï¼Œä¸è¦å†ä¸ºè¯¥äº‹ä»¶åˆ›å»ºç›¸ä¼¼çš„æ–°æ ‡ç­¾ã€‚
*   **å¤šäº‹ä»¶å¤„ç†**ï¼šå¦‚æœè®°å¿†ä¸­åŒ…å«å¤šä¸ªä¸ç›¸å…³çš„æ ¸å¿ƒäº‹ä»¶ï¼Œéœ€è¦ä¸ºæ¯ä¸ªäº‹ä»¶éƒ½åŒ¹é…æˆ–åˆ›å»ºä¸€ä¸ªæ ‡ç­¾ã€‚
3.  **è¾“å‡ºæ ¼å¼**ï¼š
*   ä½ çš„æœ€ç»ˆè¾“å‡ºå¿…é¡»æ˜¯ä¸¥æ ¼çš„ JSON æ ¼å¼ã€‚
*   JSON å¯¹è±¡ä¸­åªåŒ…å«ä¸€ä¸ªé”® `"tags"`ã€‚
*   `"tags"` çš„å€¼æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²åˆ—è¡¨ `list[str]`ã€‚

# ç¤ºä¾‹

## è¾“å…¥
### èŠå¤©è®°å¿†:
```
A: æˆ‘ä»¬ä¸‹ä¸ªæœˆå»äº‘å—çš„æœºç¥¨è®¢å¥½äº†å—ï¼Ÿ
B: è®¢å¥½äº†ï¼Œä¸‹å‘¨äº”æ—©ä¸Š8ç‚¹çš„ã€‚å¯¹äº†ï¼Œæˆ‘çœ‹åˆ°ä¸€ä¸ªå¾ˆæœ‰æ„æ€çš„å’–å•¡åº„å›­ï¼Œè¦ä¸è¦åŠ åˆ°è¡Œç¨‹é‡Œï¼Ÿ
A: å¥½ä¸»æ„ï¼ä¸€ç›´æƒ³å»çœ‹çœ‹ã€‚é‚£å°±è¿™ä¹ˆå®šäº†ã€‚
```

### å·²æœ‰æ ‡ç­¾åˆ—è¡¨:
```
["é¡¹ç›®AæŠ€æœ¯æ–¹æ¡ˆè®¨è®º", "é¢„å®šä¸‹ä¸ªæœˆå»äº‘å—çš„æœºç¥¨", "å‘¨æœ«èšé¤è®¡åˆ’"]
```

## æœŸæœ›è¾“å‡º
```
{{"tags": ["é¢„å®šä¸‹ä¸ªæœˆå»äº‘å—çš„æœºç¥¨", "äº‘å—è¡Œç¨‹ä¸­å¢åŠ å‚è§‚å’–å•¡åº„å›­"]}}
```
---

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°è§„åˆ™ï¼Œå§‹ç»ˆç”¨ä¸­æ–‡è¾“å‡ºæ ‡ç­¾å†…å®¹ã€‚
"""

    # åˆ›å»ºåŒ…å«ç³»ç»ŸæŒ‡ä»¤çš„æç¤ºè¯æ¨¡æ¿ç”¨äºæ‘˜è¦ç”Ÿæˆ
    existing_summary_prompt = ChatPromptTemplate.from_messages([
        ("system", system_message),
        ("user", """
ç°åœ¨å¯¹ä»¥ä¸‹å†…å®¹è¿›è¡Œæ ‡ç­¾ç”Ÿæˆï¼š

## æ–°æ¶ˆæ¯å†…å®¹:
{messages}

## å·²æœ‰æ ‡ç­¾åˆ—è¡¨:
{existing_summary}

è¯·æŒ‰ç…§ç³»ç»Ÿæç¤ºè¯ä¸­çš„è§„åˆ™ä¸ºè¿™äº›æ–°æ¶ˆæ¯ç”Ÿæˆæˆ–åŒ¹é…æ ‡ç­¾ã€‚
""")
    ])

    if 'summary' in state:
        print(state['summary'])

    # ä½¿ç”¨åŸå§‹æ¶ˆæ¯ï¼Œé¿å…IDé—®é¢˜
    messages = state["messages"]

    # ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯è¿›è¡Œæ‘˜è¦
    summarization_result = summarize_messages(
        messages,
        running_summary=state.get("summary"),
        model=summarization_model,
        max_tokens=512,
        max_tokens_before_summary=50,
        max_summary_tokens=50,
        existing_summary_prompt=existing_summary_prompt
    )


    response = model.invoke(summarization_result.messages)
    state_update = {"messages": [response]}
    if summarization_result.running_summary:
        state_update["summary"] = summarization_result.running_summary
    return state_update

checkpointer = InMemorySaver()
workflow = StateGraph(SummaryState)
workflow.add_node(call_model)
workflow.add_edge(START, "call_model")
graph = workflow.compile(checkpointer=checkpointer)

config = {"configurable": {"thread_id": "1"}}
print("ç¬¬ä¸€æ¡æ¶ˆæ¯...")
a=graph.invoke({"messages": "ä½ å¥½æˆ‘å«BOB"}, config)
print("\nç¬¬äºŒæ¡æ¶ˆæ¯...")
b=graph.invoke({"messages": "å†™ä¸€ä¸ªå…³äºçŒ«çš„ç¬‘è¯"}, config)
print("\nç¬¬ä¸‰æ¡æ¶ˆæ¯...")
c=graph.invoke({"messages": "åšåŒæ ·çš„äº‹æƒ…ä½†æ˜¯æ˜¯å…³äºç‹—çš„"}, config)
print("\nç¬¬å››æ¡æ¶ˆæ¯...")
d=graph.invoke({"messages": "æˆ‘æƒ³å­¦ä¹ Pythonç¼–ç¨‹"}, config)
print("\nç¬¬äº”æ¡æ¶ˆæ¯...")
e=graph.invoke({"messages": "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿè®¡åˆ’å»å…¬å›­æ•£æ­¥"}, config)

if 'summary' in e:
    print("\næœ€ç»ˆæ‘˜è¦:", e['summary'])
else:
    print("å°šæœªç”Ÿæˆæ‘˜è¦")

~~~

åœ¨langgraphä¸­è¿˜æä¾›äº†æ‘˜è¦èŠ‚ç‚¹ï¼Œä¸summarize_messagesç±»ä¼¼åªä¸è¿‡å…¶ç›´æ¥å°è£…æˆäº†èŠ‚ç‚¹å¯ä»¥ç›´æ¥å¡«å…¥å›¾ä¸­ã€‚

##### SummarizationNode 

| å‚æ•°åç§°                    | ç±»å‹                 | é»˜è®¤å€¼                            | æè¿°                                                         |
| --------------------------- | -------------------- | --------------------------------- | ------------------------------------------------------------ |
| `model`                     | `LanguageModelLike`  | -                                 | ç”Ÿæˆæ‘˜è¦çš„è¯­è¨€æ¨¡å‹ã€‚                                         |
| `max_tokens`                | `int`                | -                                 | æœ€ç»ˆè¾“å‡ºæœ€å¤§ä»¤ç‰Œæ•°ã€‚                                         |
| `max_tokens_before_summary` | `int | None`         | `None` (é»˜è®¤ä¸º `max_tokens`)      | è§¦å‘æ±‡æ€»å‰ç´¯ç§¯æœ€å¤§ä»¤ç‰Œæ•°ã€‚                                   |
| `max_summary_tokens`        | `int`                | `256`                             | æ‘˜è¦ä»¤ç‰Œé¢„ç®—ã€‚                                               |
| `token_counter`             | `TokenCounter`       | `count_tokens_approximately`      | ä»¤ç‰Œè®¡æ•°å‡½æ•°ã€‚                                               |
| `initial_summary_prompt`    | `ChatPromptTemplate` | `DEFAULT_INITIAL_SUMMARY_PROMPT`  | é¦–æ¬¡æ‘˜è¦æç¤ºã€‚                                               |
| `existing_summary_prompt`   | `ChatPromptTemplate` | `DEFAULT_EXISTING_SUMMARY_PROMPT` | æ›´æ–°æ‘˜è¦æç¤ºã€‚                                               |
| `final_prompt`              | `ChatPromptTemplate` | `DEFAULT_FINAL_SUMMARY_PROMPT`    | æœ€ç»ˆç»„åˆæç¤ºã€‚                                               |
| `input_messages_key`        | `str`                | `"messages"`                      | è¾“å…¥çŠ¶æ€ä¸­åŒ…å«æ¶ˆæ¯åˆ—è¡¨çš„é”®ã€‚                                 |
| `output_messages_key`       | `str`                | `"summarized_messages"`           | è¾“å‡ºçŠ¶æ€æ›´æ–°ä¸­æ›´æ–°æ¶ˆæ¯çš„é”®ã€‚ **è­¦å‘Šï¼š** é»˜è®¤ä¸è¾“å…¥é”®ä¸åŒï¼Œä»¥é¿å…è¦†ç›–ä¸»æ¶ˆæ¯åˆ—è¡¨ã€‚åªæœ‰åœ¨æœ‰æ„è¦†ç›–æ—¶æ‰è®¾ä¸ºç›¸åŒã€‚ |
| `name`                      | `str`                | `"summarization"`                 | èŠ‚ç‚¹çš„åç§°ã€‚                                                 |

### 5.2 é•¿æœŸè®°å¿†

é•¿æœŸè®°å¿†é’ˆå¯¹äºçŸ­æœŸè®°å¿†çš„ä¸åŒç‚¹åœ¨äºä»–æ˜¯é€šè¿‡å‘½åç©ºé—´æ¥è¿›è¡Œåˆ†ç¦»ï¼Œè€Œå¹¶éæ˜¯çº¿ç¨‹ï¼Œå³ä½¿ä¸åŒçº¿ç¨‹çš„å¯¹è¯ä¹Ÿå¯ä»¥è®¿é—®ç›¸åŒå­˜å‚¨å†…å®¹ã€‚

```python
store = InMemoryStore()
#ä½¿ç”¨å‘½åç©ºé—´éš”ç¦»æ•°æ®ï¼ˆå¦‚ç”¨æˆ· IDï¼‰ï¼Œé€šè¿‡ put(namespace, key, value) å­˜å‚¨ï¼Œget(namespace, key) æ£€ç´¢ã€‚æ”¯æŒ UUID ç­‰åŠ¨æ€é”®ã€‚
from langgraph.store.memory import InMemoryStore
import uuid

store = InMemoryStore()

# å®šä¹‰ä¸åŒç”¨æˆ·çš„å‘½åç©ºé—´ï¼ˆéš”ç¦»ï¼‰
#å‘½åç©ºé—´å¯ä»¥æ˜¯å­—ç¬¦ä¸²ä¹Ÿå¯ä»¥æ˜¯å…ƒç¥–
user1_namespace = ("users", "user_123")  # ç”¨æˆ· 1 çš„è®°å¿†æ–‡ä»¶å¤¹
user2_namespace = ("users", "user_456")  # ç”¨æˆ· 2 çš„è®°å¿†æ–‡ä»¶å¤¹

# ä¸ºç”¨æˆ· 1 å­˜å‚¨è®°å¿†
key1 = str(uuid.uuid4())
store.put(user1_namespace, key1, {"data": "User 123's favorite color is blue"})

# ä¸ºç”¨æˆ· 2 å­˜å‚¨è®°å¿†
key2 = str(uuid.uuid4())
store.put(user2_namespace, key2, {"data": "User 456's favorite food is pizza"})

# æ£€ç´¢ï¼šåªè·å–ç”¨æˆ· 1 çš„æ•°æ®ï¼ˆç”¨æˆ· 2 çš„ä¸ä¼šè¿”å›ï¼‰
retrieved1 = store.get(user1_namespace, key1)
print(retrieved1.value)  # è¾“å‡º: {'data': "User 123's favorite color is blue"}

retrieved2 = store.get(user1_namespace, key2)  # é”®ä¸å­˜åœ¨äºæ­¤å‘½åç©ºé—´
print(retrieved2)  # è¾“å‡º: Noneï¼ˆéš”ç¦»ç”Ÿæ•ˆï¼‰


#ä¸æ­¤åŒæ—¶è¿˜æ”¯æŒè¯­ä¹‰æ£€ç´¢é•¿æœŸè®°å¿†

store = InMemoryStore(
    index={
        "embed": embeddings,##åœ¨è¿™ä¼ å…¥é¢„å…ˆå®šä¹‰å¥½çš„æ½œå…¥æ¨¡å‹
        "dims": 1536,#è¯¥åµŒå…¥æ¨¡å‹çš„ç»´åº¦
    }
)

memories = store.search(namespace, query=query, limit=3)
#è¿™é‡Œåªæ˜¯ç®€å•çš„è¯­ä¹‰æ£€ç´¢ï¼Œä½ å¯ä»¥é›†æˆä¸€äº›æ›´ä¸ºé«˜çº§çš„RAGç­–ç•¥ ä¾‹å¦‚queryæ”¹å†™ï¼Œé‡æ’ç­‰ç­‰

```

### 5.3 æ£€æŸ¥ç‚¹

#### è·å–å½“å‰å¯¹è¯çŠ¶æ€

```
state = agent.get_state(config)
```

#### è·å–æ•´ä¸ªè¿‡ç¨‹å¯¹è¯å†å²çŠ¶æ€è®°å½•

```
agent.get_state_history(config)

#ä»å¼€å§‹åˆ°ç»“æŸæ¯ä¸€ä¸ªæ­¥çš„çŠ¶æ€ä¿¡æ¯ç»„æˆçš„åˆ—è¡¨ï¼Œä½†æ˜¯å®ƒæ˜¯æŒ‰ç…§æ—¶é—´å€’åºæ’åˆ—çš„

```

#### åˆ é™¤çº¿ç¨‹çš„æ‰€æœ‰æ£€æŸ¥ç‚¹

```
checkpointer.delete_thread(thread_id)
```



## 6. ç»„ä»¶äº”ï¼šä»£ç† (Agents)

Agent æ˜¯ LangChain ä¸­æœ€å¼ºå¤§çš„åŠŸèƒ½ä¹‹ä¸€ã€‚å®ƒä¸éµå¾ªé¢„è®¾çš„é“¾æ¡ï¼Œè€Œæ˜¯åˆ©ç”¨ LLM çš„æ¨ç†èƒ½åŠ›ï¼ŒåŠ¨æ€åœ°å†³å®šè°ƒç”¨å“ªä¸ª**å·¥å…· (Tool)** æ¥è§£å†³é—®é¢˜ã€‚

### 6.1. å·¥å…·

#### **å·¥å…·åŸºæœ¬å‚æ•°**

| Attribute å±æ€§ | Type ç±»å‹          | Description æè¿°                                             |
| -------------- | ------------------ | ------------------------------------------------------------ |
| name           | str                | åœ¨æä¾›ç»™ LLM æˆ–ä»£ç†çš„ä¸€ç»„å·¥å…·ä¸­å¿…é¡»æ˜¯å”¯ä¸€çš„ã€‚                |
| description    | str                | æè¿°è¯¥å·¥å…·çš„ä½œç”¨ã€‚ç”± LLM æˆ–ä»£ç†ç”¨ä½œä¸Šä¸‹æ–‡ã€‚                  |
| args_schema    | pydantic.BaseModel | å¯é€‰ï¼Œä½†å»ºè®®ä½¿ç”¨ï¼Œå¦‚æœä½¿ç”¨å›è°ƒå¤„ç†ç¨‹åºï¼Œåˆ™ä¸ºå¿…éœ€çš„ã€‚å®ƒå¯ç”¨äºæä¾›æ›´å¤šä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼Œå°‘é‡ç¤ºä¾‹ï¼‰æˆ–éªŒè¯é¢„æœŸå‚æ•°ã€‚ |
| return_direct  | boolean            | ä»…ä¸ä»£ç†ç›¸å…³ã€‚å½“ True æ—¶ï¼Œåœ¨è°ƒç”¨ç»™å®šçš„å·¥å…·åï¼Œä»£ç†å°†åœæ­¢å¹¶å°†ç»“æœç›´æ¥è¿”å›ç»™ç”¨æˆ·ã€‚è¿™ä¸ªååˆ†æœ‰ç”¨ä¾‹å¦‚ä½ çš„å·¥å…·å°±æ˜¯è¿”å›æœ€ç»ˆç»“æœçš„æ— éœ€è¦è®©llmå†ç»“åˆå·¥å…·è¿›è¡Œæ±‡æ€»å°±å¯ä»¥ä½¿ç”¨è¿™ä¸ªã€‚ |

#### **åˆ›å»ºæ–¹æ³•**

##### @tool åˆ›å»º

```python
from pydantic import BaseModel, Field


class CalculatorInput(BaseModel):
    a: int = Field(description="first number")
    b: int = Field(description="second number")

#åœ¨@tool ä¸­å¯ä»¥ç›´æ¥å®šä¹‰å·¥å…·åç§°
@tool("multiplication-tool", args_schema=CalculatorInput, return_direct=True)
def multiply(a: int, b: int) -> int:
    """Multiply two numbers.""" #è¿™ä¸ªå°±æ˜¯å·¥å…·çš„æè¿° å·¥å…·æè¿°å¯ä»¥ä½¿ç”¨googleæ–‡æ¡£å­—ç¬¦ä¸²
    return a * b
"""
Google æ ·å¼çš„ä¸»è¦ç‰¹ç‚¹

ç»“æ„ï¼šdocstring åˆ†ä¸ºå‡ ä¸ªå›ºå®šéƒ¨åˆ†ï¼Œæ¯ä¸ªéƒ¨åˆ†ç”¨ç²—ä½“æ ‡é¢˜ï¼ˆå¦‚ Args:ï¼‰å¼€å¤´ï¼Œåè·Ÿæè¿°ã€‚éƒ¨åˆ†ä¹‹é—´ç”¨ç©ºè¡Œåˆ†éš”ã€‚
å¸¸è§éƒ¨åˆ†ï¼š

Args:ï¼ˆå‚æ•°ï¼‰ï¼šåˆ—å‡ºæ¯ä¸ªå‚æ•°çš„åç§°ã€ç±»å‹ï¼ˆå¯é€‰ï¼‰å’Œæè¿°ã€‚æ¯ä¸ªå‚æ•°ä¸€è¡Œã€‚
Returns:ï¼ˆè¿”å›å€¼ï¼‰ï¼šæè¿°å‡½æ•°è¿”å›å€¼çš„ç±»å‹å’Œå«ä¹‰ã€‚
Raises:ï¼ˆå¼‚å¸¸ï¼‰ï¼šåˆ—å‡ºå¯èƒ½æŠ›å‡ºçš„å¼‚å¸¸åŠå…¶åŸå› ã€‚
Yields:ï¼ˆç”Ÿæˆå™¨ï¼‰ï¼šå¦‚æœå‡½æ•°æ˜¯ç”Ÿæˆå™¨ï¼Œç”¨è¿™ä¸ªéƒ¨åˆ†æè¿° yield çš„å€¼ã€‚
Examples:ï¼ˆç¤ºä¾‹ï¼‰ï¼šå¯é€‰ï¼Œæä¾›ä½¿ç”¨ç¤ºä¾‹ã€‚


è§„åˆ™ï¼š

ç¬¬ä¸€è¡Œæ˜¯ç®€çŸ­çš„æ‘˜è¦ï¼ˆä¸€è¡Œï¼‰ã€‚
æ•´ä¸ª docstring ç¼©è¿›ä¸ä»£ç å¯¹é½ã€‚
å‚æ•°æè¿°æ—¶ï¼Œå‚æ•°åç”¨ç©ºæ ¼åè·Ÿå†’å·ã€‚
ç±»å‹ç”¨æ–¹æ‹¬å·è¡¨ç¤ºï¼Œå¦‚ [str]ã€‚
ä¿æŒç®€æ´ï¼Œé¿å…å†—é•¿æè¿°ã€‚
"""

"""è¿”å›ä¸¤ä¸ªæ•´æ•°çš„å’Œã€‚

    Args:
        a [int]: ç¬¬ä¸€ä¸ªæ•´æ•°ã€‚
        b [int]: ç¬¬äºŒä¸ªæ•´æ•°ã€‚

    Returns:
        int: ä¸¤ä¸ªæ•´æ•°çš„å’Œã€‚

    Raises:
        TypeError: å¦‚æœ a æˆ– b ä¸æ˜¯æ•´æ•°ã€‚

    Examples:
        >>> add_numbers(2, 3)
        5
    """
    


# Let's inspect some of the attributes associated with the tool.
print(multiply.name)
print(multiply.description)
print(multiply.args)
print(multiply.return_direct)

```

```
multiplication-tool
Multiply two numbers.
{'a': {'description': 'first number', 'title': 'A', 'type': 'integer'}, 'b': {'description': 'second number', 'title': 'B', 'type': 'integer'}}
True
```

##### StructuredTool

å¦‚æœä½ æƒ³è¦ç»“æ„åŒ–çš„åˆ›å»ºå·¥å…·å¹¶ä¸”ä½¿ä½ çš„ä»£ç æ›´åŠ å¥å£®å¯å¤ç”¨è¿™ä¸ªæ— ç–‘æ˜¯æ›´å¥½é€‰æ‹©

```python
calculator = StructuredTool.from_function(
    func=multiply,
    name="Calculator",
    description="multiply numbers",
    args_schema=CalculatorInput,
    return_direct=True,
    # coroutine= ... <- you can specify an async method if desired as well
)
#é‡ç‚¹ä»‹ç»ä¸€ä¸‹ coroutineå‚æ•°ã€‚å½“ä½¿ç”¨ StructuredTool åˆ›å»ºå·¥å…·æ—¶å…è®¸é’ˆå¯¹ä¸€ä¸ªå‡½æ•°åŒæ—¶ä¼ å…¥åŒæ­¥å’Œå¼‚æ­¥ä¸¤ä¸ªç‰ˆæœ¬ï¼Œå®ƒä¼šæ ¹æ®ä½ è°ƒç”¨æ‰€å¤„äºç¯å¢ƒè¿›è¡Œè‡ªåŠ¨è½¬æ¢ï¼Œæ— éœ€è¦äººå·¥è‡ªè¡Œè½¬æ¢ã€‚

from langchain_core.tools import StructuredTool


def multiply(a: int, b: int) -> int:
    """Multiply two numbers."""
    return a * b


async def amultiply(a: int, b: int) -> int:
    """Multiply two numbers."""
    return a * b


calculator = StructuredTool.from_function(func=multiply, coroutine=amultiply)

```

##### é’ˆå¯¹äºå·¥å…·çš„é”™è¯¯å¤„ç†

```
from langchain_core.tools import ToolException


def get_weather(city: str) -> int:
    """Get weather for the given city."""
    raise ToolException(f"Error: There is no city by the name of {city}.")
#ä»…å¼•å‘ ToolException æ˜¯æ— æ•ˆçš„ã€‚æ‚¨éœ€è¦é¦–å…ˆè®¾ç½®å·¥å…·çš„ handle_tool_errorsï¼Œå› ä¸ºå®ƒçš„é»˜è®¤å€¼ä¸º Falseã€‚    
get_weather_tool = StructuredTool.from_function(
    func=get_weather,
    handle_tool_error=True,
)


```

##### è¿›é˜¶ç”¨æ³•

å°†Runnableå¯æ‰§è¡Œé“¾ä½œä¸ºå·¥å…·

```
from langchain_core.language_models import GenericFakeChatModel
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate

prompt = ChatPromptTemplate.from_messages(
    [("human", "Hello. Please respond in the style of {answer_style}.")]
)

# Placeholder LLM
llm = GenericFakeChatModel(messages=iter(["hello matey"]))

chain = prompt | llm | StrOutputParser()

as_tool = chain.as_tool(
    name="Style responder", description="Description of when to use tool."
)
as_tool.args
```

```
{'answer_style': {'title': 'Answer Style', 'type': 'string'}}

#å‚æ•°å°±æ˜¯æç¤ºè¯æ¨¡ç‰ˆæ‰€æ¬ ç¼ºçš„å‚æ•°ï¼Œæ³¨æ„partial_variableæ˜¯ä¸ä¼šæ˜¾ç¤ºçš„
```



#### **å·¥å…·è°ƒç”¨**

##### è°ƒç”¨æ–¹æ³•

```
llm_with_tools = llm.bind_tools(tools)

query = "What is 3 * 12?"

llm_with_tools.invoke(query)
#ä½¿ç”¨bind.toolså¯ä»¥å°†å·¥å…·é›†æˆåˆ°llmä¸­ä½†æ˜¯æ³¨æ„ï¼Œè¯¥ç§æ–¹æ³•åªä¼šè°ƒç”¨å·¥å…·ä¸ä¼šæ‰§è¡Œå·¥å…·ã€‚
#åœ¨è¿™é‡Œåœ¨ä»‹ç»ä¸€ä¸ªè¾“å‡ºè§£é‡Šå™¨
#PydanticToolsParser(ï¼‰


from langchain_core.output_parsers import PydanticToolsParser
from pydantic import BaseModel, Field


class add(BaseModel):
    """Add two integers."""

    a: int = Field(..., description="First integer")
    b: int = Field(..., description="Second integer")


class multiply(BaseModel):
    """Multiply two integers."""

    a: int = Field(..., description="First integer")
    b: int = Field(..., description="Second integer")


chain = llm_with_tools | PydanticToolsParser(tools=[add, multiply])
chain.invoke(query)
#é€šè¿‡ä¼ å…¥éœ€è¦è§£æçš„å·¥å…·å°±å¯ä»¥è‡ªåŠ¨å°†å¤æ‚çš„tool_callsè½¬åŒ–ä¸º
[multiply(a=3, b=12), add(a=11, b=49)]
```

##### é’ˆå¯¹äºéšè—å‚æ•°çš„å¤„ç†

æˆ‘ä»¬ä½¿ç”¨æŸäº›å·¥å…·çš„æ—¶å€™å¸¸å¸¸ä¼šæœ‰ä¸€äº›æ¶‰åŠåˆ°ç”¨æˆ·éšç§çš„æ•°æ®æ˜¯ä¸åº”è¯¥ç”±å¤§æ¨¡å‹å¡«å…¥è€Œæ˜¯ç”±æˆ‘ä»¬æ‰‹åŠ¨å¡«å…¥ä¾‹å¦‚user_idæˆ–è€…api_keyç­‰å†…å®¹é‚£ä¹ˆæˆ‘ä»¬éœ€è¦è¿›è¡Œå‚æ•°éšè— å¯ä»¥ä½¿ç”¨ InjectedToolArgç±»å‹è¿›è¡Œæ ‡æ³¨

```
from typing import List

from langchain_core.tools import InjectedToolArg, tool
from typing_extensions import Annotated

user_to_pets = {}


@tool(parse_docstring=True)
def update_favorite_pets(
    pets: List[str], user_id: Annotated[str, InjectedToolArg]
) -> None:
    """Add the list of favorite pets.

    Args:
        pets: List of favorite pets to set.
        user_id: User's ID.
    """
    user_to_pets[user_id] = pets


@tool(parse_docstring=True)
def delete_favorite_pets(user_id: Annotated[str, InjectedToolArg]) -> None:
    """Delete the list of favorite pets.

    Args:
        user_id: User's ID.
    """
    if user_id in user_to_pets:
        del user_to_pets[user_id]


@tool(parse_docstring=True)
def list_favorite_pets(user_id: Annotated[str, InjectedToolArg]) -> None:
    """List favorite pets if any.

    Args:
        user_id: User's ID.
    """
    return user_to_pets.get(user_id, [])
```

å½“æˆ‘ä»¬ä½¿ç”¨äº†è¯¥ç±»æ—¶å…¶å®å°±æ˜¯å‘ŠçŸ¥llmï¼Œè¯¥å‚æ•°æ— éœ€ä½ å¡«å…¥
llmåœ¨ç”Ÿæˆtool_callçš„æ—¶å€™ä¼šå°†è¯¥å‚æ•°å¡«å…¥çš„å€¼è®¾ç½®ä¸ºç©ºï¼Œå…è®¸ä½ åœ¨å·¥å…·è¿è¡Œçš„æ—¶å€™è‡ªåŠ¨è¿›è¡Œå¡«å…¥ï¼ˆåœ¨è¿™é‡Œæˆ‘æ›´åŠ æ¨èä½ ä½¿ç”¨langgraphä¸“é—¨è®¾ç½®å·¥å…·èŠ‚ç‚¹æ„å»ºå¾ªç¯é“¾

å¯ä»¥å‚è€ƒ

[4.4 å¾ªç¯é“¾-langgraphç‰¹æœ‰](#44å¾ªç¯é“¾-langgraphç‰¹æœ‰)

### 6.2 React_agent

ç›®å‰æœ€ä¸ºå¸¸ç”¨çš„æ™ºèƒ½ä½“æ¶æ„å°±æ˜¯react_agent

#### æ¶æ„ä»‹ç»

ReAct çš„æ‰§è¡Œæµç¨‹æ˜¯ä¸€ä¸ª**å¾ªç¯è¿­ä»£è¿‡ç¨‹**ï¼Œä»£ç†ä¼šåå¤è¿›è¡Œä»¥ä¸‹æ­¥éª¤ï¼Œç›´åˆ°ä»»åŠ¡å®Œæˆæˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆé€šå¸¸ 5-10 æ¬¡ï¼‰ï¼š

1. **Thoughtï¼ˆæ€è€ƒï¼‰**ï¼šLLM åŸºäºå½“å‰çŠ¶æ€å’Œå†å²ä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆæ¨ç†æ­¥éª¤ï¼Œåˆ†æé—®é¢˜å¹¶è§„åˆ’ä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚ä¾‹å¦‚ï¼šâ€œæˆ‘éœ€è¦æŸ¥è¯¢å¤©æ°”æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚â€
2. **Actionï¼ˆè¡ŒåŠ¨ï¼‰**ï¼šåŸºäºæ€è€ƒç»“æœï¼Œé€‰æ‹©å¹¶è°ƒç”¨å·¥å…·ï¼ˆå¦‚æœç´¢å·¥å…·æˆ–è®¡ç®—å™¨ï¼‰ï¼Œç”Ÿæˆå…·ä½“çš„è¾“å…¥å‚æ•°ã€‚
3. **Observationï¼ˆè§‚å¯Ÿï¼‰**ï¼šæ‰§è¡Œè¡ŒåŠ¨åï¼Œè·å–å·¥å…·çš„è¾“å‡ºç»“æœï¼Œå¹¶åé¦ˆç»™ä»£ç†ã€‚
4. **å¾ªç¯**ï¼šå°†è§‚å¯Ÿç»“æœä½œä¸ºæ–°è¾“å…¥ï¼Œè¿”å›æ­¥éª¤ 1ï¼Œç»§ç»­è¿­ä»£ã€‚

**å®ƒçš„å†…éƒ¨å®ç°æœ¬è´¨å…¶å®å°±æ˜¯ä¸€ä¸ª modelèŠ‚ç‚¹å’ŒtoolèŠ‚ç‚¹ç»„æˆçš„å¾ªç¯é“¾æ¶æ„**

åœ¨langgraphä¸­å·²ç»ä¸ºä½ å°è£…ReactèŒƒå¼çš„æ™ºèƒ½ä½“ï¼šcreate_react_agent

#### **å‚æ•°ä»‹ç»**

| å‚æ•°å                | ç±»å‹ï¼ˆç®€åŒ–ï¼‰                                                 | æè¿°                                                         | æ˜¯å¦å¿…éœ€ |
| --------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | -------- |
| `model`               | Union[str, LanguageModelLike, Callable[[StateSchema, Runtime[ContextT]], BaseChatModel æˆ– Awaitable[BaseChatModel] æˆ– Runnable]] | ä»£ç†ä½¿ç”¨çš„è¯­è¨€æ¨¡å‹ï¼Œæ”¯æŒé™æ€ï¼ˆå­—ç¬¦ä¸²æˆ–å®ä¾‹ï¼‰æˆ–åŠ¨æ€ï¼ˆæ ¹æ®çŠ¶æ€/è¿è¡Œæ—¶é€‰æ‹©æ¨¡å‹çš„å‡½æ•°ï¼‰ã€‚åŠ¨æ€å‡½æ•°éœ€è¿”å›ç»‘å®šå·¥å…·çš„æ¨¡å‹ã€‚ | æ˜¯       |
| `tools`               | Union[Sequence[Union[BaseTool, Callable, dict[str, Any]]], ToolNode] | å·¥å…·åˆ—è¡¨æˆ– ToolNode å®ä¾‹ã€‚å¦‚æœä¸ºç©ºï¼Œåˆ™ä»£ç†ä»…è°ƒç”¨ LLM æ— å·¥å…·ã€‚æ”¯æŒå†…ç½®å·¥å…·ï¼ˆdict æ ¼å¼ï¼‰ã€‚ | æ˜¯       |
| `prompt`              | Optional[Prompt] (é»˜è®¤: None)                                | å¯é€‰æç¤ºæ¨¡æ¿ï¼šå­—ç¬¦ä¸²ï¼ˆè½¬ä¸º SystemMessageï¼‰ã€SystemMessageã€Callable æˆ– Runnableã€‚ç”¨äºå¼•å¯¼ LLM è¾“å‡º ReAct æ ¼å¼ã€‚ | å¦       |
| `response_format`     | Optional[Union[StructuredResponseSchema, tuple[str, StructuredResponseSchema]]] (é»˜è®¤: None) | æœ€ç»ˆè¾“å‡ºç»“æ„åŒ– schemaï¼ˆå¦‚ OpenAI å·¥å…· schemaã€JSON Schemaã€TypedDict æˆ– Pydanticï¼‰ã€‚éœ€æ¨¡å‹æ”¯æŒ `.with_structured_output()`ã€‚å¯é€‰å…ƒç»„ (prompt, schema) ç”¨äºé¢å¤–ç³»ç»Ÿæç¤ºã€‚ | å¦       |
| `pre_model_hook`      | Optional[RunnableLike] (é»˜è®¤: None)                          | LLM è°ƒç”¨å‰çš„å¯é€‰èŠ‚ç‚¹ï¼ˆRunnable æˆ– Callableï¼‰ã€‚ç”¨äºæ¶ˆæ¯ä¿®å‰ª/æ€»ç»“ç­‰ï¼Œè¿”å› {"messages": [...] æˆ– "llm_input_messages": [...]} æ›´æ–°çŠ¶æ€ã€‚ | å¦       |
| `post_model_hook`     | Optional[RunnableLike] (é»˜è®¤: None)                          | LLM è°ƒç”¨åçš„å¯é€‰èŠ‚ç‚¹ï¼ˆä»… v2 æ”¯æŒï¼‰ã€‚ç”¨äºäººæœºäº¤äº’ã€éªŒè¯ç­‰ï¼Œè¿”å›çŠ¶æ€æ›´æ–°ã€‚ | å¦       |
| `state_schema`        | Optional[StateSchemaType] (é»˜è®¤: None)                       | è‡ªå®šä¹‰å›¾çŠ¶æ€ schemaï¼ˆTypedDict æˆ– Pydanticï¼‰ã€‚å¿…é¡»åŒ…å« "messages" å’Œ "remaining_steps" é”®ï¼›è‹¥æœ‰ response_formatï¼Œåˆ™åŠ  "structured_response"ã€‚é»˜è®¤ AgentStateã€‚ | å¦       |
| `context_schema`      | Optional[Type[Any]] (é»˜è®¤: None)                             | è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ schemaï¼ˆç”¨äºåŠ¨æ€æ¨¡å‹é€‰æ‹©ï¼‰ã€‚æ›¿æ¢å·²å¼ƒç”¨çš„ config_schemaã€‚ | å¦       |
| `checkpointer`        | Optional[Checkpointer] (é»˜è®¤: None)                          | å¯é€‰æ£€æŸ¥ç‚¹ä¿å­˜å™¨ï¼Œç”¨äºæŒä¹…åŒ–çŠ¶æ€ï¼ˆå¦‚å•çº¿ç¨‹èŠå¤©è®°å¿†ï¼‰ã€‚       | å¦       |
| `store`               | Optional[BaseStore] (é»˜è®¤: None)                             | å¯é€‰å­˜å‚¨å¯¹è±¡ï¼Œç”¨äºè·¨çº¿ç¨‹æŒä¹…åŒ–æ•°æ®ï¼ˆå¦‚å¤šç”¨æˆ·å¯¹è¯ï¼‰ã€‚         | å¦       |
| `interrupt_before`    | Optional[list[str]] (é»˜è®¤: None)                             | ä¸­æ–­å‰èŠ‚ç‚¹åˆ—è¡¨ï¼ˆ"agent" æˆ– "tools"ï¼‰ã€‚ç”¨äºç”¨æˆ·ç¡®è®¤ç­‰ã€‚       | å¦       |
| `interrupt_after`     | Optional[list[str]] (é»˜è®¤: None)                             | ä¸­æ–­åèŠ‚ç‚¹åˆ—è¡¨ï¼ˆ"agent" æˆ– "tools"ï¼‰ã€‚ç”¨äºé¢å¤–å¤„ç†ã€‚         | å¦       |
| `debug`               | bool (é»˜è®¤: False)                                           | å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œè¾“å‡ºè¯¦ç»†æ—¥å¿—ã€‚                                 | å¦       |
| `version`             | Literal["v1", "v2"] (é»˜è®¤: "v2")                             | å›¾ç‰ˆæœ¬ï¼š"v1"ï¼ˆå•æ¶ˆæ¯å¹¶è¡Œå·¥å…·è°ƒç”¨ï¼‰ï¼›"v2"ï¼ˆæ¯ä¸ªå·¥å…·è°ƒç”¨ç‹¬ç«‹ Sendï¼Œæ”¯æŒ post_model_hookï¼‰ã€‚ | å¦       |
| `name`                | Optional[str] (é»˜è®¤: None)                                   | å›¾çš„åç§°ï¼Œä¾¿äºä½œä¸ºå­å›¾é›†æˆåˆ°å¤šä»£ç†ç³»ç»Ÿä¸­ã€‚                   | å¦       |
| `**deprecated_kwargs` | Any (é»˜è®¤: None)                                             | æ•è·å¼ƒç”¨å‚æ•°ï¼ˆå¦‚ config_schemaï¼Œå·²è­¦å‘Šå¹¶æ˜ å°„åˆ° context_schemaï¼‰ã€‚ | å¦       |

### 6.3 å›¾

åœ¨ä¸Šé¢å¯èƒ½å·²ç»æ¶‰åŠåˆ°äº†ä¸€äº›å…³äºlanggraphå›¾çš„ä¸€äº›ç”¨æ³•ä½†æ˜¯å¹¶æ²¡æœ‰å»è¯¦ç»†çš„ä»‹ç»ï¼Œè¿™ä¸€æ¿å—å°†è¯¦ç»†ä»‹ç»ã€‚

#### æ ¸å¿ƒæ¦‚å¿µ

LangGraph çš„å·¥ä½œæµç”±ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶æ„æˆï¼š

1.  **State (çŠ¶æ€)**: ä¸€ä¸ªå…±äº«çš„æ•°æ®ç»“æ„ï¼Œä»£è¡¨äº†åº”ç”¨åœ¨ä»»ä¸€æ—¶åˆ»çš„å¿«ç…§ã€‚å®ƒå®šä¹‰äº†å›¾çš„æ•°æ®æ¨¡å¼ï¼ˆSchemaï¼‰ã€‚
2.  **Nodes (èŠ‚ç‚¹)**: å°è£…äº†æ™ºèƒ½ä½“é€»è¾‘çš„ Python å‡½æ•°ã€‚èŠ‚ç‚¹æ¥æ”¶å½“å‰çš„çŠ¶æ€ä½œä¸ºè¾“å…¥ï¼Œæ‰§è¡Œè®¡ç®—æˆ–äº§ç”Ÿå‰¯ä½œç”¨ï¼Œå¹¶è¿”å›çŠ¶æ€çš„æ›´æ–°ã€‚
3.  **Edges (è¾¹)**: å†³å®šä¸‹ä¸€ä¸ªæ‰§è¡Œå“ªä¸ªèŠ‚ç‚¹çš„é€»è¾‘ã€‚è¾¹å¯ä»¥æ˜¯å›ºå®šçš„è½¬æ¢ï¼Œä¹Ÿå¯ä»¥æ˜¯åŸºäºå½“å‰çŠ¶æ€çš„æ¡ä»¶åˆ†æ”¯ã€‚

é€šè¿‡ç»„åˆèŠ‚ç‚¹å’Œè¾¹ï¼Œå¯ä»¥åˆ›å»ºèƒ½å¤Ÿéšæ—¶é—´æ¼”è¿›çŠ¶æ€çš„ã€å¤æ‚çš„ã€å¯å¾ªç¯çš„å·¥ä½œæµã€‚å…¶åº•å±‚ç®—æ³•å— Google çš„ Pregel ç³»ç»Ÿå¯å‘ï¼Œé€šè¿‡æ¶ˆæ¯ä¼ é€’æ¥å®šä¹‰ç¨‹åºï¼Œæ‰§è¡Œè¿‡ç¨‹ä»¥ç¦»æ•£çš„â€œè¶…æ­¥â€ï¼ˆsuper-stepsï¼‰è¿›è¡Œã€‚

**StateGraph**

`StateGraph` æ˜¯æœ€ä¸»è¦çš„å›¾æ„å»ºç±»ï¼Œå®ƒéœ€è¦ä¸€ä¸ªç”¨æˆ·å®šä¹‰çš„çŠ¶æ€å¯¹è±¡æ¥è¿›è¡Œå‚æ•°åŒ–ã€‚

**å›¾çš„æ„å»ºä¸ç¼–è¯‘**

æ„å»ºä¸€ä¸ªå›¾é€šå¸¸åŒ…å«ä»¥ä¸‹æ­¥éª¤ï¼š
1.  å®šä¹‰ `State`ã€‚
2.  ä½¿ç”¨ `add_node` æ·»åŠ èŠ‚ç‚¹ã€‚
3.  ä½¿ç”¨ `add_edge` æˆ– `add_conditional_edges` æ·»åŠ è¾¹ã€‚
4.  è°ƒç”¨ `.compile()` æ–¹æ³•è¿›è¡Œç¼–è¯‘ã€‚

**ç¼–è¯‘æ˜¯å¿…é¡»çš„**ï¼Œå®ƒä¼šè¿›è¡Œä¸€äº›åŸºç¡€çš„ç»“æ„æ£€æŸ¥ï¼ˆå¦‚æ˜¯å¦å­˜åœ¨å­¤ç«‹èŠ‚ç‚¹ï¼‰ï¼Œå¹¶ä¸”æ˜¯é…ç½®æ£€æŸ¥ç‚¹ï¼ˆcheckpointersï¼‰å’Œæ–­ç‚¹ç­‰è¿è¡Œæ—¶å‚æ•°çš„åœ°æ–¹ã€‚

```python
# ç¤ºä¾‹
graph = graph_builder.compile()
```

####  stateï¼ˆçŠ¶æ€ï¼‰

çŠ¶æ€æ˜¯ Langgraphä¸­ä¸€ä¸ªé‡è¦çš„æ¦‚å¿µï¼Œå®ƒå…è®¸ä½ åœ¨é“¾å’Œä»£ç†ä¸­å­˜å‚¨å’Œä¼ é€’æ•°æ®ã€‚LangGraph æä¾›äº† `State` ç±»æ¥ç®¡ç†çŠ¶æ€ã€‚
state å¯ä»¥å…è®¸ä½¿ç”¨typedictï¼Œdataclassï¼Œpydantic åˆ›å»ºã€‚

æŒ‡å®šå›¾å½¢æ¶æ„çš„ä½ å¯ä»¥ä½¿ç”¨ TypedDictï¼ˆæ¯”å¦‚graphçš„è¾“å…¥è¾“å‡ºï¼Œæ˜¯å›ºå®šï¼Œç”±äºtypedictæ— æ³•åˆå§‹åŒ–ï¼Œæ‰€ä»¥å¦‚æœæœªæä¾›é»˜è®¤å€¼ï¼Œå°±ä¼šæŠ¥é”™ï¼‰ã€‚å¦‚æœè¦åœ¨çŠ¶æ€ä¸­æä¾›é»˜è®¤å€¼ï¼Œè¯·ä½¿ç”¨dataclass ã€‚å¦‚æœæ‚¨æƒ³è¦é€’å½’æ•°æ®éªŒè¯ï¼Œæˆ‘ä»¬è¿˜æ”¯æŒä½¿ç”¨ Pydantic BaseModel ä½œä¸ºå›¾å½¢çŠ¶æ€ï¼ˆä½†è¯·æ³¨æ„ï¼Œpydantic çš„æ€§èƒ½ä¸å¦‚ TypedDict æˆ–database ï¼‰ã€‚

æ¥ä¸‹æ¥æˆ‘å°†å…ˆè¿›è¡Œç›¸å…³åŸºç¡€çŸ¥è¯†çš„è¡¥å……

##### å¸¸è§type

| ç±»å‹æç¤º                  | ä½•æ—¶ä½¿ç”¨                                             | ç¤ºä¾‹                                                        |
| :------------------------ | :--------------------------------------------------- | :---------------------------------------------------------- |
| `Optional[T]` æˆ– `T|None` | å½“ä¸€ä¸ªå€¼å¯ä»¥æ˜¯æŸä¸ªç±»å‹ï¼Œä¹Ÿå¯èƒ½æ˜¯ `None` æ—¶ã€‚         | `Optional[str]` æˆ– `str | None`                             |
| `Annotated[T, Meta]`      | å½“ä½ éœ€è¦ä¸ºç±»å‹é™„åŠ é¢å¤–ä¿¡æ¯ï¼ˆå¦‚éªŒè¯è§„åˆ™ã€æç¤ºä¿¡æ¯ï¼‰ã€‚ | `name: Annotated[str, Field(max_length=50)]`                |
| `Union[T1, T2]`           | å½“ä¸€ä¸ªå€¼å¯ä»¥æ˜¯å¤šç§ä¸åŒç±»å‹ä¸­çš„ä¸€ç§æ—¶ã€‚               | `Union[int, str]` æˆ– `int | str`                            |
| `list[T]`, `dict[K, V]`ç­‰ | ä¸ºæ ‡å‡†å®¹å™¨ç±»å‹æŒ‡å®šå…¶å†…éƒ¨å…ƒç´ çš„ç±»å‹ã€‚                 | `scores: list[int]` `dict[str,int]` è¡¨ç¤ºkeyä¸ºstr valueä¸ºint |
| `Literal[...]`            | å½“ä¸€ä¸ªå˜é‡çš„å€¼å¿…é¡»æ˜¯å‡ ä¸ªé¢„å®šä¹‰çš„å¸¸é‡ä¹‹ä¸€æ—¶ã€‚         | `status: Literal["pending", "success", "failed"]`           |
| `Callable[...]`           | å½“å‚æ•°æˆ–è¿”å›å€¼æ˜¯ä¸€ä¸ªå‡½æ•°æ—¶ã€‚                         | `callback: Callable[[str], None]`                           |

###### **pydanticä»‹ç»-Field**

å®ƒå…è®¸ä½ ä¸ºæ¨¡å‹çš„å­—æ®µå£°æ˜é¢å¤–çš„å…ƒæ•°æ®å’ŒéªŒè¯çº¦æŸã€‚é€šå¸¸ä¸ `typing.Annotated` ç»“åˆä½¿ç”¨ï¼Œä»¥ä¿æŒç±»å‹æç¤ºçš„æ¸…æ™°æ€§ã€‚

**åŸºæœ¬ç”¨æ³•**:

```python
from typing import Annotated
from pydantic import BaseModel, Field

class MyModel(BaseModel):
    # Annotated[<type>, Field(...)] æ˜¯æ¨èçš„ç°ä»£ç”¨æ³•
    my_field: Annotated[str, Field(
        description="This is a description for my_field.",
        min_length=3,
        # ... å…¶ä»–å‚æ•°
    )]
```

**`Field` ä¸»è¦å‚æ•°åˆ†ç±»ä»‹ç»**

æˆ‘ä»¬å°† `Field` çš„å¸¸ç”¨å‚æ•°åˆ†ä¸ºå‡ ç±»ï¼šé€šç”¨å…ƒæ•°æ®ã€å­—ç¬¦ä¸²éªŒè¯ã€æ•°å­—éªŒè¯ã€ä»¥åŠå…¶ä»–é«˜çº§åŠŸèƒ½ã€‚

**é€šç”¨å…ƒæ•°æ®å‚æ•°**

è¿™äº›å‚æ•°ä¸»è¦ç”¨äºæ–‡æ¡£ç”Ÿæˆã€JSON Schema è¾“å‡ºå’Œæä¾›å­—æ®µæè¿°ä¿¡æ¯ã€‚

| å‚æ•°                  | ç±»å‹                | æè¿°                                                         | ç¤ºä¾‹                                             |
| :-------------------- | :------------------ | :----------------------------------------------------------- | :----------------------------------------------- |
| `default`             | `Any`               | ä¸ºå­—æ®µæä¾›ä¸€ä¸ªé™æ€çš„é»˜è®¤å€¼ã€‚å¦‚æœå­—æ®µæœ‰æ­¤å‚æ•°ï¼Œåˆ™å˜ä¸ºå¯é€‰ã€‚   | `Field(default=100)`                             |
| `default_factory`     | `Callable[[], Any]` | ä¸€ä¸ªæ— å‚æ•°çš„å¯è°ƒç”¨å¯¹è±¡ï¼ˆå¦‚å‡½æ•°ï¼‰ï¼Œç”¨äºç”ŸæˆåŠ¨æ€çš„é»˜è®¤å€¼ã€‚**ç”¨äºå¯å˜ç±»å‹ï¼ˆå¦‚ `list`, `dict`ï¼‰**ã€‚ | `Field(default_factory=list)`                    |
| `description`         | `str`               | å­—æ®µçš„è¯¦ç»†æ–‡å­—æè¿°ï¼Œä¼šå‡ºç°åœ¨ç”Ÿæˆçš„ JSON Schema å’Œæ–‡æ¡£ä¸­ã€‚    | `Field(description="User's unique identifier.")` |
| `title`               | `str`               | å­—æ®µçš„ç®€çŸ­ã€äººç±»å¯è¯»çš„æ ‡é¢˜ã€‚                                 | `Field(title="User ID")`                         |
| `examples`            | `list[Any]`         | ä¸€ä¸ªåŒ…å«ç¤ºä¾‹å€¼çš„åˆ—è¡¨ï¼Œç”¨äºæ–‡æ¡£å’Œ API å·¥å…·ã€‚                  | `Field(examples=["user-123", "user-456"])`       |
| `deprecated`          | `bool`              | æ ‡è®°æ­¤å­—æ®µæ˜¯å¦å·²å¼ƒç”¨ã€‚åœ¨æ–‡æ¡£ä¸­ä¼šæ˜¾ç¤ºè­¦å‘Šã€‚                   | `Field(deprecated=True)`                         |
| `alias`               | `str`               | ä¸ºå­—æ®µè®¾ç½®ä¸€ä¸ªåˆ«åã€‚åœ¨æ•°æ®è¾“å…¥å’Œè¾“å‡ºæ—¶ä½¿ç”¨æ­¤åˆ«åã€‚           | `Field(alias="user-id")` (æ¨¡å‹ä¸­ç”¨ `user_id`)    |
| `validation_alias`    | `str`               | **ä»…åœ¨è¾“å…¥æ—¶**ä½¿ç”¨çš„åˆ«åï¼Œç”¨äºæ•°æ®éªŒè¯å’Œè§£æã€‚               | `Field(validation_alias="userId")`               |
| `serialization_alias` | `str`               | **ä»…åœ¨è¾“å‡ºæ—¶**ï¼ˆå¦‚ `.model_dump()`ï¼‰ä½¿ç”¨çš„åˆ«åã€‚             | `Field(serialization_alias="userIdentifier")`    |
| `repr`                | `bool`              | æ§åˆ¶æ­¤å­—æ®µæ˜¯å¦åº”åŒ…å«åœ¨æ¨¡å‹çš„ `__repr__` è¾“å‡ºä¸­ã€‚é»˜è®¤ä¸º `True`ã€‚ | `Field(repr=False)` (éšè—æ•æ„Ÿä¿¡æ¯å¦‚å¯†ç )         |

**æ•°å­—éªŒè¯å‚æ•° (`int`, `float`, `Decimal`)**

è¿™äº›å‚æ•°ç”¨äºå¯¹æ•°å­—ç±»å‹çš„å€¼æ–½åŠ èŒƒå›´çº¦æŸã€‚

| å‚æ•°          | å«ä¹‰                             | æ•°å­¦è¡¨ç¤º                   | ç¤ºä¾‹                                   |
| :------------ | :------------------------------- | :------------------------- | :------------------------------------- |
| `gt`          | **G**reater **T**han             | `> value`                  | `Field(gt=0)` (å¿…é¡»å¤§äº0)              |
| `ge`          | **G**reater than or **E**qual to | `>= value`                 | `Field(ge=0)` (å¿…é¡»å¤§äºç­‰äº0)          |
| `lt`          | **L**ess **T**han                | `< value`                  | `Field(lt=100)` (å¿…é¡»å°äº100)          |
| `le`          | **L**ess than or **E**qual to    | `<= value`                 | `Field(le=100)` (å¿…é¡»å°äºç­‰äº100)      |
| `multiple_of` | å€æ•°                             | `value % multiple_of == 0` | `Field(multiple_of=5)` (å¿…é¡»æ˜¯5çš„å€æ•°) |

**å­—ç¬¦ä¸²éªŒè¯å‚æ•° (`str`, `bytes`)**

è¿™äº›å‚æ•°ç”¨äºå¯¹å­—ç¬¦ä¸²æˆ–å­—èŠ‚åºåˆ—çš„æ ¼å¼å’Œé•¿åº¦è¿›è¡Œçº¦æŸã€‚

| å‚æ•°         | ç±»å‹  | æè¿°                                 | ç¤ºä¾‹                                |
| :----------- | :---- | :----------------------------------- | :---------------------------------- |
| `min_length` | `int` | å­—ç¬¦ä¸²çš„æœ€å°é•¿åº¦ï¼ˆåŒ…å«ï¼‰ã€‚           | `Field(min_length=3)`               |
| `max_length` | `int` | å­—ç¬¦ä¸²çš„æœ€å¤§é•¿åº¦ï¼ˆåŒ…å«ï¼‰ã€‚           | `Field(max_length=50)`              |
| `pattern`    | `str` | ä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼ï¼Œå­—ç¬¦ä¸²å¿…é¡»ä¸ä¹‹åŒ¹é…ã€‚ | `Field(pattern=r"^[a-zA-Z0-9_]+$")` |

**é›†åˆ/åˆ—è¡¨éªŒè¯å‚æ•° (`list`, `set`, `tuple`)**

è¿™äº›å‚æ•°ç”¨äºå¯¹åŒ…å«å¤šä¸ªé¡¹çš„é›†åˆç±»å‹è¿›è¡Œçº¦æŸã€‚

| å‚æ•°                       | ç±»å‹  | æè¿°               | ç¤ºä¾‹                                 |
| :------------------------- | :---- | :----------------- | :----------------------------------- |
| `min_length` / `min_items` | `int` | é›†åˆä¸­æœ€å°‘çš„é¡¹æ•°ã€‚ | `Field(min_length=1)` (åˆ—è¡¨ä¸èƒ½ä¸ºç©º) |
| `max_length` / `max_items` | `int` | é›†åˆä¸­æœ€å¤šçš„é¡¹æ•°ã€‚ | `Field(max_length=5)` (æœ€å¤š5ä¸ªæ ‡ç­¾)  |

*æ³¨æ„: `min_items` å’Œ `max_items` æ˜¯æ—§ç‰ˆ Pydantic çš„å«æ³•ï¼Œç°åœ¨æ¨èç»Ÿä¸€ä½¿ç”¨ `min_length` å’Œ `max_length` ä»¥ä¿æŒä¸€è‡´æ€§ã€‚*

**å…¶ä»–é«˜çº§å‚æ•°**

è¿™äº›å‚æ•°æä¾›äº†æ›´ç²¾ç»†çš„æ§åˆ¶ã€‚

| å‚æ•°               | ç±»å‹   | æè¿°                                                         | ç¤ºä¾‹                                                         |
| :----------------- | :----- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| `exclude`          | `bool` | å¦‚æœä¸º `True`ï¼Œæ­¤å­—æ®µåœ¨ `.model_dump()` æ—¶é»˜è®¤è¢«æ’é™¤ã€‚       | `Field(exclude=True)`                                        |
| `include`          | `bool` | (ä¸å¸¸ç”¨) å¦‚æœä¸º `True`ï¼Œå³ä½¿åœ¨ `.model_dump(exclude_unset=True)` æ—¶ï¼Œå¦‚æœå­—æ®µæœ‰é»˜è®¤å€¼ï¼Œä¹Ÿä¼šè¢«åŒ…å«ã€‚ | `Field(include=True)`                                        |
| `discriminator`    | `str`  | ç”¨äº `Union` ç±»å‹çš„é‰´åˆ«å™¨ã€‚æ ¹æ®æ­¤å­—æ®µçš„å€¼æ¥å†³å®šä½¿ç”¨ `Union` ä¸­çš„å“ªä¸ªæ¨¡å‹ã€‚ | `Field(discriminator="pet_type")`                            |
| `frozen`           | `bool` | å¦‚æœä¸º `True`ï¼Œåˆ™è¯¥å­—æ®µåœ¨æ¨¡å‹å®ä¾‹åˆ›å»ºåä¸å¯ä¿®æ”¹ã€‚            | `Field(frozen=True)`                                         |
| `validate_default` | `bool` | å¦‚æœä¸º `True`ï¼ŒPydantic ä¼šå¯¹å­—æ®µçš„é»˜è®¤å€¼ä¹Ÿæ‰§è¡ŒéªŒè¯ã€‚é»˜è®¤ä¸º `False`ã€‚ | `Field(default="abc", min_length=5, validate_default=True)` (ä¼šæŠ¥é”™) |

**ç»¼åˆç¤ºä¾‹**

```python
import uuid
from typing import Annotated, List
from pydantic import BaseModel, Field

class User(BaseModel):
    # ä½¿ç”¨åˆ«åï¼Œæœ‰æè¿°ï¼Œä¸”å¿…éœ€
    id: Annotated[
        uuid.UUID,
        Field(
            default_factory=uuid.uuid4,
            title="User's Unique Identifier",
            description="A standard UUID4 for identifying the user.",
            alias="userId",
            repr=False # ä¸åœ¨ repr ä¸­æ˜¾ç¤º
        )
    ]

    # å­—ç¬¦ä¸²éªŒè¯
    username: Annotated[
        str,
        Field(
            description="Username must be 3 to 20 alphanumeric characters.",
            min_length=3,
            max_length=20,
            pattern=r"^[a-zA-Z0-9_]+$"
        )
    ]

    # æ•°å­—éªŒè¯
    age: Annotated[
        int,
        Field(
            description="User's age, must be between 18 and 120.",
            gt=17,
            le=120
        )
    ]

    # åˆ—è¡¨éªŒè¯
    tags: Annotated[
        List[str],
        Field(
            description="A list of user tags, max 5 tags.",
            max_length=5,
            default_factory=list
        )
    ]

# åˆ›å»ºå®ä¾‹
user_data = {
    "userId": "a1b2c3d4-e5f6-7890-1234-567890abcdef",
    "username": "john_doe_123",
    "age": 30,
    "tags": ["vip", "new_user"]
}

user = User(**user_data)

print(user)
# > username='john_doe_123' age=30 tags=['vip', 'new_user'] (idè¢«repr=Falseéšè—äº†)

print(user.model_dump(by_alias=True))
# > {'userId': UUID('a1b2c3d4-e5f6-7890-1234-567890abcdef'), 'username': 'john_doe_123', 'age': 30, 'tags': ['vip', 'new_user']}
```

###### **dataclassä»‹ç»**

**åŸºæœ¬ç”¨æ³•**

åªéœ€åœ¨ç±»å®šä¹‰å‰åŠ ä¸Š `@dataclass` è£…é¥°å™¨ï¼Œå¹¶ä½¿ç”¨ç±»å‹æç¤ºå®šä¹‰å±æ€§å³å¯ã€‚

```python
from dataclasses import dataclass

@dataclass
class Point:
    x: int
    y: int

# ç¤ºä¾‹
p1 = Point(10, 20)
```

**`dataclass` è£…é¥°å™¨çš„å‚æ•°**

`@dataclass` è£…é¥°å™¨æ¥å—ä»¥ä¸‹å‚æ•°æ¥æ§åˆ¶ç”Ÿæˆæ–¹æ³•çš„è¡Œä¸ºï¼š

| å‚æ•°          | æè¿°                                                         | é»˜è®¤å€¼  |
| :------------ | :----------------------------------------------------------- | :------ |
| `init`        | æ˜¯å¦ç”Ÿæˆ `__init__` æ–¹æ³•                                     | `True`  |
| `repr`        | æ˜¯å¦ç”Ÿæˆ `__repr__` æ–¹æ³•                                     | `True`  |
| `eq`          | æ˜¯å¦ç”Ÿæˆ `__eq__` æ–¹æ³•                                       | `True`  |
| `order`       | æ˜¯å¦ç”Ÿæˆç”¨äºæ¯”è¾ƒçš„æ–¹æ³• (`__lt__`, `__le__`, `__gt__`, `__ge__`) | `False` |
| `unsafe_hash` | å¼ºåˆ¶ç”Ÿæˆ `__hash__` æ–¹æ³•ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰                         | `False` |
| `frozen`      | ä½¿å®ä¾‹ä¸å¯å˜ï¼ˆå°è¯•ä¿®æ”¹å±æ€§ä¼šæŠ›å‡º `FrozenInstanceError`ï¼‰     | `False` |

**ç¤ºä¾‹ï¼šä½¿ç”¨å‚æ•°**

```python
from dataclasses import dataclass, field, FrozenInstanceError

@dataclass(order=True, frozen=True)
class Product:
    name: str
    price: float
    quantity: int = 0  # å­—æ®µå¯ä»¥æœ‰é»˜è®¤å€¼

# ç¤ºä¾‹
apple = Product("Apple", 1.0, 5)
banana = Product("Banana", 0.5, 10)
apple_clone = Product("Apple", 1.0, 5)

print(apple)
# è¾“å‡º: Product(name='Apple', price=1.0, quantity=5)

# order=True å…è®¸æ¯”è¾ƒ
print(apple > banana)
# è¾“å‡º: True (åŸºäºå­—æ®µé¡ºåº: name, price, quantity)
# frozen=True ä½¿å®ä¾‹ä¸å¯å˜
try:
    apple.price = 1.2
except FrozenInstanceError as e:
    print(e)
# è¾“å‡º: cannot assign to field 'price'

# frozen=True è‡ªåŠ¨ç”Ÿæˆ __hash__
product_set = {apple, banana, apple_clone}
print(product_set)
# è¾“å‡º: {Product(name='Apple', price=1.0, quantity=5), Product(name='Banana', price=0.5, quantity=10)}
```

**`field()` å‡½æ•°**

ç”±äºdataclassæ— æ³•åƒpydanticä¸€æ ·å¯ä»¥è¿›è¡Œæ•°æ®éªŒè¯ï¼Œæ‰€ä»¥åœ¨fieldé‡Œé¢å¸¸ç”¨çš„å°±æ˜¯ defaultï¼Œdefault_factory å’Œ descriptionã€‚ç”¨æ³•å’Œpydanticä¸€è‡´ï¼Œæˆ‘å°±ä¸åœ¨ç»™å‡ºä¾‹å­  

##### Reducers (å½’çº³å‡½æ•°)

Reducer å®šä¹‰äº†èŠ‚ç‚¹çš„æ›´æ–°å¦‚ä½•åº”ç”¨åˆ° `State` ä¸Šã€‚`State` ä¸­çš„æ¯ä¸ªé”®ï¼ˆkeyï¼‰éƒ½æœ‰è‡ªå·±ç‹¬ç«‹çš„ Reducerã€‚

-   **é»˜è®¤ Reducer**: å¦‚æœä¸æŒ‡å®šï¼Œé»˜è®¤è¡Œä¸ºæ˜¯**è¦†ç›–**ã€‚å³èŠ‚ç‚¹è¿”å›çš„æ›´æ–°ä¼šç›´æ¥æ›¿æ¢æ‰çŠ¶æ€ä¸­å¯¹åº”é”®çš„å€¼ã€‚
-   **è‡ªå®šä¹‰ Reducer**: å¯ä»¥ä½¿ç”¨ `typing.Annotated` ä¸ºç‰¹å®šçš„é”®æŒ‡å®šä¸€ä¸ª Reducer å‡½æ•°ã€‚ä¸€ä¸ªå¸¸è§çš„ä¾‹å­æ˜¯ä½¿ç”¨ `operator.add` æ¥å®ç°åˆ—è¡¨çš„è¿½åŠ ï¼Œè€Œä¸æ˜¯è¦†ç›–ã€‚

```python
from typing import Annotated
from typing_extensions import TypedDict
from operator import add

class State(TypedDict):
    foo: int
    # bar çš„æ›´æ–°å°†é€šè¿‡ add å‡½æ•°è¿›è¡Œï¼Œå®ç°è¿½åŠ æ•ˆæœ
    bar: Annotated[list[str], add]
```

##### Messages (æ¶ˆæ¯)

åœ¨ LLM åº”ç”¨ä¸­ï¼Œå°†å¯¹è¯å†å²ä½œä¸ºæ¶ˆæ¯åˆ—è¡¨å­˜å‚¨åœ¨çŠ¶æ€ä¸­éå¸¸æ™®éã€‚

-   **`add_messages` Reducer**: LangGraph æä¾›äº†ä¸€ä¸ªé¢„æ„å»ºçš„ `add_messages` Reducerã€‚å®ƒä¸ä»…èƒ½å°†æ–°æ¶ˆæ¯è¿½åŠ åˆ°åˆ—è¡¨ä¸­ï¼Œè¿˜èƒ½æ ¹æ®æ¶ˆæ¯ ID æ›´æ–°å·²æœ‰çš„æ¶ˆæ¯ï¼Œè¿™å¯¹äºå®ç°"human-in-the-loop"ç­‰åœºæ™¯è‡³å…³é‡è¦ã€‚åŒæ—¶ï¼Œå®ƒè¿˜æ”¯æŒè‡ªåŠ¨ååºåˆ—åŒ–ã€‚
-   **`MessagesState`**: è¿™æ˜¯ä¸€ä¸ªé¢„æ„å»ºçš„çŠ¶æ€ç±»ï¼Œå®ƒå†…ç½®äº†ä¸€ä¸ªåä¸º `messages` çš„é”®ï¼Œå¹¶è‡ªåŠ¨ä½¿ç”¨äº† `add_messages` ä½œä¸ºå…¶ Reducerï¼Œæ–¹ä¾¿ç›´æ¥ç»§æ‰¿å’Œæ‰©å±•ã€‚

```python
from langgraph.graph import MessagesState

class MyAgentState(MessagesState):
    # å¯ä»¥æ·»åŠ æ›´å¤šè‡ªå®šä¹‰çš„çŠ¶æ€å­—æ®µ
    documents: list[str]
```

##### çŠ¶æ€å®ä¾‹è®²è§£

```
class InputState(TypedDict):
    user_input: str

class OutputState(TypedDict):
    graph_output: str

class OverallState(TypedDict):
    foo: str
    user_input: str
    graph_output: str

class PrivateState(TypedDict):
    bar: str

def node_1(state: InputState) -> OverallState:
    # Write to OverallState
    return {"foo": state["user_input"] + " name"}

def node_2(state: OverallState) -> PrivateState:
    # Read from OverallState, write to PrivateState
    return {"bar": state["foo"] + " is"}

def node_3(state: PrivateState) -> OutputState:
    # Read from PrivateState, write to OutputState
    return {"graph_output": state["bar"] + " Lance"}

builder = StateGraph(OverallState,input_schema=InputState,output_schema=OutputState)
builder.add_node("node_1", node_1)
builder.add_node("node_2", node_2)
builder.add_node("node_3", node_3)
builder.add_edge(START, "node_1")
builder.add_edge("node_1", "node_2")
builder.add_edge("node_2", "node_3")
builder.add_edge("node_3", END)

graph = builder.compile()
graph.invoke({"user_input":"My"})
# {'graph_output': 'My name is Lance'}
```

---

**ä¸»è¦å‚æ•°ä»‹ç»**

å¯ä»¥çœ‹åˆ°åœ¨stateGraphä¸­æˆ‘ä»¬å¯ä»¥ä¼ å…¥ä¸€ä¸ªinput_schemaå’Œoutput_schemaï¼Œä»¥åŠä¸€ä¸ªè´¯ç©¿å…¨å±€çš„stateã€‚

input_schema æ˜¯è¾“å…¥ç±»å‹ï¼Œå½“è®¾å®šè¯¥å‚æ•°ä¹‹åï¼Œä»–å°±ä¼šä»è¾“å…¥ä¸­æå–ç›¸å…³å‚æ•°ç„¶åä½œä¸ºåˆå§‹èŠ‚ç‚¹è¾“å…¥ï¼Œoutput_schema æ˜¯æœ€ç»ˆèŠ‚ç‚¹çš„è¾“å‡ºç±»å‹,å®ƒç”¨æ¥ä»çŠ¶æ€é€šé“é‡Œé¢æŒ‰ç…§keyè¿›è¡Œæå–å¹¶è¿”å›ã€‚å®ƒçš„ä¸»è¦ä½œç”¨æ˜¯ä½ ä¸å¸Œæœ›æœ€ç»ˆçš„è¾“å‡ºæ‰“å°æ‰€æœ‰çš„stateæˆ–è€…åœ¨å¤šæ™ºèƒ½ä½“ååŒä¸­ä¸å¸Œæœ›ä¼ é€’ç‹¬å±äºæœ¬æ¨¡å‹çš„ç§æœ‰æ•°æ®ã€‚

output_schema å¦‚æœä¸è®¾å®šï¼Œé‚£ä¹ˆæœ€ç»ˆinvokeçš„è¾“å‡ºå°±æ˜¯å…¨å±€state

---

**çŠ¶æ€æ›´æ–°**
åœ¨èŠ‚ç‚¹ä¸­å†™å…¥çŠ¶æ€æ˜¯æ²¡æœ‰é™åˆ¶çš„


è´¯ç©¿å…¨å±€çš„stateæ˜¯ä¸€ä¸ªæ•´ä½“çš„çŠ¶æ€ï¼Œå®ƒå¯ä»¥è¢«æ‰€æœ‰èŠ‚ç‚¹è¯»å–å’Œå†™å…¥ï¼Œéœ€è¦æ³¨æ„çš„ç‚¹æ˜¯åªæœ‰èŠ‚ç‚¹çº§åˆ«çš„æ‰å¯ä»¥ç”¨æ¥æ›´æ–°çŠ¶æ€ï¼Œè€Œå·¥å…·çº§åˆ«çš„ä¸å¯ä»¥ã€‚

å…¶æ¬¡è§‚å¯Ÿåˆ°äº†ä¸€ä¸ªè²Œä¼¼æ²¡æœ‰ä¼ å…¥graphçš„state PrivateState  è¿™ä¸ªå¯ä»¥ä½œä¸ºç§æœ‰çŠ¶æ€ï¼Œå®ƒåªåœ¨èŠ‚ç‚¹å†…éƒ¨ä½¿ç”¨ï¼Œä¸ä¼šè¢«å¤–éƒ¨è®¿é—®ã€‚æ›´æ–°çš„çŠ¶æ€ä¹Ÿä¸ä¼šå‡ºç°åœ¨å…¨å±€stateä¸­ï¼Œä½†æ˜¯å´èƒ½å¤Ÿæ›´æ–°ï¼Œä¾›å†…éƒ¨èŠ‚ç‚¹ä½¿ç”¨ã€‚

    state=graph.get_state(config=thread_config)
    print(state)
    ## è¾“å‡ºï¼š StateSnapshot(values={'foo': 'My name', 'user_input': 'My', 'graph_output': 'My name is Lance', 'bar': 'My name is'}ï¼‰

å¯æ˜¯çœ‹åˆ°ç§æœ‰stateä¹Ÿæ˜¯çœŸæ­£è¢«å¡«å…¥çš„ï¼Œä½†æ˜¯æ³¨æ„ç§æœ‰stateåœ¨å…¨å±€çŠ¶æ€æ˜¯è®¿é—®ä¸åˆ°çš„ã€‚


åŒæ—¶éœ€è¦æ³¨æ„ä¸€ç‚¹ï¼Œå¦‚æœä¸»å›¾å’Œå­å›¾æ‹¥æœ‰åŒåçš„çŠ¶æ€å‚æ•°ï¼Œä»–ä»¬çš„æ›´æ–°é€»è¾‘æ˜¯ä¸åŒçš„ï¼Œåœ¨ä¸»å›¾ä¸­æ›´æ–°çš„æ˜¯ä¸»å›¾çŠ¶æ€ï¼Œåœ¨å­å›¾ä¸­æ›´æ–°çš„æ˜¯å­å›¾çŠ¶æ€ï¼Œå¦‚æœä¸è¿›è¡ŒçŠ¶æ€æ›´æ–°ï¼ˆå³é€šè¿‡è½¬äº¤æ›´æ–°ä¸»å›¾çŠ¶æ€ï¼‰é‚£ä¹ˆå³ä½¿åœ¨å­å›¾ä¿®æ”¹è¯¥å‚æ•°ï¼Œé‚£ä¹ˆä½ åœ¨ä¸»å›¾ä¸­è®¿é—®çš„è¿˜æ˜¯æœªä¿®æ”¹çš„å†…å®¹ã€‚

#### Nodes (èŠ‚ç‚¹)

èŠ‚ç‚¹æ˜¯æ‰§è¡Œå…·ä½“é€»è¾‘çš„ Python å‡½æ•°ï¼Œå¯ä»¥åŒæ­¥æˆ–å¼‚æ­¥ã€‚

- **å‡½æ•°ç­¾å**: èŠ‚ç‚¹å‡½æ•°æ¥æ”¶ `state` å’Œå¯é€‰çš„ `config` (`RunnableConfig`) ä½œä¸ºå‚æ•°ã€‚

- **æ·»åŠ èŠ‚ç‚¹**: ä½¿ç”¨ `graph_builder.add_node("node_name", node_function)` æ·»åŠ ã€‚

- **ç‰¹æ®ŠèŠ‚ç‚¹**:
  -   `START`: ä¸€ä¸ªè™šæ‹Ÿçš„èµ·å§‹èŠ‚ç‚¹ï¼Œç”¨äºå®šä¹‰å›¾çš„å…¥å£è¾¹ã€‚
  -   `END`: ä¸€ä¸ªè™šæ‹Ÿçš„ç»ˆæ­¢èŠ‚ç‚¹ï¼Œè¡¨ç¤ºå·¥ä½œæµçš„ç»“æŸã€‚

- **èŠ‚ç‚¹ç¼“å­˜ (Caching)**: LangGraph æ”¯æŒèŠ‚ç‚¹çº§åˆ«çš„ç¼“å­˜ï¼Œä»¥é¿å…é‡å¤æ‰§è¡Œæ˜‚è´µçš„è®¡ç®—ã€‚å¯ä»¥åœ¨ `compile()` æ—¶ä¼ å…¥ä¸€ä¸ªç¼“å­˜å®ä¾‹ï¼Œå¹¶åœ¨ `add_node` æ—¶æŒ‡å®š `cache_policy`ã€‚

  ```python
  import time
  from typing_extensions import TypedDict
  from langgraph.graph import StateGraph
  from langgraph.cache.memory import InMemoryCache
  from langgraph.types import CachePolicy
  
  
  class State(TypedDict):
      x: int
      result: int
  
  
  builder = StateGraph(State)
  
  
  def expensive_node(state: State) -> dict[str, int]:
      # expensive computation
      time.sleep(2)
      return {"result": state["x"] * 2}
  
  
  builder.add_node("expensive_node", expensive_node, cache_policy=CachePolicy(ttl=3))
  builder.set_entry_point("expensive_node")
  builder.set_finish_point("expensive_node")
  
  graph = builder.compile(cache=InMemoryCache())
  
  print(graph.invoke({"x": 5}, stream_mode='updates'))    
  [{'expensive_node': {'result': 10}}]
  print(graph.invoke({"x": 5}, stream_mode='updates'))    
  [{'expensive_node': {'result': 10}, '__metadata__': {'cached': True}}]
  ```

  ttlä»£è¡¨å­˜å‚¨ç¼“å­˜çš„æ—¶é—´ï¼ˆsï¼‰è¶…è¿‡äº†æ—¶é—´å°±ä¼šæ¸…é™¤ç¼“å­˜

  ç¼“å­˜keyæ˜¯æ ¹æ®å½“å‰ä¼ å…¥çš„stateå’ŒèŠ‚ç‚¹åå­—ç”Ÿæˆçš„key

---

#### Edges (è¾¹)

è¾¹å®šä¹‰äº†å›¾çš„æ§åˆ¶æµã€‚

-   **æ™®é€šè¾¹ (`add_edge`)**: å®šä¹‰ä»ä¸€ä¸ªèŠ‚ç‚¹åˆ°å¦ä¸€ä¸ªèŠ‚ç‚¹çš„å›ºå®šè·¯å¾„ã€‚
    ```python
    graph.add_edge("node_a", "node_b")
    ```
-   **æ¡ä»¶è¾¹ (`add_conditional_edges`)**: åŸºäºä¸€ä¸ªè·¯ç”±å‡½æ•°ï¼ˆrouting functionï¼‰çš„è¾“å‡ºæ¥åŠ¨æ€å†³å®šä¸‹ä¸€ä¸ªèŠ‚ç‚¹ã€‚è¯¥å‡½æ•°æ¥æ”¶å½“å‰çŠ¶æ€ï¼Œè¿”å›ä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„åç§°ï¼ˆæˆ–åç§°åˆ—è¡¨ï¼‰ã€‚
    ```python
    def should_continue(state):
        # ... logic ...
        return "end" if finished else "continue"
    
    graph.add_conditional_edges("node_a", should_continue, {"continue": "node_b", "end": END})
    ```
-   **å…¥å£ç‚¹ (`Entry Point`)**: ä» `START` èŠ‚ç‚¹è¿æ¥ä¸€æ¡è¾¹ï¼Œä»¥æŒ‡å®šå›¾çš„èµ·å§‹èŠ‚ç‚¹ã€‚
    ```python
    from langgraph.graph import START
    graph.add_edge(START, "node_a")
    ```
-   **æ¡ä»¶å…¥å£ç‚¹**: ä¹Ÿå¯ä»¥ä» `START` ä½¿ç”¨æ¡ä»¶è¾¹ï¼Œæ ¹æ®è¾“å…¥åŠ¨æ€é€‰æ‹©èµ·å§‹èŠ‚ç‚¹ã€‚

#### `Send` å’Œ `Command`

-   **`Send`**:

     åœ¨æ¡ä»¶è¾¹ä¸­è¿”å›ä¸€ä¸ª `Send` å¯¹è±¡ï¼Œå¯ä»¥å‘æŒ‡å®šçš„ä¸‹æ¸¸èŠ‚ç‚¹å‘é€ä¸€ä¸ªå…¨æ–°çš„ã€ä¸åŒçš„çŠ¶æ€ã€‚è¿™å¯¹äº Map-Reduce ç­‰æ¨¡å¼éå¸¸æœ‰ç”¨ï¼Œå› ä¸ºå¯ä»¥åœ¨è¿è¡Œæ—¶åŠ¨æ€åœ°åˆ›å»ºåˆ†æ”¯ã€‚

    -   ä¼˜åŠ¿
        1. å¯ä»¥å®ç°å¹¶å‘é€»è¾‘
        2. çŠ¶æ€éš”ç¦»ï¼Œé€šè¿‡sendå¯ä»¥å‘ä¸åŒçš„èŠ‚ç‚¹ä¼ é€’éš”ç¦»çš„ä¸åŒçŠ¶æ€

    **æ³¨æ„ï¼šsendåªèƒ½åœ¨æ¡ä»¶è¾¹ä¸­ä½¿ç”¨**

    ```
    def continue_to_jokes(state: OverallState):
        return [Send("generate_joke", {"subject": s}) for s in state['subjects']]
    
    graph.add_conditional_edges("node_a", continue_to_jokes)
    ```

-   **`Command`**

     åœ¨**èŠ‚ç‚¹**å‡½æ•°ä¸­è¿”å› `Command` å¯¹è±¡ï¼Œå¯ä»¥åŒæ—¶å®ç°**çŠ¶æ€æ›´æ–°**å’Œ**æ§åˆ¶æµè·³è½¬**ã€‚è¿™åœ¨éœ€è¦å°†çŠ¶æ€æ›´æ–°å’Œè·¯ç”±å†³ç­–åˆå¹¶åœ¨ä¸€æ­¥å®Œæˆæ—¶éå¸¸æœ‰ç”¨ï¼Œä¾‹å¦‚å¤šæ™ºèƒ½ä½“ä¹‹é—´çš„åˆ‡æ¢ã€‚

    **ä¼˜åŠ¿**

    1. æ—¢å¯ä»¥å®ç°èŠ‚ç‚¹è½¬ç§»åˆå¯ä»¥æ›´æ–°çŠ¶æ€
    2. å³å¯ä»¥å®ç°å›¾å†…èŠ‚ç‚¹è½¬ç§»åˆå¯ä»¥å‘çˆ¶å›¾å†…è·³è½¬

    ```
    def my_node(state: State) -> Command[Literal["other_subgraph"]]:
        return Command(
            update={"foo": "bar"},
            goto="other_subgraph",  
            graph=Command.PARENT #å½“æŒ‡å®šè¯¥å‚æ•°é‚£ä¹ˆå°±ä¼šä»çˆ¶å›¾å†…å¯»æ‰¾ gotoçš„èŠ‚ç‚¹è¿›è¡Œè·³è½¬
        )
        
    ```

#### Runtime Contextï¼ˆè¿è¡Œæ—¶ä¸Šä¸‹æ–‡ ï¼‰: 

å…è®¸åœ¨è°ƒç”¨å›¾æ—¶ä¼ å…¥ä¸å±äº `State` çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¦‚æ•°æ®åº“è¿æ¥ã€APIå¯†é’¥ç­‰ï¼‰

- ä¼˜åŠ¿

  1. **ä¼ é€’é…ç½®/å‡­è¯**: åƒ API å¯†é’¥ã€æ•°æ®åº“è¿æ¥æ± ã€ç”¨æˆ· ID ç­‰ä¿¡æ¯ï¼Œå®ƒä»¬æ˜¯é…ç½®æˆ–ä¸Šä¸‹æ–‡ï¼Œè€Œä¸æ˜¯å·¥ä½œæµæœ¬èº«çš„çŠ¶æ€ã€‚å°†å®ƒä»¬æ”¾åœ¨ State ä¸­æ˜¯ä¸åˆé€‚çš„ï¼Œå› ä¸ºå®ƒä»¬ä¸åº”è¯¥è¢«ä¿å­˜åˆ°æ£€æŸ¥ç‚¹é‡Œã€‚
  2. **é¿å…çŠ¶æ€è†¨èƒ€**: ä¿æŒ State çš„ç®€æ´ï¼ŒåªåŒ…å«çœŸæ­£éœ€è¦åœ¨æ­¥éª¤ä¹‹é—´ä¼ é€’å’Œæ¼”å˜çš„æ•°æ®ã€‚

  ```
  @dataclass
  class ContextSchema:
      llm_provider: str = "openai"
  from langgraph.graph import StateGraph
  from langgraph.graph.config import RunnableConfig
  
  # é‡ç‚¹ï¼šèŠ‚ç‚¹å‡½æ•°æ¥æ”¶ state å’Œ config ä¸¤ä¸ªå‚æ•°
  def my_awesome_node(state: State, config: RunnableConfig):
      # ä» config['configurable'] ä¸­è·å–ä¸Šä¸‹æ–‡ä¿¡æ¯
      provider = config["configurable"]["llm_provider"]
      
      print(f"--- Inside my_awesome_node ---")
      print(f"The current LLM provider from context is: {provider}")
      
      # åœ¨è¿™é‡Œï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ provider å˜é‡æ¥åŠ¨æ€é€‰æ‹© LLM å®¢æˆ·ç«¯
      if provider == "openai":
          # Do something with OpenAI client
          pass
      elif provider == "anthropic":
          # Do something with Anthropic client
          pass
          
      return {} # è¿”å›çŠ¶æ€æ›´æ–°
  
  graph = StateGraph(State, context_schema=ContextSchema)
  ```

**é€’å½’é™åˆ¶ (Recursion Limit)**: ä¸ºé˜²æ­¢æ— é™å¾ªç¯ï¼Œå›¾çš„æ‰§è¡Œæœ‰é»˜è®¤çš„é€’å½’æ­¥æ•°é™åˆ¶ï¼ˆ25æ­¥ï¼‰ï¼Œå¯ä»¥é€šè¿‡é…ç½®è¿›è¡Œä¿®æ”¹ã€‚

**å¯è§†åŒ– (Visualization)**: å†…ç½®äº†å¤šç§æ–¹æ³•æ¥å¯è§†åŒ–å›¾çš„ç»“æ„ï¼Œä¾¿äºè°ƒè¯•å’Œç†è§£ã€‚

---

å¸Œæœ›è¿™ä»½ç¬”è®°èƒ½å¸®åŠ©æ‚¨å¿«é€ŸæŒæ¡ LangGraph Graph API çš„æ ¸å¿ƒç”¨æ³•ï¼

### 6.4 å¤šæ™ºèƒ½ä½“

#### è½¬äº¤æœºåˆ¶

åœ¨å¤šæ™ºèƒ½ä½“è¿›è¡Œé€šä¿¡çš„æ—¶å€™é‡è¦çš„æ˜¯å¦‚ä½•è¿›è¡Œæ•°æ®ä¼ è¾“ä»¥åŠæ™ºèƒ½è¯†åˆ«æ„å›¾å®ç°èŠ‚ç‚¹è·³è½¬

æ•°æ®å¦‚ä½•ä¼ è¾“ä»¥åŠç§æœ‰åŒ–å¯ä»¥å‚è€ƒ

[3.4 çŠ¶æ€-çŠ¶æ€å®ä¾‹è®²è§£](#44å¾ªç¯é“¾-langgraphç‰¹æœ‰)

##### æ„å›¾è¯†åˆ«

åœ¨å¤šæ™ºèƒ½ä½“é€šä¿¡çš„æ—¶å€™æˆ‘ä»¬éœ€è¦æ˜ç¡®çš„å…³é”®ç‚¹æˆ‘ä»¬å¦‚ä½•çŸ¥é“éœ€è¦ä»å½“å‰æ™ºèƒ½ä½“åˆ‡æ¢åˆ°å…¶ä»–æ™ºèƒ½ä½“

- workflowèŒƒå¼ è¿™ç§æœ€ä¸ºç®€å•å°±æ˜¯é€šè¿‡ç¡¬ç¼–ç äººä¸ºå®šä¹‰è½¬äº¤æ¡ä»¶

- agentèŒƒå¼ï¼šæˆ‘ä»¬å¯ä»¥è®©å¤§æ¨¡å‹ä¸ºæˆ‘ä»¬è¿›è¡Œåˆ¤æ–­

  1. è®©å¤§æ¨¡å‹ä¸ä½†è¾“å‡ºé—®é¢˜ç­”æ¡ˆåŒæ—¶è¿˜è¾“å‡ºè·¯ç”±ç„¶åä¿å­˜åœ¨stateé‡Œé¢ï¼ˆç»™å®šä¸å…¶è¿æ¥çš„æ™ºèƒ½ä½“èŠ‚ç‚¹åç§°å’ŒåŠŸèƒ½è®©å…¶è‡ªè¡Œåˆ¤æ–­æ˜¯å¦ç§»äº¤ï¼‰

     ```
     reviewer_prompt = ChatPromptTemplate.from_messages([
         ("system", "ä½ æ˜¯å®¡ç¨¿äººã€‚å®¡æŸ¥æŠ¥å‘Šï¼Œæä¾›åé¦ˆï¼Œç„¶åå†³å®šï¼šè¿”å› writer èŠ‚ç‚¹é‡æ–°ä¹¦å†™ï¼Œæˆ–ç»“æŸã€‚è¾“å‡ºä»¥jsonæ ¼å¼è¾“å‡º {{'data':string,'next':str'}}"),
         ("placeholder", "{messages}"),
     ])
     ```

     2.å¯ä»¥å•ç‹¬åœ¨è¯¥èŠ‚ç‚¹ä¸‹é¢è¿æ¥ä¸€ä¸ªèŠ‚ç‚¹è¿›è¡Œåˆ¤æ–­

     

##### èŠ‚ç‚¹ç§»äº¤

- èŠ‚ç‚¹è¿”å›commandæ¥è¿›è¡Œè·³è½¬

  ```
  return Command(
          # Specify which agent to call next
          goto=ï¼ˆ...ï¼‰,åœ¨è¿™é‡Œå¡«å……éœ€è¦è·³è½¬çš„èŠ‚ç‚¹
          # Update the graph state
          update={"my_state_key": "my_state_value"}
      )
  ```

- é€šè¿‡è·¯ç”±å‡½æ•°æ­é…æ¡ä»¶è·¯å¾„

  ```
  # è·¯ç”±å‡½æ•°ï¼šåŸºäº next_agent å†³å®šä¸‹ä¸€ä¸ªèŠ‚ç‚¹
  def route_to_next(state: AgentState) -> str:
      return state["next_agent"]
  #åœ¨stateä¸­å®æ—¶æ›´æ–°ä¸‹ä¸€æ­¥èŠ‚ç‚¹åç§°
  workflow.add_conditional_edges(
      "reviewer",
      route_to_next,
  )
  ```

#### å¤šæ™ºèƒ½ä½“æ¶æ„

å¸¸ç”¨çš„å¤šæ™ºèƒ½ä½“æ¶æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæ¥ä¸‹æ¥æˆ‘å°†ä¸€ä¸€ä»‹ç»

![image-20251016142911013](image-20251016142911013_å‰¯æœ¬.png)

##### Network-ç½‘ç»œæ¶æ„ï¼ˆSwarm-é¸Ÿç¾¤æ¶æ„ï¼‰

å»ä¸­å¿ƒåŒ–çš„æ™ºèƒ½ä½“æ¶æ„ï¼Œä¸ä¸­å¿ƒåŒ–æ™ºèƒ½ä½“æ¶æ„ç›¸æ¯”æ˜¾è‘—ä¼˜åŠ¿å°±æ˜¯å‡è½»äº†ä¸­å¿ƒæ™ºèƒ½ä½“çš„è´Ÿæ‹…ï¼Œå¦‚æœæ™ºèƒ½ä½“æ•°é‡ä¼—å¤šï¼Œé‚£ä¹ˆä¸­å¿ƒæ™ºèƒ½ä½“çš„å‹åŠ›è¿‡å¤§ä¼šå¢åŠ è°ƒåº¦å›°éš¾ä»è€Œå¢åŠ äº†è½¬äº¤é”™è¯¯çš„é£é™©ã€‚

æ™ºèƒ½ä½“ç›¸äº’è¿æ¥é€šä¿¡ç¡®ä¿ä¿¡æ¯æ— éšœç¢æµåŠ¨ï¼Œé¿å…ä¿¡æ¯å­¤å²›ã€‚ä»£ç†å¯ä»¥å¹¶è¡Œæˆ–ä¸²è¡Œåä½œï¼Œç±»ä¼¼äºäººç±»å›¢é˜Ÿä¸­çš„è‡ªç”±è®¨è®ºã€‚

å›¾ä¸­å±•ç¤ºäº†å…¨è¿æ¥æ¶æ„ä½†æ˜¯æˆ‘ä»¬å¯ä»¥å–æ¶ˆæŸäº›åŸºæœ¬ä¸ä¼šå­˜åœ¨ç›´æ¥è”ç³»çš„æ™ºèƒ½ä½“ä¹‹é—´çš„è¿æ¥ä»è€Œå‡å°‘å¼€é”€ã€‚



**ä»£ç å®ä¾‹**

```python
from typing import TypedDict, Annotated, Sequence
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate
import os
from base import llm

# å®šä¹‰çŠ¶æ€ï¼šæ¶ˆæ¯å†å² + å½“å‰å†³ç­–ï¼ˆä¸‹ä¸€ä¸ªä»£ç†ï¼‰
class AgentState(TypedDict):
    messages: Annotated[Sequence[AIMessage], add_messages]
    next_agent: str  # "researcher", "writer", "reviewer" æˆ– "END"

# ä»£ç†æç¤ºæ¨¡æ¿
researcher_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ç ”ç©¶å‘˜ã€‚æ”¶é›†æ°”å€™å˜åŒ–æ•°æ®ï¼Œç„¶åå†³å®šï¼šå¦‚æœæ•°æ®è¶³å¤Ÿï¼Œè°ƒç”¨ writerï¼›å¦åˆ™ç»“æŸã€‚è¾“å‡ºæ ¼å¼ï¼šå†…å®¹ + 'Next: writer' æˆ– 'Next: END'"),
    ("human", "{input}"),
    ("placeholder", "{messages}"),
])

writer_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä½œå®¶ã€‚åŸºäºæ•°æ®æ’°å†™æŠ¥å‘Šè‰ç¨¿ï¼Œç„¶åå†³å®šï¼šè°ƒç”¨ reviewer å®¡æŸ¥ï¼Œæˆ– researcher è¡¥å……ã€‚è¾“å‡ºæ ¼å¼ï¼šå†…å®¹ + 'Next: reviewer' æˆ– 'Next: researcher'"),
    ("placeholder", "{messages}"),
])

reviewer_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯å®¡ç¨¿äººã€‚å®¡æŸ¥æŠ¥å‘Šï¼Œæä¾›åé¦ˆï¼Œç„¶åå†³å®šï¼šè¿”å› writer è¿­ä»£ï¼Œæˆ–ç»“æŸã€‚è¾“å‡ºæ ¼å¼ï¼šå†…å®¹ + 'Next: writer' æˆ– 'Next: END'"),
    ("placeholder", "{messages}"),
])

# ä»£ç†èŠ‚ç‚¹å‡½æ•°ï¼šè°ƒç”¨ LLM å¹¶è§£æ next_agent
def researcher_node(state: AgentState) -> AgentState:
    chain = researcher_prompt | llm
    response = chain.invoke({"input": state["messages"][0].content, "messages": state["messages"]})
    content = response.content
    next_agent = "END"  # é»˜è®¤
    if "Next: writer" in content:
        next_agent = "writer"
    return {"messages": [AIMessage(content=content)], "next_agent": next_agent}

def writer_node(state: AgentState) -> AgentState:
    chain = writer_prompt | llm
    response = chain.invoke({"messages": state["messages"]})
    content = response.content
    next_agent = "reviewer"  # é»˜è®¤è°ƒç”¨ reviewer
    if "Next: researcher" in content:
        next_agent = "researcher"
    elif "Next: END" in content:
        next_agent = "END"
    return {"messages": [AIMessage(content=content)], "next_agent": next_agent}

def reviewer_node(state: AgentState) -> AgentState:
    chain = reviewer_prompt | llm
    response = chain.invoke({"messages": state["messages"]})
    content = response.content
    next_agent = "writer"  # é»˜è®¤è¿­ä»£
    if "Next: END" in content:
        next_agent = "END"
    return {"messages": [AIMessage(content=content)], "next_agent": next_agent}

# è·¯ç”±å‡½æ•°ï¼šåŸºäº next_agent å†³å®šä¸‹ä¸€ä¸ªèŠ‚ç‚¹
def route_to_next(state: AgentState) -> str:
    return state["next_agent"]

# æ„å»ºå›¾
workflow = StateGraph(AgentState)
workflow.add_node("researcher", researcher_node)
workflow.add_node("writer", writer_node)
workflow.add_node("reviewer", reviewer_node)

# æ·»åŠ æ¡ä»¶è¾¹
workflow.add_conditional_edges(
    "researcher",
    route_to_next,
    {"writer": "writer", "END": END}
)
workflow.add_conditional_edges(
    "writer",
    route_to_next,
    {"reviewer": "reviewer", "researcher": "researcher", "END": END}
)
workflow.add_conditional_edges(
    "reviewer",
    route_to_next,
    {"writer": "writer", "END": END}
)

# è®¾ç½®å…¥å£
workflow.set_entry_point("researcher")

# ç¼–è¯‘å›¾
graph = workflow.compile()

# è¿è¡Œ demo
if __name__ == "__main__":
    user_input = "ç”Ÿæˆä¸€ä»½å…³äºæ°”å€™å˜åŒ–å½±å“çš„ç®€çŸ­æŠ¥å‘Šã€‚"
    initial_state = {
        "messages": [HumanMessage(content=user_input)],
        "next_agent": "researcher"
    }
    result = graph.invoke(initial_state)
    print("æœ€ç»ˆæŠ¥å‘Šï¼š")
    for msg in result["messages"]:
        print(f"- {msg.content}")
        
```



![](Network_workflow_graph.png)







```
#è¾“å‡ºï¼š
æœ€ç»ˆæŠ¥å‘Šï¼š
- ç”Ÿæˆä¸€ä»½å…³äºæ°”å€™å˜åŒ–å½±å“çš„ç®€çŸ­æŠ¥å‘Šã€‚
- æ ¹æ®å½“å‰æ”¶é›†çš„æ•°æ®ï¼Œæ°”å€™å˜åŒ–çš„å½±å“å·²ç»æ˜¾è‘—ä½“ç°åœ¨å¤šä¸ªæ–¹é¢ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š

1. **æç«¯å¤©æ°”äº‹ä»¶åŠ å‰§**ï¼šå…¨çƒèŒƒå›´å†…ï¼Œçƒ­æµªã€å¹²æ—±ã€æ´ªæ°´å’Œå¼ºé£æš´çš„é¢‘ç‡ä¸å¼ºåº¦å¢åŠ ï¼Œå¯¼è‡´äººå‘˜ä¼¤äº¡å’Œç»æµæŸå¤±ã€‚
2. **æµ·å¹³é¢ä¸Šå‡**ï¼šå†°å·å’Œæåœ°å†°ç›–èåŒ–ï¼Œå¨èƒæ²¿æµ·ç¤¾åŒºå’Œç”Ÿæ€ç³»ç»Ÿï¼Œé€ æˆåœŸåœ°ä¸§å¤±å’Œäººå£è¿ç§»ã€‚
3. **ç”Ÿç‰©å¤šæ ·æ€§ä¸§å¤±**ï¼šæ –æ¯åœ°å˜åŒ–å’Œæµ·æ´‹é…¸åŒ–å¯¼è‡´ç‰©ç§ç­ç»åŠ é€Ÿï¼Œå½±å“é£Ÿç‰©é“¾å’Œç”Ÿæ€å¹³è¡¡ã€‚
4. **å†œä¸šä¸ç²®é£Ÿå®‰å…¨**ï¼šæ¸©åº¦å‡é«˜å’Œé™æ°´æ¨¡å¼æ”¹å˜å½±å“ä½œç‰©äº§é‡ï¼ŒåŠ å‰§å…¨çƒç²®é£Ÿä¸å®‰å…¨ã€‚
5. **äººç±»å¥åº·é£é™©**ï¼šçƒ­ç›¸å…³ç–¾ç—…ã€ä¼ æŸ“ç—…ä¼ æ’­èŒƒå›´æ‰©å¤§ä»¥åŠç©ºæ°”æ±¡æŸ“é—®é¢˜æ—¥ç›Šä¸¥é‡ã€‚

è¿™äº›å½±å“å‡¸æ˜¾äº†é‡‡å–ç´§æ€¥å‡ç¼“ä¸é€‚åº”æªæ–½çš„å¿…è¦æ€§ã€‚

Next: writer
- æ ¹æ®å½“å‰æ”¶é›†çš„æ•°æ®ï¼Œæ°”å€™å˜åŒ–çš„å½±å“å·²ç»æ˜¾è‘—ä½“ç°åœ¨å¤šä¸ªæ–¹é¢ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š

1. **æç«¯å¤©æ°”äº‹ä»¶åŠ å‰§**ï¼šå…¨çƒèŒƒå›´å†…ï¼Œçƒ­æµªã€å¹²æ—±ã€æ´ªæ°´å’Œå¼ºé£æš´çš„é¢‘ç‡ä¸å¼ºåº¦å¢åŠ ï¼Œå¯¼è‡´äººå‘˜ä¼¤äº¡å’Œç»æµæŸå¤±ã€‚
2. **æµ·å¹³é¢ä¸Šå‡**ï¼šå†°å·å’Œæåœ°å†°ç›–èåŒ–ï¼Œå¨èƒæ²¿æµ·ç¤¾åŒºå’Œç”Ÿæ€ç³»ç»Ÿï¼Œé€ æˆåœŸåœ°ä¸§å¤±å’Œäººå£è¿ç§»ã€‚
3. **ç”Ÿç‰©å¤šæ ·æ€§ä¸§å¤±**ï¼šæ –æ¯åœ°å˜åŒ–å’Œæµ·æ´‹é…¸åŒ–å¯¼è‡´ç‰©ç§ç­ç»åŠ é€Ÿï¼Œå½±å“é£Ÿç‰©é“¾å’Œç”Ÿæ€å¹³è¡¡ã€‚
4. **å†œä¸šä¸ç²®é£Ÿå®‰å…¨**ï¼šæ¸©åº¦å‡é«˜å’Œé™æ°´æ¨¡å¼æ”¹å˜å½±å“ä½œç‰©äº§é‡ï¼ŒåŠ å‰§å…¨çƒç²®é£Ÿä¸å®‰å…¨ã€‚
5. **äººç±»å¥åº·é£é™©**ï¼šçƒ­ç›¸å…³ç–¾ç—…ã€ä¼ æŸ“ç—…ä¼ æ’­èŒƒå›´æ‰©å¤§ä»¥åŠç©ºæ°”æ±¡æŸ“é—®é¢˜æ—¥ç›Šä¸¥é‡ã€‚

è¿™äº›å½±å“å‡¸æ˜¾äº†é‡‡å–ç´§æ€¥å‡ç¼“ä¸é€‚åº”æªæ–½çš„å¿…è¦æ€§ã€‚

Next: reviewer
- ä½œä¸ºå®¡ç¨¿äººï¼Œæˆ‘å¯¹è¿™ä»½æ°”å€™å˜åŒ–å½±å“æŠ¥å‘Šè¿›è¡Œä»¥ä¸‹è¯„ä¼°ï¼š

**æŠ¥å‘Šä¼˜ç‚¹ï¼š**
1. ç»“æ„æ¸…æ™°ï¼Œé‡‡ç”¨åˆ†ç‚¹åˆ—ä¸¾æ–¹å¼ï¼Œä¾¿äºè¯»è€…å¿«é€ŸæŒæ¡å…³é”®ä¿¡æ¯
2. æ¶µç›–é¢†åŸŸå…¨é¢ï¼Œæ¶‰åŠæç«¯å¤©æ°”ã€æµ·å¹³é¢ã€ç”Ÿç‰©å¤šæ ·æ€§ã€å†œä¸šå’Œå¥åº·ç­‰ä¸»è¦æ–¹é¢
3. è¯­è¨€ç®€æ´æ˜äº†ï¼Œä¸“ä¸šæœ¯è¯­ä½¿ç”¨æ°å½“
4. ç»“å°¾å¼ºè°ƒè¡ŒåŠ¨å¿…è¦æ€§ï¼Œå¢å¼ºäº†æŠ¥å‘Šçš„ç´§è¿«æ„Ÿ

**æ”¹è¿›å»ºè®®ï¼š**
1. å¯å¢åŠ å…·ä½“æ•°æ®æ”¯æŒï¼Œå¦‚æµ·å¹³é¢ä¸Šå‡çš„å…·ä½“æ•°å€¼æˆ–æ¸©åº¦å‡é«˜å¹…åº¦
2. å»ºè®®è¡¥å……æ—¶é—´ç»´åº¦ï¼Œè¯´æ˜è¿™äº›å½±å“æ˜¯æ­£åœ¨å‘ç”Ÿè¿˜æ˜¯æœªæ¥é¢„æµ‹
3. å¯ç®€è¦æåŠä¸åŒåœ°åŒºå—å½±å“ç¨‹åº¦çš„å·®å¼‚æ€§
4. å»ºè®®åœ¨ç”Ÿç‰©å¤šæ ·æ€§éƒ¨åˆ†è¡¥å……1-2ä¸ªå…·ä½“ç‰©ç§å—å½±å“çš„ä¾‹å­

**æ€»ä½“è¯„ä»·ï¼š**
è¿™æ˜¯ä¸€ä»½ç»“æ„å®Œæ•´ã€å†…å®¹å‡†ç¡®çš„æ°”å€™å˜åŒ–å½±å“æ¦‚è¿°æŠ¥å‘Šã€‚è™½ç„¶å¯ä»¥è¿›ä¸€æ­¥ä¸°å¯Œç»†èŠ‚ï¼Œä½†ç°æœ‰ç‰ˆæœ¬å·²ç»å¾ˆå¥½åœ°å®Œæˆäº†åŸºæœ¬ä¿¡æ¯ä¼ è¾¾çš„ä»»åŠ¡ã€‚

Next: END

è¿›ç¨‹å·²ç»“æŸï¼Œé€€å‡ºä»£ç ä¸º 0

```

##### Supervisoræ¶æ„

ä¸­å¿ƒåŒ–æ™ºèƒ½ä½“æ¶æ„,é€šè¿‡ä¸€ä¸ªä¸­å¿ƒè·¯ç”±è¿æ¥æ‰€æœ‰æ™ºèƒ½ä½“è¿›è¡Œæ™ºèƒ½åˆ†é…





